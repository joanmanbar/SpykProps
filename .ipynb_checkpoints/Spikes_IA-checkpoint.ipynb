{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "packed-shanghai",
   "metadata": {
    "id": "packed-shanghai"
   },
   "source": [
    "# Guide to Analyze Spike Properties\n",
    "This file is meant to ilustrate the data collected in each single spike using SpykProps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hNzyEWWvYgWP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27938,
     "status": "ok",
     "timestamp": 1634305152791,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "hNzyEWWvYgWP",
    "outputId": "66e71b8c-15a4-4e6b-8bd1-2477bf356a7b"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kDCJPXr1azrf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6449,
     "status": "ok",
     "timestamp": 1634306009623,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "kDCJPXr1azrf",
    "outputId": "128f898d-b179-4af0-f774-aeee4ebf1574"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/M.Sc/THESIS/ImageAnalysis/SpikeProperties/Spyk_Prop')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IYipVKCzbpUM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6398,
     "status": "ok",
     "timestamp": 1634306022215,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "IYipVKCzbpUM",
    "outputId": "73c276d9-c7cb-47be-d6e0-a081548ef74c"
   },
   "outputs": [],
   "source": [
    "pip install skan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5c0465-9452-49f0-afdc-25d779168805",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "695bd235-2d6f-4e4d-a762-45e8c3646d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SpykFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "encouraging-personal",
   "metadata": {
    "executionInfo": {
     "elapsed": 7205,
     "status": "ok",
     "timestamp": 1634306029412,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "encouraging-personal",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "\n",
    "from SpykFunctions import *\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import math\n",
    "import pathlib\n",
    "\n",
    "from skimage import measure, segmentation, color\n",
    "from skimage.morphology import skeletonize, thin\n",
    "from skimage.future import graph\n",
    "from skimage.segmentation import watershed, active_contour\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.filters import meijering, sato, frangi, hessian, gaussian\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import hough_line, hough_line_peaks, probabilistic_hough_line\n",
    "from skimage.draw import line\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from skan import Skeleton, summarize, skeleton_to_csgraph, draw\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import imutils\n",
    "\n",
    "import imageio\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# import astropy.units as u\n",
    "# from fil_finder import FilFinder2D\n",
    "# from astropy.io import fits\n",
    "\n",
    "# Make sure Jupyter Notebook shows all outputs from the same cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-venice",
   "metadata": {
    "executionInfo": {
     "elapsed": 197,
     "status": "ok",
     "timestamp": 1634306940963,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "capital-venice",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the \"%matplotlib inline\" figure resolution on the notebook\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c3d30-4d58-4562-9317-253e91e116dd",
   "metadata": {
    "id": "d75c3d30-4d58-4562-9317-253e91e116dd"
   },
   "source": [
    "# Get files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-sunrise",
   "metadata": {
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1634306942747,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "needed-sunrise"
   },
   "outputs": [],
   "source": [
    "# Define image folder\n",
    "mypath = r'./Images/TEST'\n",
    "# mypath = r'/content/drive/MyDrive/M.Sc/THESIS/ImageAnalysis/SpikeProperties/Spyk_Prop/Images/TEST'\n",
    "Images = glob.glob(mypath + '/**/*.tif', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-zealand",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1634306944336,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "cardiovascular-zealand",
    "outputId": "77f7af5a-56b7-4f8b-8fa5-78a37e2bca2a"
   },
   "outputs": [],
   "source": [
    "len(Images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d90bcc3-bc56-4338-a176-842d8b3070e7",
   "metadata": {
    "id": "7d90bcc3-bc56-4338-a176-842d8b3070e7"
   },
   "source": [
    "## Select an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-special",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5619,
     "status": "ok",
     "timestamp": 1634306951758,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "whole-special",
    "outputId": "9ca0aee4-5e9f-4432-cf4b-966bbe84006a"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Open and image and remove background\n",
    "img0_name = Images[3]\n",
    "# plt.imshow(plt.imread(img0_name))\n",
    "img0 = RemoveBackground(img0_name, OtsuScaling=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-terrace",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5674,
     "status": "ok",
     "timestamp": 1634306957405,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "pharmaceutical-terrace",
    "outputId": "68083d4c-1d44-4708-eadf-223e9248b31d"
   },
   "outputs": [],
   "source": [
    "# plt.imshow(plt.imread(img0_name))\n",
    "plt.imshow(img0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-benchmark",
   "metadata": {
    "id": "confidential-benchmark"
   },
   "outputs": [],
   "source": [
    "# mpl.rcParams['figure.dpi']= 300\n",
    "# plt.imshow(img0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-detective",
   "metadata": {
    "executionInfo": {
     "elapsed": 8406,
     "status": "ok",
     "timestamp": 1634306965769,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "confident-detective"
   },
   "outputs": [],
   "source": [
    "# Convert to gray\n",
    "gray0 = img0 @ [0.2126, 0.7152, 0.0722]\n",
    "   \n",
    "# Threshold\n",
    "otsu = filters.threshold_otsu(gray0)\n",
    "bw0 = gray0 > 0\n",
    "bw1 = morphology.remove_small_objects(bw0, min_size=1.5e-05 * gray0.shape[0] * gray0.shape[1])\n",
    "\n",
    "# Get Lab values\n",
    "img1 = np.where(bw1[..., None], img0, 0)\n",
    "Lab = color.rgb2lab(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ab3542-cccb-4756-ac16-ca8d30cf676a",
   "metadata": {
    "id": "41ab3542-cccb-4756-ac16-ca8d30cf676a"
   },
   "outputs": [],
   "source": [
    "# plt.imshow(Lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda47fe-b4fd-45d0-abc5-9e9ba097fec2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1634221493984,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "1dda47fe-b4fd-45d0-abc5-9e9ba097fec2",
    "outputId": "abc7b3fa-5571-431d-b172-1f4b24ba5f62"
   },
   "outputs": [],
   "source": [
    "plt.imshow(bw1)\n",
    "otsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e45a8-7ef3-4ede-9140-9b2334b42878",
   "metadata": {
    "id": "aa4e45a8-7ef3-4ede-9140-9b2334b42878"
   },
   "outputs": [],
   "source": [
    "# plt.imshow(bw1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d8d0c-ef56-4323-b906-785f624113f1",
   "metadata": {
    "id": "8e5d8d0c-ef56-4323-b906-785f624113f1"
   },
   "source": [
    "## Enumerate (label) spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7e30c1-fcc0-472d-aa07-61e1c164295b",
   "metadata": {
    "id": "da7e30c1-fcc0-472d-aa07-61e1c164295b"
   },
   "source": [
    "**NOTE:** Spike number starts at 0 in TROE2020, and at 1 in TROE2021. For the latter, object 0 is the envelop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-coordination",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5828,
     "status": "ok",
     "timestamp": 1634246251274,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "banned-coordination",
    "outputId": "1d54d38d-9f31-486e-e4e6-e7918b424887"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def EnumerateSpk(bw, TROE2020=False):\n",
    "    \n",
    "    # Regionprops\n",
    "    labels, n_labels = label(bw, return_num = True)\n",
    "    props = regionprops(labels)\n",
    "\n",
    "    # Visualize spike number\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(bw, cmap=plt.cm.gray)\n",
    "    \n",
    "    if TROE2020 == True:\n",
    "        spike_ind = 1\n",
    "    else:\n",
    "        spike_ind = 0\n",
    "\n",
    "    for props in props_spikes:\n",
    "        y0, x0 = props.centroid\n",
    "        plt.text(x0, y0, str(spike_ind), color=\"red\", fontsize=15)\n",
    "        spike_ind += 1 \n",
    "\n",
    "def EnumerateSpkCV(bw, rgb, TextSize=5, TROE2020=False):\n",
    "    \n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(bw), connectivity=8)\n",
    "\n",
    "    img = rgb.copy()\n",
    "    counter=-1\n",
    "    for c in centroids:\n",
    "#         print(c)\n",
    "        cx = round(c[0])\n",
    "        cy = round(c[1])\n",
    "        img = cv2.circle(img, (cx, cy), 10, (255, 0, 0), -1)\n",
    "        img = cv2.putText(img, str(counter), (cx - 25, cy - 25),cv2.FONT_HERSHEY_SIMPLEX, TextSize, (255, 0, 0), 15)\n",
    "        counter = counter+1\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564fd497-efa7-49c4-b7d3-7cfa8693ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "EnumerateSpk(bw1,TROE2020=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04dcb47-e048-45ff-aaea-5ace5164bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "EnumerateSpkCV(bw1, img0, TROE2020=False)\n",
    "# This one is faster because doesn't require regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a376338-eea4-4588-b6d0-1b586057e399",
   "metadata": {
    "id": "6a376338-eea4-4588-b6d0-1b586057e399"
   },
   "outputs": [],
   "source": [
    "# plt.imshow(labeled_spks==1, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d9ee82-c3f3-47c0-8b90-64f45972271c",
   "metadata": {
    "id": "37d9ee82-c3f3-47c0-8b90-64f45972271c"
   },
   "source": [
    "## Select a spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac976883-ef60-4500-b8e1-9ee2fe07d4dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "executionInfo": {
     "elapsed": 2796,
     "status": "ok",
     "timestamp": 1634306969248,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "ac976883-ef60-4500-b8e1-9ee2fe07d4dd",
    "outputId": "43b1846f-b6f5-4234-d8eb-432c8bd40f83"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Select a spike from the labeled image\n",
    "Selected_Spike = 13\n",
    "spk = labeled_spks==Selected_Spike+1\n",
    "\n",
    "# Crop spike\n",
    "slice_x, slice_y = ndimage.find_objects(spk)[0]\n",
    "cropped_spk = spk[slice_x, slice_y]\n",
    "cropped_rgb = img0[slice_x, slice_y]\n",
    "cropped_rgb = np.where(cropped_spk[..., None], cropped_rgb, 0)\n",
    "cropped_gray = cropped_rgb @ [0.2126, 0.7152, 0.0722]\n",
    "cropped_lab = color.rgb2lab(cropped_rgb)\n",
    "plt.imshow(cropped_rgb)\n",
    "# plt.imshow(cropped_gray)\n",
    "\n",
    "# Plot selected spike\n",
    "# plt.imshow(cropped_spk)\n",
    "\n",
    "## Add 100 pixels to each border (optional)\n",
    "# padded = np.pad(cropped_spk, ((100,100), (100,100)))\n",
    "# plt.imshow(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f14d59-bf1d-4b86-ae62-f784e7c69466",
   "metadata": {
    "id": "02f14d59-bf1d-4b86-ae62-f784e7c69466"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2e71b9-5a99-41c5-bf1f-97bf59f40c3a",
   "metadata": {
    "id": "1f2e71b9-5a99-41c5-bf1f-97bf59f40c3a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11208e-b1ad-480c-a9b9-b0025a67f966",
   "metadata": {
    "id": "8d11208e-b1ad-480c-a9b9-b0025a67f966"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e02ceae-4610-4d43-8bd2-10a993bbf601",
   "metadata": {
    "id": "6e02ceae-4610-4d43-8bd2-10a993bbf601"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47663a5d-0f73-423c-b822-dab53c5030c3",
   "metadata": {
    "id": "47663a5d-0f73-423c-b822-dab53c5030c3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acute-grenada",
   "metadata": {
    "id": "acute-grenada"
   },
   "source": [
    "# Plot pixel distributions\n",
    "## CIE Lab Color Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-needle",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 14159,
     "status": "ok",
     "timestamp": 1634144425800,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "japanese-needle",
    "outputId": "4f6f6312-e912-484c-c489-0ca07120d800"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# L* channel (Luminosity)\n",
    "PixelHist(labeled_spks, Lab, 0, 250)\n",
    "# Single spike\n",
    "# PixelHist(spk, Lab, 0, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-notice",
   "metadata": {
    "id": "loaded-notice",
    "outputId": "2773a4c5-5f18-4a78-85d8-86d167c565e2"
   },
   "outputs": [],
   "source": [
    "# a* channel. Green (-a) to Red (+a)\n",
    "PixelHist(labeled_spks, Lab, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-bruce",
   "metadata": {
    "id": "fiscal-bruce",
    "outputId": "a21f5081-1eed-487e-9626-720ce728011b"
   },
   "outputs": [],
   "source": [
    "# b* channel. Blue (-b) to Yellow (+b)\n",
    "PixelHist(labeled_spks, Lab, 2, nbins = 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-power",
   "metadata": {
    "id": "lined-power"
   },
   "source": [
    "## RGB Color Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-georgia",
   "metadata": {
    "id": "loaded-georgia",
    "outputId": "41bdadb4-92f1-4a74-cce3-6b21f6c8dbdf"
   },
   "outputs": [],
   "source": [
    "# Red channel\n",
    "PixelHist(labeled_spks, img0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a293eb-0498-4f36-9803-69018332115b",
   "metadata": {
    "id": "a3a293eb-0498-4f36-9803-69018332115b",
    "outputId": "21c4f4c8-3658-4ceb-e74d-fca4aec9379a"
   },
   "outputs": [],
   "source": [
    "# Green channel\n",
    "PixelHist(labeled_spks, img0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-dodge",
   "metadata": {
    "id": "exempt-dodge",
    "outputId": "353b07f5-794f-4ebd-f754-510d0035f167"
   },
   "outputs": [],
   "source": [
    "# Blue channel\n",
    "PixelHist(labeled_spks, img0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-efficiency",
   "metadata": {
    "id": "peripheral-efficiency"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d98d2f4-b963-4376-a884-0553f57b696f",
   "metadata": {
    "id": "4d98d2f4-b963-4376-a884-0553f57b696f",
    "tags": []
   },
   "source": [
    "# Detecting Length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6396dd7-037f-4686-a5a4-0e00de764a8d",
   "metadata": {
    "id": "d6396dd7-037f-4686-a5a4-0e00de764a8d"
   },
   "source": [
    "## Define function\n",
    "The function has two possible methods, the skeleton of a blurry image (`skelblur`) or the skeleton of a convexhull (`chull`). First one is more accurate and faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993dec09-e2f1-4bc3-9101-13456a8ae015",
   "metadata": {
    "id": "993dec09-e2f1-4bc3-9101-13456a8ae015"
   },
   "outputs": [],
   "source": [
    "def spk_length(spk, method='skelblur', Overlay=True, PlotCH=False):\n",
    "    \n",
    "    if method=='skelblur':\n",
    "        # Severly blur the image\n",
    "        blur = cv2.blur(np.float32(spk),(100,100))\n",
    "        # Threshold the blur\n",
    "        thrb = blur > 0.1\n",
    "        skeleton = skeletonize(thrb)\n",
    "#         plt.imshow(skeleton)\n",
    "        \n",
    "    if method=='chull':\n",
    "        # Blur the image with a 50x50 kernel\n",
    "        blur = cv2.blur(np.float32(spk),(50,50))\n",
    "\n",
    "        # Get convex hull \n",
    "        chull = convex_hull_image(blur>0)\n",
    "\n",
    "        # Perform skeletonization\n",
    "        image = chull\n",
    "        skeleton = skeletonize(image)\n",
    "    #     plt.imshow(skeleton)\n",
    "    \n",
    "    # Spike length\n",
    "    SpkL = cv2.countNonZero(np.float32(skeleton))\n",
    "    \n",
    "    if PlotCH == True:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "        ax = axes.ravel()\n",
    "\n",
    "        ax[0].set_title('Original picture')\n",
    "        ax[0].imshow(spk, cmap=plt.cm.gray)\n",
    "        ax[0].set_axis_off()\n",
    "\n",
    "        ax[1].set_title('Transformed picture')\n",
    "        ax[1].imshow(chull, cmap=plt.cm.gray)\n",
    "        ax[1].set_axis_off()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Visualize overlay?\n",
    "    if Overlay == True:\n",
    "        overlay_images = cv2.addWeighted(np.float32(spk),20,np.float32(skeleton),255,0)\n",
    "        plt.imshow(overlay_images, cmap='gray')\n",
    "    \n",
    "    return SpkL\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304fe381-0bee-4a06-9345-d489c93a063e",
   "metadata": {
    "id": "304fe381-0bee-4a06-9345-d489c93a063e"
   },
   "source": [
    "## Execution on selected spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c4bd1-ebc6-4491-8de9-69c93db83c0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "executionInfo": {
     "elapsed": 2808,
     "status": "ok",
     "timestamp": 1634221604798,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "f56c4bd1-ebc6-4491-8de9-69c93db83c0f",
    "outputId": "c91858d9-42eb-4732-f14d-83e144a4f13c"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "spkl = spk_length(cropped_spk, Overlay=True)\n",
    "print('\\n', 'Approximated spike length =',spkl, 'pixels', '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf28bb1-8326-46df-addc-9b8c9e86bcdb",
   "metadata": {
    "id": "6bf28bb1-8326-46df-addc-9b8c9e86bcdb"
   },
   "source": [
    "# Skeletonize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41d7663-a352-46be-bb75-e726cc43e78a",
   "metadata": {
    "id": "a41d7663-a352-46be-bb75-e726cc43e78a"
   },
   "source": [
    "## Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f263a94-5d31-4f0e-9166-e85527b1cb68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "executionInfo": {
     "elapsed": 944,
     "status": "ok",
     "timestamp": 1634311044814,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "5f263a94-5d31-4f0e-9166-e85527b1cb68",
    "outputId": "e2c27ecf-ac90-4d29-a581-4df1f50650d6"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rescaled_spk = rescale(cropped_gray, 0.1, preserve_range=True, multichannel=False, anti_aliasing=True)\n",
    "# plt.imshow(rescaled_spk)\n",
    "# np.amax(rescaled_spk)\n",
    "\n",
    "# Image.resize(size, resample=None, box=None, reducing_gap=None)\n",
    "\n",
    "# Reduce image size\n",
    "im = Image.fromarray((cropped_gray).astype(np.uint8))\n",
    "(width, height) = (im.width // 30, im.height // 30)\n",
    "rescaled_spk2 = im.resize((width, height))\n",
    "\n",
    "# Increase to original size\n",
    "(width, height) = (im.width, im.height)\n",
    "rescaled_spk2 = rescaled_spk2.resize((width, height))\n",
    "plt.imshow(rescaled_spk2)\n",
    "rescaled_spk2 = np.asarray(rescaled_spk2)\n",
    "\n",
    "# rescaled_spk2 = Image.fromarray((rescaled_spk).astype(np.uint8))\n",
    "# rescaled_spk2 = rescaled_spk2.resize((cropped_rgb.shape[1],cropped_rgb.shape[0]))\n",
    "# # plt.imshow(rescaled_spk2)\n",
    "# # rescaled_spk2.size\n",
    "# opening = np.asarray(rescaled_spk2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc22423-7f53-43a2-afc2-1010249bd81f",
   "metadata": {},
   "source": [
    "## Equalization and blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88350489-5acc-4589-a042-227dcd1d1d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram equalization\n",
    "rescaled_spk3 = exposure.equalize_hist(rescaled_spk2)\n",
    "\n",
    "# Blur with a Gaussian\n",
    "blurred = filters.gaussian(rescaled_spk3, sigma=1, preserve_range=True)\n",
    "\n",
    "# Adaptative equalization\n",
    "blurred = exposure.equalize_adapthist(blurred)\n",
    "\n",
    "# Normalize\n",
    "blurred = cv2.normalize(blurred, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "blurred = blurred.astype(np.uint8)\n",
    "\n",
    "plt.imshow(blurred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829a3c2a-4e9a-4876-a8be-0d8d683f0d8c",
   "metadata": {},
   "source": [
    "## Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ebc007-d673-4386-9e31-c2aa470e8be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold at 80%\n",
    "ret, thresh = cv2.threshold(blurred, 0.8*255, 255, 0)\n",
    "thresh = np.uint8(thresh)\n",
    "\n",
    "nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(thresh, connectivity=8)\n",
    "sizes = stats[1:, -1]; nb_components = nb_components - 1    \n",
    "\n",
    "thresh2 = np.zeros((output.shape))\n",
    "#for every component in the image, you keep it only if it's above min_size\n",
    "for i in range(0, nb_components):\n",
    "    if sizes[i] >= MinSize:\n",
    "        thresh2[output == i + 1] = 255\n",
    "\n",
    "\n",
    "thresh2 = np.uint8(thresh2)\n",
    "plt.imshow(thresh2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4170cd1b-a7d0-45e3-8921-7e4ef9c1d8dc",
   "metadata": {},
   "source": [
    "## Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb1eec1-0060-4fb7-998f-553489550a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpkContours(cropped_rgb, ResizeFactor=30, MinSize = 1000, plot=True):\n",
    "    \n",
    "    # Copy iamge\n",
    "    OutImage = cropped_rgb.copy()\n",
    "    \n",
    "    # Convert to gray\n",
    "    cropped_gray = color.rgb2gray(OutImage)\n",
    "    \n",
    "    # Reduce image size\n",
    "    im = Image.fromarray((cropped_gray*255).astype(np.uint8))\n",
    "    (width, height) = (im.width // ResizeFactor, im.height // ResizeFactor)\n",
    "    rescaled_spk = im.resize((width, height))\n",
    "\n",
    "    # Increase to original size\n",
    "    (width, height) = (im.width, im.height)\n",
    "    rescaled_spk = rescaled_spk.resize((width, height))\n",
    "    rescaled_spk = np.asarray(rescaled_spk)\n",
    "\n",
    "    # Histogram equalization\n",
    "    rescaled_spk = exposure.equalize_hist(rescaled_spk)\n",
    "\n",
    "    # Blur with a Gaussian\n",
    "    blurred = filters.gaussian(rescaled_spk, sigma=1, preserve_range=True)\n",
    "\n",
    "    # Adaptative equalization\n",
    "    blurred = exposure.equalize_adapthist(blurred)\n",
    "\n",
    "    # Normalize\n",
    "    blurred = cv2.normalize(blurred, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    blurred = blurred.astype(np.uint8)\n",
    "\n",
    "    # Find contours at a constant value of 0.8\n",
    "    \n",
    "    # Threshold at 80%\n",
    "    ret, thresh = cv2.threshold(blurred, 0.8*255, 255, 0)\n",
    "    thresh = np.uint8(thresh)\n",
    "    \n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(thresh, connectivity=8)\n",
    "    sizes = stats[1:, -1]; nb_components = nb_components - 1    \n",
    "       \n",
    "    thresh2 = np.zeros((output.shape))\n",
    "    #for every component in the image, you keep it only if it's above min_size\n",
    "    for i in range(0, nb_components):\n",
    "        if sizes[i] >= MinSize:\n",
    "            thresh2[output == i + 1] = 255\n",
    "    \n",
    "#     plt.imshow(thresh2)\n",
    "    thresh2 = np.uint8(thresh2)\n",
    "    \n",
    "    EnumerateSpk(thresh2, OutImage, TROE2020=False)\n",
    "    \n",
    "#     contours = measure.find_contours(blurred,(0.8*255))\n",
    "    contours, hierarchy = cv2.findContours(thresh2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     len(contours)\n",
    "    \n",
    "    # Detected spikelets\n",
    "    print(\"Detected spikeletes: \", len(contours))\n",
    "    \n",
    "    if plot==True:\n",
    "        img = OutImage.copy()\n",
    "        # Plot all found contours\n",
    "        plot_contours = cv2.drawContours(img, contours, -1, (0,255,0), 10)\n",
    "        plt.imshow(plot_contours)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac8a281-3a1b-4bb0-b986-4f040628f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "SpkContours(cropped_rgb, MinSize = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261eb2de-bd73-4555-a021-e227272876fe",
   "metadata": {},
   "source": [
    "## Spikelet properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bbbfe5-f311-47cd-a5c5-1cafcb9b613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpkltProps(cropped_rgb, img_name, ResizeFactor=30, MinSize = 1000, plot=True):\n",
    "    \n",
    "    # Copy image\n",
    "    OutImage = cropped_rgb.copy()\n",
    "    \n",
    "    OutImageLab = color.rgb2lab(OutImage)\n",
    "    \n",
    "    # Convert to gray\n",
    "    cropped_gray = color.rgb2gray(OutImage)\n",
    "    \n",
    "    # Reduce image size\n",
    "    im = Image.fromarray((cropped_gray*255).astype(np.uint8))\n",
    "    (width, height) = (im.width // ResizeFactor, im.height // ResizeFactor)\n",
    "    rescaled_spk = im.resize((width, height))\n",
    "\n",
    "    # Increase to original size\n",
    "    (width, height) = (im.width, im.height)\n",
    "    rescaled_spk = rescaled_spk.resize((width, height))\n",
    "    rescaled_spk = np.asarray(rescaled_spk)\n",
    "\n",
    "    # Histogram equalization\n",
    "    rescaled_spk = exposure.equalize_hist(rescaled_spk)\n",
    "\n",
    "    # Blur with a Gaussian\n",
    "    blurred = filters.gaussian(rescaled_spk, sigma=1, preserve_range=True)\n",
    "\n",
    "    # Adaptative equalization\n",
    "    blurred = exposure.equalize_adapthist(blurred)\n",
    "\n",
    "    # Normalize\n",
    "    blurred = cv2.normalize(blurred, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    blurred = blurred.astype(np.uint8)\n",
    "\n",
    "    # Find contours at a constant value of 0.8\n",
    "    # Threshold at 80%\n",
    "    ret, thresh = cv2.threshold(blurred, 0.8*255, 255, 0)\n",
    "    thresh = np.uint8(thresh)\n",
    "    \n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(thresh, connectivity=8)\n",
    "    sizes = stats[1:, -1]; nb_components = nb_components - 1\n",
    "# plt.imshow(output==1)\n",
    "#     labels = output\n",
    "       \n",
    "    thresh2 = np.zeros((output.shape))\n",
    "    #for every component in the image, you keep it only if it's above min_size\n",
    "    for i in range(0, nb_components):\n",
    "        if sizes[i] >= MinSize:\n",
    "            thresh2[output == i + 1] = 255\n",
    "    \n",
    "#     plt.imshow(thresh2)\n",
    "    thresh2 = np.uint8(thresh2)\n",
    "    \n",
    "    #     contours = measure.find_contours(blurred,(0.8*255))\n",
    "    contours, hierarchy = cv2.findContours(thresh2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     len(contours)\n",
    "    \n",
    "    Props = ObjProps(thresh2, OutImage, OutImageLab, img_name='some_name')\n",
    "\n",
    "    \n",
    "    # Remove contours smallers than MinSize\n",
    "#     Filtered = [c for c in contours if cv2.contourArea(c) > MinSize]\n",
    "    \n",
    "    # Detected spikelets\n",
    "    print(\"Detected spikeletes: \", len(contours))\n",
    "    \n",
    "    # Create list for slopes\n",
    "    Slopes = []\n",
    "#     len(Slopes)\n",
    "\n",
    "    if plot==True:\n",
    "\n",
    "        # Plot all found contours\n",
    "        OutImage = cv2.drawContours(OutImage, contours, -1, (255,255,255), 10);\n",
    "        \n",
    "        # Palette\n",
    "#         cmap = matplotlib.cm.get_cmap('Spectral')\n",
    "#         color_n = 0.1\n",
    "        \n",
    "        for c in contours:\n",
    "            \n",
    "            # Generate random color from palette\n",
    "#             random_channels = cmap(color_n)\n",
    "            random_channels = (np.random.choice(range(256), size=3))\n",
    "            rr = int(random_channels[0])\n",
    "            rg = int(random_channels[1])\n",
    "            rb = int(random_channels[2])\n",
    "            \n",
    "            ellipse = cv2.fitEllipse(c)\n",
    "            OutImage = cv2.ellipse(OutImage,ellipse,(rr,rg,rb),10);\n",
    "\n",
    "            # Fit a line \n",
    "            rows,cols = OutImage.shape[:2]\n",
    "            [vx,vy,x,y] = cv2.fitLine(c, cv2.DIST_L2,0,0.01,0.01);\n",
    "            lefty = int((-x*vy/vx) + y)\n",
    "            righty = int(((cols-x)*vy/vx)+y)\n",
    "            OutImage = cv2.line(OutImage,(cols-1,righty),(0,lefty),(rr,rg,rb),3);\n",
    "            \n",
    "            # Slope from tope left, which is is the origin [0,0]\n",
    "            rise = (0,lefty)[1] - (cols-1,righty)[1]\n",
    "            run = cols\n",
    "            Slope = rise/run\n",
    "            Slopes.append(Slope)\n",
    "            \n",
    "#             color_n = color_n+0.015\n",
    "            \n",
    "        \n",
    "        # Plot\n",
    "        plt.imshow(OutImage)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        for c in contours:\n",
    "            \n",
    "            ellipse = cv2.fitEllipse(c)\n",
    "            \n",
    "            # Fit a line \n",
    "            rows,cols = OutImage.shape[:2]\n",
    "            [vx,vy,x,y] = cv2.fitLine(c, cv2.DIST_L2,0,0.01,0.01);\n",
    "            lefty = int((-x*vy/vx) + y)\n",
    "            righty = int(((cols-x)*vy/vx)+y)\n",
    "\n",
    "            rise = (0,lefty)[1] - (cols-1,righty)[1]\n",
    "            run = cols\n",
    "            Slope = rise/run\n",
    "            Slopes.append(Slope)\n",
    "    \n",
    "    # Add slopes to data frame\n",
    "    Props['Spklt_Angle'] = Slopes\n",
    "    \n",
    "    return Props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92bd247-9321-48f5-818b-f765abe2883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "SP = SpkltProps(cropped_rgb, img_name=Images[0])\n",
    "# SP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46462296-f16c-4e2f-b3db-52b283e57d7b",
   "metadata": {},
   "source": [
    "## Contour props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15edb366-084c-47b2-a5b9-0b1f1ef3e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ObjProps(mask, cropped_rgb, cropped_lab, img_name):\n",
    "\n",
    "    # Regionprops\n",
    "    labeled_contours, num_contours = label(mask, return_num = True)\n",
    "    props_contours = regionprops(labeled_contours)\n",
    "\n",
    "    # # Create column with image name\n",
    "    Image_Name = img_name.split('\\\\')[-1]\n",
    "    Image_Name = [Image_Name] * num_contours\n",
    "\n",
    "    # Geometric properties\n",
    "    Labels = [rp.label for rp in props_contours]\n",
    "    Areas = [rp.area for rp in props_contours]\n",
    "    MajorAxes = [rp.major_axis_length for rp in props_contours]\n",
    "    MinorAxes = [rp.minor_axis_length for rp in props_contours]\n",
    "    Orientations = [rp.orientation for rp in props_contours]\n",
    "    Perimeters = [rp.perimeter for rp in props_contours]\n",
    "    Eccentricities = [rp.eccentricity for rp in props_contours]\n",
    "\n",
    "    # Spectral properties\n",
    "    red_props = regionprops(labeled_contours, intensity_image=cropped_rgb[:,:,0])\n",
    "    green_props = regionprops(labeled_contours, intensity_image=cropped_rgb[:,:,1])\n",
    "    blue_props = regionprops(labeled_contours, intensity_image=cropped_rgb[:,:,2])\n",
    "    L_props = regionprops(labeled_contours, intensity_image=cropped_lab[:,:,0])\n",
    "    a_props = regionprops(labeled_contours, intensity_image=cropped_lab[:,:,1])\n",
    "    b_props = regionprops(labeled_contours, intensity_image=cropped_lab[:,:,2])\n",
    "\n",
    "    red = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in red_props])\n",
    "    green = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in green_props])\n",
    "    blue = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in blue_props])\n",
    "    L = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in L_props])\n",
    "    a = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in a_props])\n",
    "    b = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in b_props])\n",
    "\n",
    "    Red_Perc = np.array(channel_percentiles(red_props, Negatives=False)).T\n",
    "    Green_Perc = np.array(channel_percentiles(green_props, Negatives=False)).T\n",
    "    Blue_Perc = np.array(channel_percentiles(blue_props, Negatives=False)).T\n",
    "    L_Perc = np.array(channel_percentiles(L_props)).T\n",
    "    a_Perc = np.array(channel_percentiles(a_props, Negatives=True)).T\n",
    "    b_Perc = np.array(channel_percentiles(b_props, Negatives=True)).T\n",
    "\n",
    "    # Dataframe 1: for single obervation per spike\n",
    "    contours_per_image = pd.DataFrame(\n",
    "    list(zip(Image_Name, Labels, Areas, MajorAxes, MinorAxes, Orientations, Eccentricities, Perimeters, \n",
    "    red[:,0], red[:,1], red[:,2], green[:,0], green[:,1], green[:,2], blue[:,0], blue[:,1], blue[:,2], \n",
    "    L[:,0], L[:,1], L[:,2], a[:,0], a[:,1], a[:,2], b[:,0], b[:,1], b[:,2], \n",
    "    Red_Perc[:,0], Red_Perc[:,1], Red_Perc[:,2], Red_Perc[:,3], Red_Perc[:,4], Red_Perc[:,5], Red_Perc[:,6], \n",
    "    Green_Perc[:,0], Green_Perc[:,1], Green_Perc[:,2], Green_Perc[:,3], Green_Perc[:,4], Green_Perc[:,5], Green_Perc[:,6], \n",
    "    Blue_Perc[:,0], Blue_Perc[:,1], Blue_Perc[:,2], Blue_Perc[:,3], Blue_Perc[:,4], Blue_Perc[:,5], Blue_Perc[:,6], \n",
    "    L_Perc[:,0], L_Perc[:,1], L_Perc[:,2], L_Perc[:,3], L_Perc[:,4], L_Perc[:,5], L_Perc[:,6], \n",
    "    a_Perc[:,0], a_Perc[:,1], a_Perc[:,2], a_Perc[:,3], a_Perc[:,4], a_Perc[:,5], a_Perc[:,6], \n",
    "    a_Perc[:,7], a_Perc[:,8], a_Perc[:,9], a_Perc[:,10], a_Perc[:,11], a_Perc[:,12], a_Perc[:,13], \n",
    "    b_Perc[:,0], b_Perc[:,1], b_Perc[:,2], b_Perc[:,3], b_Perc[:,4], b_Perc[:,5], b_Perc[:,6], \n",
    "    b_Perc[:,7], b_Perc[:,8], b_Perc[:,9], b_Perc[:,10], b_Perc[:,11], b_Perc[:,12], b_Perc[:,13])), \n",
    "    columns = ['Image_Name', 'Spklt_Label', 'Area', 'MajorAxis', 'MinorAxes', 'Orientation', 'Eccentricity', 'Perimeter', \n",
    "      'Red_mean', 'Red_min', 'Red_max', 'Green_mean', 'Green_min', 'Green_max', 'Blue_mean', 'Blue_min', 'Blue_max', \n",
    "      'L_mean', 'L_min', 'L_max', 'a_mean', 'a_min', 'a_max', 'b_mean', 'b_min', 'b_max', \n",
    "      'Red_p25', 'Red_p50', 'Red_p75', 'Red_Mean', 'Red_sd', 'Red_Min', 'Red_Max', \n",
    "      'Green_p25', 'Green_p50', 'Green_p75', 'Green_Mean', 'Green_sd', 'Green_Min', 'Green_Max', \n",
    "      'Blue_p25', 'Blue_p50', 'Blue_p75', 'Blue_Mean', 'Blue_sd', 'Blue_Min', 'Blue_Max', \n",
    "      'L_p25', 'L_p50', 'L_p75', 'L_Mean', 'L_sd', 'L_Min', 'L_Max', \n",
    "      'a_p25_pos', 'a_p50_pos', 'a_p75_pos', 'a_Mean_pos', 'a_sd_pos', 'a_Min_pos', 'a_Max_pos', \n",
    "      'a_p25_neg', 'a_p50_neg', 'a_p75_neg', 'a_Mean_neg', 'a_sd_neg', 'a_Min_neg', 'a_Max_neg', \n",
    "      'b_p25_pos', 'b_p50_pos', 'b_p75_pos', 'b_Mean_pos', 'b_sd_pos', 'b_Min_pos', 'b_Max_pos', \n",
    "      'b_p25_neg', 'b_p50_neg', 'b_p75_neg', 'b_Mean_neg', 'b_sd_neg', 'b_Min_neg', 'b_Max_neg'])\n",
    "\n",
    "    contours_per_image['Circularity'] = (4 * np.pi * contours_per_image['Area']) / (contours_per_image['Perimeter'] ** 2)\n",
    "\n",
    "    return contours_per_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19805e5-8132-4fd0-9d0c-f1b0a4d48677",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ObjP = ObjProps(mask = thresh2, cropped_rgb=cropped_rgb, cropped_lab=cropped_lab, img_name=Images[0])\n",
    "ObjP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473105a0-135e-4e2a-83f4-c70c50e2cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnumerateSpkCV(thresh2, cropped_rgb, TextSize=3,  TROE2020=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a50a26-3f74-4a06-8d3d-52f966c3595e",
   "metadata": {},
   "source": [
    "## Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c87ab9-be8b-4a8f-8fde-fe82d05599c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c0eaaa-fb48-47b6-94ca-85f111339ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.array([1,2,3,4])\n",
    "L = L.reshape(len(L), 1)\n",
    "LT = L.T\n",
    "matL = np.multiply(L, LT)\n",
    "len(matL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a7c3b2-157a-4a25-af77-f03b32364cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(matL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e145b59-f9d1-47bf-9941-9ad4c452e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S = np.array(Slopes)\n",
    "# S = S.reshape(len(S), 1)\n",
    "# ST = S.T\n",
    "# matS = np.multiply(S, ST)\n",
    "# matS.shape\n",
    "\n",
    "\n",
    "\n",
    "def Heatmat(a, frames=30):\n",
    "    a = np.array(a)\n",
    "    a = a.reshape(len(a), 1)\n",
    "    aT = a.T\n",
    "    mat = np.multiply(a, aT)\n",
    "#     mata.shape\n",
    "\n",
    "    for frame in range(frames):\n",
    "        if frame < 10:\n",
    "            name = \"./GIFS/Angles_0\"+str(frame)+\".png\"\n",
    "        else:\n",
    "            name = \"./GIFS/Angles_\"+str(frame)+\".png\"\n",
    "        \n",
    "        new_mat = np.log10( 1+(mat**(frame) ) )\n",
    "        sns.heatmap(new_mat)\n",
    "        plt.savefig(name)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f9ed64-7ba4-40d1-9d76-c0669721947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "S = np.array(Slopes)\n",
    "S = S.reshape(len(S), 1)\n",
    "Heatmat(S, frames=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195aef24-7dbe-40d0-a036-b8ee51c555df",
   "metadata": {},
   "source": [
    "## GIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500ede59-c50d-47c9-ba88-dce8666166ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"./GIFS/\" + '*.png', recursive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d3c713-634f-4063-953c-f360d7bb31cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with imageio.get_writer('./GIFS/GIF_Angles.gif', mode='I', duration=0.25) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f985e7-211b-4a65-a2e9-ffccf67d329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "images = []\n",
    "for filename in filenames:\n",
    "    images.append(imageio.imread(filename))\n",
    "imageio.mimsave('./GIFS/GIF_Angles2.gif', images, duration=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca335e-366e-47c1-9414-0775e09c792a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c87cc1-8799-4806-bebc-3e2f6b7a8edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7139e540-7091-44a6-8222-17a8b1549174",
   "metadata": {},
   "source": [
    "## Euclidean distances of centroids\n",
    "**NOTE:** Curvature of the spike must be consider as it alters the real distance between spikelets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8cc852-7205-4bd7-a415-67ab9750d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(thresh2), \n",
    "                                                                           connectivity=8)\n",
    "# len(centroids[1:][:])\n",
    "img_center = centroids[0][:]\n",
    "c_points = centroids[1:][:]\n",
    "c_df = pd.DataFrame(c_points, columns=[\"x\",\"y\"])\n",
    "# c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d345a2c-fdc0-49c7-b49a-707b9f117143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/57107729/how-to-compute-multiple-euclidean-distances-of-all-points-in-a-dataset\n",
    "\n",
    "# Consider your points as tuples in a list\n",
    "data = [ (float(x),float(y)) for x,y in c_df[['x', 'y']].values ]\n",
    "\n",
    "# Empty list to keep the distances\n",
    "distances = []\n",
    "\n",
    "for point in data:\n",
    "    \n",
    "    # Compute the Euclidean distance between the current point and all others\n",
    "    euc_dist = [math.sqrt((point[0]-x[0] )**2 + (point[1]-x[1])**2) for x in data]\n",
    "    \n",
    "    # Append\n",
    "    distances.append(euc_dist)\n",
    "\n",
    "# Convert list to array\n",
    "D = np.array(distances)\n",
    "\n",
    "# Express it as a fraction from spike length\n",
    "D2 = D/spkl\n",
    "D2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e801e70-d721-463a-a517-1486ff61ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distances as proportion from spike length\n",
    "sns.heatmap(D2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001cc18c-0e38-4b7d-bebd-cf127ccdae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnumerateSpkCV(thresh2, cropped_rgb, TextSize=3,  TROE2020=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdeda05-e073-4831-b328-3a7bfd621752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d6d1910-419c-4d4b-bd20-279adcb09501",
   "metadata": {},
   "source": [
    "# Graph analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514def6f-b0ba-49f3-9e86-f7855a6c9944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/54832694/how-to-represent-a-binary-image-as-a-graph-with-the-axis-being-height-and-width\n",
    "image = blurred\n",
    "\n",
    "#Use argmax with 200 cutoff colour in one channel\n",
    "maxindex = np.argmax(image[:,:], axis=0)\n",
    "\n",
    "# Plot graph\n",
    "plt.plot(image.shape[0] - maxindex)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2989ebe-6241-4f1f-b7f8-177b92828900",
   "metadata": {
    "id": "b30fd696-0c28-43c7-a0e6-dc72d301492b"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e25ce6-00b1-4678-822f-c2856b27c24a",
   "metadata": {
    "id": "429ec9ee-ebe7-4cad-aff4-3a4e7c457e3a"
   },
   "outputs": [],
   "source": [
    "data_skel = summarize(Skeleton(skel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cbd6d3-6daa-4977-8045-57d90b26cb0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 875
    },
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1634058896512,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "77e4dc5a-1cf9-49e6-96e2-90d9a517d4d6",
    "outputId": "f7b35e7e-eba0-4398-a7cf-c45a45926235"
   },
   "outputs": [],
   "source": [
    "data_skel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406544cd-029c-4eed-b821-7facc95802ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytrax as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9b89d2-9a4e-4bd1-b9af-f05f33059bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = ~blurred\n",
    "im = np.pad(im, pad_width=50, mode='constant', constant_values=1)\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d29aa24-2385-4e1a-ad5a-63972412bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = pt.RandomWalk(image=im, seed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17778b92-9bf5-45c5-a3aa-d0885ccadc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "rw.run(nt=20000, nw=1000)\n",
    "rw.plot_walk_2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c64aee-ab9c-4120-a9d8-e1a7a52918f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rw.plot_msd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f6053-638d-482f-a7a3-cb67a6b8f65e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c306f-dddb-4357-b8f9-ed3590dcdbfe",
   "metadata": {
    "id": "f43e5447-d314-4cf2-b418-1e1f0639a79a"
   },
   "outputs": [],
   "source": [
    "pixel_graph, coordinates, degrees = skeleton_to_csgraph(skel)\n",
    "# plt.imshow(degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63858c92-f7d2-4df2-a4da-4eb08c29c872",
   "metadata": {
    "id": "cdcc98e4-13e6-49db-9cba-e4941a321292"
   },
   "source": [
    "### Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74546b75-4c89-4eef-8128-a4e2e4fce8a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1634058931448,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "ea68874e-73d0-4cfb-b1ad-ed82ff6aac57",
    "outputId": "4b91a4d2-2587-4236-b2a4-3101d2f9a6fe"
   },
   "outputs": [],
   "source": [
    "draw.overlay_euclidean_skeleton_2d(rescaled_spk, data_skel, skeleton_color_source='branch-type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd34ff25-684c-41a5-b2a4-a942120fae0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1221,
     "status": "ok",
     "timestamp": 1634058940483,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "c933784d-1b01-4550-88d2-d9911d064658",
    "outputId": "6ebecad8-11eb-4058-d25c-5f6327e2dca2"
   },
   "outputs": [],
   "source": [
    "# Histograms\n",
    "data_skel.hist(column='branch-distance', by='branch-type', bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e492c7-4f5f-47ba-9c69-fd1d9a4e58be",
   "metadata": {
    "id": "d8ded33f-e663-44de-9d75-7ff695423d99"
   },
   "source": [
    "## Medial axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595e856-6e48-4406-b17e-e3643ced7c58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "executionInfo": {
     "elapsed": 3453,
     "status": "ok",
     "timestamp": 1634307760614,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "0ff35698-c161-4556-979e-7fc277abd6e3",
    "outputId": "4470ed7b-c4dd-4d11-96ad-f5452a773221"
   },
   "outputs": [],
   "source": [
    "# Compute the medial axis (skeleton) and the distance transform\n",
    "medax, distance = medial_axis(erosion, return_distance=True)\n",
    "plt.imshow(medax)\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "dilation = cv2.dilate(np.float32(medax),(5,5),iterations = 4)\n",
    "plt.imshow(dilation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d17c455-eff4-44f3-bc39-6fc82d477ac1",
   "metadata": {
    "id": "6f02ade9-6ded-4ee3-baf6-593697959aa7"
   },
   "outputs": [],
   "source": [
    "# plt.imshow(distance)\n",
    "# distance.shape\n",
    "# np.amin(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed49e21-cff4-41ca-b8a4-987052705f9c",
   "metadata": {
    "id": "96c90e4b-1951-42c9-a193-1e794a11400c"
   },
   "outputs": [],
   "source": [
    "data_medax = summarize(Skeleton(medax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce2c846-305d-463e-b26a-9e07232bd859",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 115,
     "status": "ok",
     "timestamp": 1634058958625,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "3122d230-4951-4ef6-8b87-14a6430a3a80",
    "outputId": "8dfa1006-b80a-4970-cab5-f08286788b72"
   },
   "outputs": [],
   "source": [
    "data_medax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c7e80c-81ea-4971-b4b6-f27fc7da3d40",
   "metadata": {
    "id": "f0b6359a-d36f-4f6a-a75d-848774578ab9"
   },
   "outputs": [],
   "source": [
    "pixel_graph, coordinates, degrees = skeleton_to_csgraph(medax)\n",
    "# plt.imshow(degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc095a53-c3d9-403e-96d7-e78537509ea2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1634058969149,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "c717c656-4467-415d-b22e-2a3e30f2a180",
    "outputId": "4f961b47-64ce-4610-bee0-86443868b0d5"
   },
   "outputs": [],
   "source": [
    " draw.overlay_euclidean_skeleton_2d(rescaled_spk, data_medax, skeleton_color_source='branch-type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b384b330-53b6-4a5f-92ad-882a772988cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1150,
     "status": "ok",
     "timestamp": 1634059000631,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "1a0fbe11-f793-4118-aed9-db460278967b",
    "outputId": "6e8a688a-f2e1-47c1-8aee-cf1837810dea"
   },
   "outputs": [],
   "source": [
    "# Histograms\n",
    "data_medax.hist(column='branch-distance', by='branch-type', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e368fbeb-253e-4bd4-9b13-03fe5568be15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9760bfc2-0076-48d6-bc53-9dc3e18a6f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97c54995-6305-4504-ac78-f87ffccee02d",
   "metadata": {
    "id": "97c54995-6305-4504-ac78-f87ffccee02d"
   },
   "source": [
    "# Detecting Spikelets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e663cd-5b76-488c-8c3a-5712f061b7ee",
   "metadata": {
    "id": "18e663cd-5b76-488c-8c3a-5712f061b7ee"
   },
   "source": [
    "## Select a spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e6c102-a0a2-442e-a837-e001607e9604",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "executionInfo": {
     "elapsed": 2129,
     "status": "ok",
     "timestamp": 1634182092592,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "39e6c102-a0a2-442e-a837-e001607e9604",
    "outputId": "9dcd848d-3e61-4899-d153-9a407c33ffe7"
   },
   "outputs": [],
   "source": [
    "plt.imshow(cropped_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ER2K2rju2L3q",
   "metadata": {
    "id": "ER2K2rju2L3q",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def nSpklts(cropped_rgb, labeled_out=False):\n",
    "    \n",
    "    # Rescale to 10% of original\n",
    "    rescaled_spk = rescale(cropped_rgb[...], 0.1, preserve_range=False, multichannel=True, anti_aliasing=True)\n",
    "    # plt.imshow(rescaled_spk)\n",
    "\n",
    "    # Erosion\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "    erosion = cv2.erode(rescaled_spk,kernel,iterations = 1)\n",
    "    # plt.imshow(erosion)\n",
    "\n",
    "    # Opening\n",
    "    kernel = np.ones((1,1),np.uint8)\n",
    "    opening = cv2.morphologyEx(erosion, cv2.MORPH_OPEN, kernel, iterations = 10)\n",
    "    # plt.imshow(opening)\n",
    "\n",
    "    # Resize\n",
    "    rescaled_spk2 = Image.fromarray((rescaled_spk * 255).astype(np.uint8))\n",
    "    rescaled_spk2 = rescaled_spk2.resize((cropped_rgb.shape[1],cropped_rgb.shape[0]))\n",
    "    # plt.imshow(rescaled_spk2)\n",
    "    # rescaled_spk2.size\n",
    "    opening = np.asarray(rescaled_spk2)\n",
    "\n",
    "    # Convert rgb to gray\n",
    "    gray_spklts = opening @ [0.2126, 0.7152, 0.0722]\n",
    "    # plt.imshow(gray_spklts)\n",
    "\n",
    "    # Binarize gray\n",
    "    bw_spklts = gray_spklts > 0\n",
    "    # plt.imshow(bw_spklts)\n",
    "\n",
    "    # Get distances\n",
    "    distance = ndi.distance_transform_edt(bw_spklts)\n",
    "    # plt.imshow(-distance)\n",
    "\n",
    "    # Get max peaks\n",
    "    coords = peak_local_max(distance, min_distance=50, labels=bw_spklts)\n",
    "    # plt.imshow(coords)\n",
    "\n",
    "    mask = np.zeros(distance.shape, dtype=bool)\n",
    "    mask[tuple(coords.T)] = True\n",
    "    markers, spikelets = ndi.label(mask)\n",
    "    # markers, spikelets = label(mask, return_num = True)\n",
    "    # markers64 = np.int64(markers)\n",
    "\n",
    "    if labeled_out==True:\n",
    "        # Watershed\n",
    "        labels = watershed(-distance, markers, mask=cropped_spk)\n",
    "\n",
    "        # Detected spikelets\n",
    "        print('Detected spikelets = ', spikelets)\n",
    "\n",
    "        # Plot\n",
    "        plt.imshow(labels, cmap=plt.cm.nipy_spectral)\n",
    "\n",
    "    else:\n",
    "        return spikelets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Nc714GCy0-Qs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "executionInfo": {
     "elapsed": 4038,
     "status": "ok",
     "timestamp": 1634182256594,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "Nc714GCy0-Qs",
    "outputId": "8feab406-06e8-4dcc-c6ad-b4248194c185"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nSpklts(cropped_rgb, labeled_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ba391-75c3-4fce-ad87-82735b796734",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685
    },
    "executionInfo": {
     "elapsed": 1899,
     "status": "ok",
     "timestamp": 1634175565577,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "9b6ba391-75c3-4fce-ad87-82735b796734",
    "outputId": "8a93f8c2-0d4b-4976-d03c-8b125df8c41c"
   },
   "outputs": [],
   "source": [
    "rescaled_spk = rescale(cropped_rgb[...], 0.1, preserve_range=False, multichannel=True, anti_aliasing=True)\n",
    "plt.imshow(rescaled_spk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wqSdEey6wbjT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 147,
     "status": "ok",
     "timestamp": 1634165224001,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "wqSdEey6wbjT",
    "outputId": "400d43d5-89db-4057-c93b-3d988e20b66a"
   },
   "outputs": [],
   "source": [
    "# cropped_rgb.shape\n",
    "# rescaled_spk2 = rescale(rescaled_spk[...], 9, preserve_range=False, multichannel=True, anti_aliasing=True)\n",
    "# rescaled_spk2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ffcce2-3f86-4370-be9b-8ecee3441e83",
   "metadata": {
    "id": "50ffcce2-3f86-4370-be9b-8ecee3441e83"
   },
   "source": [
    "## Apply a Gaussian blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902f3fa1-f4d4-4687-83a9-1493e6eb7fa8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685
    },
    "executionInfo": {
     "elapsed": 963,
     "status": "ok",
     "timestamp": 1634176062028,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "902f3fa1-f4d4-4687-83a9-1493e6eb7fa8",
    "outputId": "877e956b-2762-4d92-f1bf-a28195e61ba9"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# kernel = np.ones((5,5),np.uint8)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "erosion = cv2.erode(rescaled_spk,kernel,iterations = 1)\n",
    "# plt.imshow(erosion)\n",
    "\n",
    "kernel = np.ones((1,1),np.uint8)\n",
    "opening = cv2.morphologyEx(erosion, cv2.MORPH_OPEN, kernel, iterations = 10)\n",
    "plt.imshow(opening)\n",
    "\n",
    "# blur = cv2.blur(np.float32(cropped_spk),(10,10))\n",
    "# blur = cv2.blur(erosion,(30,30))   # With RGB\n",
    "# plt.imshow(blur)\n",
    "\n",
    "# kernel = np.ones((7,7),np.uint8)\n",
    "# dilation = cv2.dilate(erosion,kernel,iterations = 2)\n",
    "# plt.imshow(dilation)\n",
    "\n",
    "# medfil = cv2.medianBlur(np.uint8(erosion), 5)\n",
    "# plt.imshow(medfil)\n",
    "\n",
    "# kernel = np.ones((10,10),np.uint8)\n",
    "# closing = cv2.morphologyEx(erosion, cv2.MORPH_CLOSE, kernel)\n",
    "# plt.imshow(closing)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# blur = cv2.blur(erosion,(10,10))   # With RGB\n",
    "# plt.imshow(blur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a4e2e8-6375-4565-9843-6583123be18b",
   "metadata": {
    "id": "c5a4e2e8-6375-4565-9843-6583123be18b"
   },
   "source": [
    "## Get distances and local peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z-Q1FaQy7f1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "executionInfo": {
     "elapsed": 1915,
     "status": "ok",
     "timestamp": 1634176108768,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "z-Q1FaQy7f1c",
    "outputId": "3c0baec2-6f14-4657-c5c4-ff3e00e0af78"
   },
   "outputs": [],
   "source": [
    "# Resize\n",
    "rescaled_spk2 = Image.fromarray((rescaled_spk * 255).astype(np.uint8))\n",
    "rescaled_spk2 = rescaled_spk2.resize((cropped_rgb.shape[1],cropped_rgb.shape[0]))\n",
    "# rescaled_spk2 = np.asarray(rescaled_spk2)\n",
    "plt.imshow(rescaled_spk2)\n",
    "rescaled_spk2.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae9994-3bd8-409e-b456-054495b6b5e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1771,
     "status": "ok",
     "timestamp": 1634176669423,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "5bae9994-3bd8-409e-b456-054495b6b5e6",
    "outputId": "4b292e7a-c23b-411f-e66a-a0befd13fb98"
   },
   "outputs": [],
   "source": [
    "opening = np.asarray(rescaled_spk2)\n",
    "# Convert rgb to gray\n",
    "gray_spklts = opening @ [0.2126, 0.7152, 0.0722]\n",
    "# plt.imshow(gray_spklts)\n",
    "\n",
    "# Binarize gray\n",
    "bw_spklts = gray_spklts > 0\n",
    "# plt.imshow(bw_spklts)\n",
    "\n",
    "# Get distances\n",
    "distance = ndi.distance_transform_edt(bw_spklts)\n",
    "# plt.imshow(-distance)\n",
    "\n",
    "# Get max peaks\n",
    "coords = peak_local_max(distance, min_distance=50, labels=bw_spklts)\n",
    "# plt.imshow(coords)\n",
    "\n",
    "mask = np.zeros(distance.shape, dtype=bool)\n",
    "mask[tuple(coords.T)] = True\n",
    "markers, spikelets = ndi.label(mask)\n",
    "# markers, spikelets = label(mask, return_num = True)\n",
    "# markers64 = np.int64(markers)\n",
    "\n",
    "# Watershed\n",
    "labels = watershed(-distance, markers, mask=cropped_spk)\n",
    "\n",
    "# Detected spikelets\n",
    "print('Detected spikelets = ', spikelets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b504c8-3e45-43a6-aba6-cd1b2c47a319",
   "metadata": {
    "id": "c9b504c8-3e45-43a6-aba6-cd1b2c47a319"
   },
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df1583f-a2b7-49bc-9fa1-ff8ae4bec2ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "executionInfo": {
     "elapsed": 3652,
     "status": "ok",
     "timestamp": 1634176677967,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "1df1583f-a2b7-49bc-9fa1-ff8ae4bec2ba",
    "outputId": "907367a7-a4c7-42e9-9673-89241b0545e1"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize=(9, 3), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(cropped_spk, cmap=plt.cm.gray)\n",
    "ax[0].set_title('Overlapping objects')\n",
    "ax[1].imshow(-np.float32(distance), cmap=plt.cm.gray)\n",
    "ax[1].set_title('Distances')\n",
    "ax[2].imshow(labels, cmap=plt.cm.nipy_spectral)\n",
    "ax[2].set_title('Separated objects')\n",
    "\n",
    "for a in ax:\n",
    "    a.set_axis_off()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2252802a-4c6d-4fc9-bfca-a4c990ddc2d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "executionInfo": {
     "elapsed": 1563,
     "status": "ok",
     "timestamp": 1634153164055,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "2252802a-4c6d-4fc9-bfca-a4c990ddc2d8",
    "outputId": "a08cea1a-20e2-4770-c589-a0216456866a"
   },
   "outputs": [],
   "source": [
    "plt.imshow(labels==4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00451a7-2c3f-478e-81b9-7b02e93219f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 149,
     "status": "ok",
     "timestamp": 1634177389462,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "c00451a7-2c3f-478e-81b9-7b02e93219f7",
    "outputId": "5ab8b48e-fa6a-4d7b-f05b-04a2b4dd9d95"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Regionprops\n",
    "labeled_spklts = np.int64(labels)\n",
    "props_spklts = regionprops(labels)\n",
    "\n",
    "# labeled_spks, num_spikes = label(bw1, return_num = True)\n",
    "# props_spikes = regionprops(labeled_spks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YrFIc08by-sA",
   "metadata": {
    "id": "YrFIc08by-sA"
   },
   "outputs": [],
   "source": [
    "spklt = labels==6\n",
    "rgb_spklt = np.where(spklt[..., None], cropped_rgb, 0)\n",
    "# plt.imshow(rgb_spklt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DDkFJ5t4y-jh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 693
    },
    "executionInfo": {
     "elapsed": 3969,
     "status": "ok",
     "timestamp": 1634177306311,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "DDkFJ5t4y-jh",
    "outputId": "aecf9c98-3afe-43b0-9f9e-907a6f946d3c"
   },
   "outputs": [],
   "source": [
    "# Spikeletes Lab values\n",
    "cropped_lab = color.rgb2lab(cropped_rgb)\n",
    "plt.imshow(cropped_lab)\n",
    "# plt.imshow(labeled_spklts, cmap='gray')\n",
    "# labeled_spklts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EpmNEsCZ7bJJ",
   "metadata": {
    "id": "EpmNEsCZ7bJJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2DWkZE42y-Yv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1181,
     "status": "ok",
     "timestamp": 1634178016576,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "2DWkZE42y-Yv",
    "outputId": "354121e7-b5be-4626-9d73-312708dc2d5f"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# # Create column with image name\n",
    "Image_Name = Images[0].split('\\\\')[-1]\n",
    "Image_Name = [Image_Name] * spikelets\n",
    "\n",
    "# Geometric properties\n",
    "Labels = [rp.label for rp in props_spklts]\n",
    "Areas = [rp.area for rp in props_spklts]\n",
    "MajorAxes = [rp.major_axis_length for rp in props_spklts]\n",
    "MinorAxes = [rp.minor_axis_length for rp in props_spklts]\n",
    "Orientations = [rp.orientation for rp in props_spklts]\n",
    "Perimeters = [rp.perimeter for rp in props_spklts]\n",
    "Eccentricities = [rp.eccentricity for rp in props_spklts]\n",
    "\n",
    "# Spectral properties\n",
    "red_props = regionprops(labeled_spklts, intensity_image=cropped_rgb[:,:,0])\n",
    "green_props = regionprops(labeled_spklts, intensity_image=cropped_rgb[:,:,1])\n",
    "blue_props = regionprops(labeled_spklts, intensity_image=cropped_rgb[:,:,2])\n",
    "L_props = regionprops(labeled_spklts, intensity_image=cropped_lab[:,:,0])\n",
    "a_props = regionprops(labeled_spklts, intensity_image=cropped_lab[:,:,1])\n",
    "b_props = regionprops(labeled_spklts, intensity_image=cropped_lab[:,:,2])\n",
    "\n",
    "red = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in red_props])\n",
    "green = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in green_props])\n",
    "blue = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in blue_props])\n",
    "L = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in L_props])\n",
    "a = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in a_props])\n",
    "b = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in b_props])\n",
    "\n",
    "Red_Perc = np.array(channel_percentiles(red_props, Negatives=False)).T\n",
    "Green_Perc = np.array(channel_percentiles(green_props, Negatives=False)).T\n",
    "Blue_Perc = np.array(channel_percentiles(blue_props, Negatives=False)).T\n",
    "L_Perc = np.array(channel_percentiles(L_props)).T\n",
    "a_Perc = np.array(channel_percentiles(a_props, Negatives=True)).T\n",
    "b_Perc = np.array(channel_percentiles(b_props, Negatives=True)).T\n",
    "\n",
    "# Dataframe 1: for single obervation per spike\n",
    "Spikes_per_image = pd.DataFrame(\n",
    "list(zip(Image_Name, Labels, Areas, MajorAxes, MinorAxes, Orientations, Eccentricities, Perimeters, \n",
    "red[:,0], red[:,1], red[:,2], green[:,0], green[:,1], green[:,2], blue[:,0], blue[:,1], blue[:,2], \n",
    "L[:,0], L[:,1], L[:,2], a[:,0], a[:,1], a[:,2], b[:,0], b[:,1], b[:,2], \n",
    "Red_Perc[:,0], Red_Perc[:,1], Red_Perc[:,2], Red_Perc[:,3], Red_Perc[:,4], Red_Perc[:,5], Red_Perc[:,6], \n",
    "Green_Perc[:,0], Green_Perc[:,1], Green_Perc[:,2], Green_Perc[:,3], Green_Perc[:,4], Green_Perc[:,5], Green_Perc[:,6], \n",
    "Blue_Perc[:,0], Blue_Perc[:,1], Blue_Perc[:,2], Blue_Perc[:,3], Blue_Perc[:,4], Blue_Perc[:,5], Blue_Perc[:,6], \n",
    "L_Perc[:,0], L_Perc[:,1], L_Perc[:,2], L_Perc[:,3], L_Perc[:,4], L_Perc[:,5], L_Perc[:,6], \n",
    "a_Perc[:,0], a_Perc[:,1], a_Perc[:,2], a_Perc[:,3], a_Perc[:,4], a_Perc[:,5], a_Perc[:,6], \n",
    "a_Perc[:,7], a_Perc[:,8], a_Perc[:,9], a_Perc[:,10], a_Perc[:,11], a_Perc[:,12], a_Perc[:,13], \n",
    "b_Perc[:,0], b_Perc[:,1], b_Perc[:,2], b_Perc[:,3], b_Perc[:,4], b_Perc[:,5], b_Perc[:,6], \n",
    "b_Perc[:,7], b_Perc[:,8], b_Perc[:,9], b_Perc[:,10], b_Perc[:,11], b_Perc[:,12], b_Perc[:,13])), \n",
    "columns = ['Image_Name', 'Spike_Label', 'Area', 'MajorAxis', 'MinorAxes', 'Orientation', 'Eccentricity', 'Perimeter', \n",
    "  'Red_mean', 'Red_min', 'Red_max', 'Green_mean', 'Green_min', 'Green_max', 'Blue_mean', 'Blue_min', 'Blue_max', \n",
    "  'L_mean', 'L_min', 'L_max', 'a_mean', 'a_min', 'a_max', 'b_mean', 'b_min', 'b_max', \n",
    "  'Red_p25', 'Red_p50', 'Red_p75', 'Red_Mean', 'Red_sd', 'Red_Min', 'Red_Max', \n",
    "  'Green_p25', 'Green_p50', 'Green_p75', 'Green_Mean', 'Green_sd', 'Green_Min', 'Green_Max', \n",
    "  'Blue_p25', 'Blue_p50', 'Blue_p75', 'Blue_Mean', 'Blue_sd', 'Blue_Min', 'Blue_Max', \n",
    "  'L_p25', 'L_p50', 'L_p75', 'L_Mean', 'L_sd', 'L_Min', 'L_Max', \n",
    "  'a_p25_pos', 'a_p50_pos', 'a_p75_pos', 'a_Mean_pos', 'a_sd_pos', 'a_Min_pos', 'a_Max_pos', \n",
    "  'a_p25_neg', 'a_p50_neg', 'a_p75_neg', 'a_Mean_neg', 'a_sd_neg', 'a_Min_neg', 'a_Max_neg', \n",
    "  'b_p25_pos', 'b_p50_pos', 'b_p75_pos', 'b_Mean_pos', 'b_sd_pos', 'b_Min_pos', 'b_Max_pos', \n",
    "  'b_p25_neg', 'b_p50_neg', 'b_p75_neg', 'b_Mean_neg', 'b_sd_neg', 'b_Min_neg', 'b_Max_neg'])\n",
    "\n",
    "Spikes_per_image['Circularity'] = (4 * np.pi * Spikes_per_image['Area']) / (Spikes_per_image['Perimeter'] ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kmM6qOG9Jzg-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1634153845877,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "kmM6qOG9Jzg-",
    "outputId": "326b20a7-79b1-42f0-b16f-fc05e2c538af"
   },
   "outputs": [],
   "source": [
    "plt.imshow(labeled_spklts)\n",
    "plt.imshow(labeled_spks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MbTG0YC2kav2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "executionInfo": {
     "elapsed": 146,
     "status": "ok",
     "timestamp": 1634154544586,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "MbTG0YC2kav2",
    "outputId": "a8ace8ff-326b-4dea-eb9b-373e55c1d5e1"
   },
   "outputs": [],
   "source": [
    "# import csv\n",
    "# labeled_spklts.to_csv('/content/drive/MyDrive/M.Sc/THESIS/ImageAnalysis/SpikeProperties/Spyk_Prop/redprops.csv')\n",
    "# pwd\n",
    "pd.DataFrame(green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xVp9Onu4yd-H",
   "metadata": {
    "id": "xVp9Onu4yd-H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c44f5820-d00c-4de4-85fc-e960dd558492",
   "metadata": {
    "id": "c44f5820-d00c-4de4-85fc-e960dd558492"
   },
   "source": [
    "# Ridge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe86c4-0b41-456c-b685-907410f8f3fc",
   "metadata": {
    "id": "eefe86c4-0b41-456c-b685-907410f8f3fc",
    "outputId": "c30fbe04-f686-4af7-a107-d53ecc268bfb"
   },
   "outputs": [],
   "source": [
    "# Crop spike\n",
    "slice_x, slice_y = ndimage.find_objects(spk)[0]\n",
    "cropped_spk = spk[slice_x, slice_y]\n",
    "cropped_rgb = img0[slice_x, slice_y]\n",
    "cropped_rgb = np.where(cropped_spk[..., None], cropped_rgb, 0)\n",
    "cropped_gray = cropped_rgb @ [0.2126, 0.7152, 0.0722]\n",
    "plt.imshow(cropped_rgb)\n",
    "# plt.imshow(cropped_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afc7b5a-00bd-4c99-a4b0-46068939bc36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 693
    },
    "executionInfo": {
     "elapsed": 1836,
     "status": "ok",
     "timestamp": 1634144519470,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "6afc7b5a-00bd-4c99-a4b0-46068939bc36",
    "outputId": "14cf28fa-369f-4817-b04c-64f03a1ae3c9"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "blur = cv2.blur(cropped_rgb,(70,70))\n",
    "# Threshold the blur\n",
    "# thrb = blur > 0.2\n",
    "# skeleton = skeletonize(thrb)\n",
    "\n",
    "plt.imshow(blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf6f2eb-a02d-4dd7-b576-71563288e8ee",
   "metadata": {
    "id": "8bf6f2eb-a02d-4dd7-b576-71563288e8ee",
    "outputId": "d5b45367-2a26-4879-e433-c35f5fbc522f"
   },
   "outputs": [],
   "source": [
    "blur2 = cv2.blur(cropped_spk.astype(np.uint8),(40,40))\n",
    "# blur = cv2.blur(cropped_rgb,(50,50))   # With RGB\n",
    "plt.imshow(blur2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d8974-7dba-4e1a-b661-871ec4c53373",
   "metadata": {
    "id": "ed0d8974-7dba-4e1a-b661-871ec4c53373"
   },
   "outputs": [],
   "source": [
    "from skimage.filters import meijering, sato, frangi, hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb6797a-8d64-445c-b75d-23445748a5bc",
   "metadata": {
    "id": "0cb6797a-8d64-445c-b75d-23445748a5bc",
    "outputId": "abb3b90e-7ee4-4d2f-8632-2c29bf71c123"
   },
   "outputs": [],
   "source": [
    "gray_cropped = cropped_rgb @ [0.2126, 0.7152, 0.0722]\n",
    "plt.imshow(gray_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f9f3d-c91b-4c3b-a96e-fe396d2ab93a",
   "metadata": {
    "id": "448f9f3d-c91b-4c3b-a96e-fe396d2ab93a",
    "outputId": "6efad520-2ed9-4f8e-d85c-1102cbc71462"
   },
   "outputs": [],
   "source": [
    "blur2 = cv2.blur(np.float32(gray_cropped),(30,30))\n",
    "# blur = cv2.blur(cropped_rgb,(50,50))   # With RGB\n",
    "plt.imshow(blur2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84636ed5-333c-4e53-8eed-28686bef4b27",
   "metadata": {
    "id": "84636ed5-333c-4e53-8eed-28686bef4b27"
   },
   "source": [
    "### Meijering\n",
    "https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.meijering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c667d-1477-4361-824e-bcb7a73258d5",
   "metadata": {
    "id": "ff2c667d-1477-4361-824e-bcb7a73258d5",
    "outputId": "5ecc808c-28f4-4919-f175-318eb537b22a"
   },
   "outputs": [],
   "source": [
    "image = blur2\n",
    "mei = meijering(image, sigmas=range(1, 10, 2), alpha=None, black_ridges=False, mode='reflect', cval=0)\n",
    "plt.imshow(mei)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7c1e2-4f67-461d-829f-190c75ab850c",
   "metadata": {
    "id": "a6f7c1e2-4f67-461d-829f-190c75ab850c",
    "outputId": "424fbbea-6e6d-42c6-802e-e522267c31d7"
   },
   "outputs": [],
   "source": [
    "image = mei > 0.2\n",
    "skeleton = skeletonize(image)\n",
    "plt.imshow(skeleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56270466-2f73-42b9-9f81-d81ca62447c4",
   "metadata": {
    "id": "56270466-2f73-42b9-9f81-d81ca62447c4"
   },
   "source": [
    "### Sato\n",
    "https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.sato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15979233-02d9-45a2-8813-5823d2f8635a",
   "metadata": {
    "id": "15979233-02d9-45a2-8813-5823d2f8635a",
    "outputId": "3392c52d-c01a-4c7b-9b2f-ae07545e0b59"
   },
   "outputs": [],
   "source": [
    "sat = sato(image, sigmas=range(1, 10, 2), black_ridges=False, mode='reflect', cval=0)\n",
    "plt.imshow(sat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a92de-4dc7-4881-9f8b-7482ec5d43c3",
   "metadata": {
    "id": "b98a92de-4dc7-4881-9f8b-7482ec5d43c3",
    "outputId": "2aa8e85d-a972-4e30-9383-3e67ca0953fd"
   },
   "outputs": [],
   "source": [
    "image = sat > 0.25\n",
    "skeleton = skeletonize(image)\n",
    "plt.imshow(skeleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88d716c-beb7-4f95-bfeb-268cc67a0b9c",
   "metadata": {
    "id": "c88d716c-beb7-4f95-bfeb-268cc67a0b9c"
   },
   "source": [
    "### Frangi\n",
    "https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.frangi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02ffa69-5083-4a60-9377-5518f48df7bd",
   "metadata": {
    "id": "c02ffa69-5083-4a60-9377-5518f48df7bd",
    "outputId": "39eb1033-fd65-42e5-8f31-743ec957b3fd"
   },
   "outputs": [],
   "source": [
    "fra =frangi(image, sigmas=range(0, 10, 2), scale_range=None, scale_step=None, black_ridges=False, mode='constant', cval=0)\n",
    "plt.imshow(fra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9fb421-1cb9-49dc-86f1-03ffc9c18e22",
   "metadata": {
    "id": "da9fb421-1cb9-49dc-86f1-03ffc9c18e22",
    "outputId": "934c9fdc-2c20-43d1-c1c4-45ca99b4663a"
   },
   "outputs": [],
   "source": [
    "image = fra>0\n",
    "skeleton = skeletonize(image)\n",
    "plt.imshow(skeleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be8099-9e4a-4614-9e4f-c805cb126462",
   "metadata": {
    "id": "76be8099-9e4a-4614-9e4f-c805cb126462"
   },
   "source": [
    "### Hessian\n",
    "https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4248cd08-92c5-45c9-96c0-c57dc4bab826",
   "metadata": {
    "id": "4248cd08-92c5-45c9-96c0-c57dc4bab826",
    "outputId": "fc11ccc8-8a1b-4447-9f57-5f12b52775df"
   },
   "outputs": [],
   "source": [
    "hes = hessian(image, sigmas=range(1, 10, 2), scale_range=None, scale_step=None, alpha=0.5, beta=0.5, gamma=15, black_ridges=True, mode='reflect', cval=0)\n",
    "plt.imshow(hes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1802c942-b405-44ba-a006-c797c640f76c",
   "metadata": {
    "id": "1802c942-b405-44ba-a006-c797c640f76c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40bad93-64fa-4f7c-9a92-e70772945f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram equalization\n",
    "rescaled_spk3 = exposure.equalize_hist(rescaled_spk2)\n",
    "# plt.imshow(rescaled_spk3)\n",
    "\n",
    "# median = cv2.medianBlur(rescaled_spk2, 3)\n",
    "# plt.imshow(median)\n",
    "blurred = filters.gaussian(rescaled_spk3, sigma=1, preserve_range=True)\n",
    "blurred = exposure.equalize_adapthist(blurred)\n",
    "# blurred = cv2.medianBlur(np.float32(blurred), 1)\n",
    "\n",
    "blurred = cv2.normalize(blurred, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "blurred = blurred.astype(np.uint8)\n",
    "# plt.imshow(bw)\n",
    "\n",
    "\n",
    "plt.imshow(blurred)\n",
    "# norm_image=blurred\n",
    "\n",
    "# closing = cv2.morphologyEx(rescaled_spk3, cv2.MORPH_OPEN, (1,1), iterations = 10)\n",
    "# plt.imshow(closing)\n",
    "\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(1,1))\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "# bw = cv2.morphologyEx(norm_image, cv2.MORPH_GRADIENT, (3,3), iterations = 3)\n",
    "# bw = cv2.morphologyEx(norm_image, cv2.MORPH_BLACKHAT, (1,1), iterations = 5)\n",
    "# bw = cv2.morphologyEx(norm_image, cv2.MORPH_TOPHAT, (3,3), iterations = 10)\n",
    "# bw = cv2.morphologyEx(norm_image, cv2.MORPH_OPEN, (3,3), iterations = 10)\n",
    "# bw = cv2.morphologyEx(norm_image, cv2.MORPH_CLOSE, (3,3), iterations = 5)\n",
    "# bw = cv2.morphologyEx(norm_image, cv2.MORPH_DILATE, (3,3), iterations = 1)\n",
    "# bw = cv2.morphologyEx(norm_image, cv2.MORPH_ERODE, kernel, iterations = 1)\n",
    "\n",
    "# bw = cv2.morphologyEx(norm_image, cv2.MORPH_TOPHAT, (3,3), iterations = 10)\n",
    "\n",
    "# blurred = filters.gaussian(blurred, sigma=0.5)\n",
    "\n",
    "# plt.imshow(median)\n",
    "\n",
    "# bw = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, (3,3), iterations = 5)\n",
    "\n",
    "# bw = exposure.equalize_adapthist(bw)\n",
    "# plt.imshow(rescaled_spk3)\n",
    "# bw = cv2.normalize(bw, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "# bw = bw.astype(np.uint8)\n",
    "# plt.imshow(bw)\n",
    "\n",
    "# plt.imshow(blurred)\n",
    "# np.min(bw)\n",
    "# median = cv2.medianBlur(rescaled_spk2, 3)\n",
    "# plt.imshow(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fdde33-b4fc-497d-9d3e-72cc33943deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histrogram\n",
    "np.median(blurred)\n",
    "histogram, bin_edges = np.histogram(blurred)\n",
    "plt.plot(bin_edges[0:-1], histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a858a78-efa8-4f0a-a4f2-e266f5973e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_filter = cv2.ximgproc.RidgeDetectionFilter_create(dx=1, dy=1, ksize = 7)\n",
    "ridges = ridge_filter.getRidgeFilteredImage(np.float32(blurred))\n",
    "plt.imshow(ridges)\n",
    "\n",
    "# Morphological operations with OpenCV\n",
    "# https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html\n",
    "\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(5,5))\n",
    "# gradient = cv2.morphologyEx(rescaled_spk2, cv2.MORPH_GRADIENT, kernel)\n",
    "# plt.imshow(gradient)\n",
    "\n",
    "# edges = cv2.Canny(cropped_rgb, 30, 100)\n",
    "# plt.imshow(edges)\n",
    "\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "# opening = cv2.morphologyEx(ridges, cv2.MORPH_BLACKHAT, kernel, iterations = 5)\n",
    "# # plt.imshow(opening)\n",
    "\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "# closing = cv2.morphologyEx(ridges, cv2.MORPH_OPEN, (3,3), iterations = 3)\n",
    "# plt.imshow(closing)\n",
    "\n",
    "# # kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "# erode = cv2.morphologyEx(closing, cv2.MORPH_ERODE, kernel, iterations = 1)\n",
    "# plt.imshow(erode)\n",
    "\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(5,5))\n",
    "# erosion = cv2.erode(opening,kernel,iterations = 1)\n",
    "# # plt.imshow(erosion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30dc6fa-d930-439f-ba4d-03da2fc1d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fra=frangi(blurred, black_ridges=False, mode='constant')\n",
    "# plt.imshow(fra)\n",
    "\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "# erosion = cv2.erode(fra,kernel,iterations = 5)\n",
    "# plt.imshow(erosion)\n",
    "\n",
    "hyst = filters.scharr_h(blurred)\n",
    "plt.imshow(hyst)\n",
    "\n",
    "# median = cv2.medianBlur(np.uint8(hyst>0), 9)\n",
    "# # plt.imshow(median)\n",
    "\n",
    "# thinned = medial_axis(rescaled_spk2[:,:,0]>0)\n",
    "# plt.imshow(thinned)\n",
    "\n",
    "# medax= medial_axis(thinned)\n",
    "# plt.imshow(medax)\n",
    "\n",
    "\n",
    "# median2 = cv2.medianBlur(median, 3)\n",
    "# # plt.imshow(median2)\n",
    "\n",
    "# median3 = cv2.medianBlur(median2, 3)\n",
    "# plt.imshow(median3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1753f2-b09e-48a5-84c9-56d0640b9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# median = cv2.medianBlur(rescaled_spk2, 3)\n",
    "# plt.imshow(median)\n",
    "\n",
    "# ret, thresh = cv2.threshold(median, 0, 255, cv2.THRESH_BINARY)\n",
    "# plt.imshow(thresh)\n",
    "\n",
    "# contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "# Find contours at a constant value of 0.8\n",
    "contours = measure.find_contours(blurred,255*0.8)\n",
    "\n",
    "# Display the image and plot all contours found\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(blurred, cmap=plt.cm.gray)\n",
    "\n",
    "for contour in contours:\n",
    "    ax.plot(contour[:, 1], contour[:, 0], linewidth=1)\n",
    "\n",
    "ax.axis('image')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.show()\n",
    "\n",
    "len(contours)\n",
    "\n",
    "# # create an empty black image\n",
    "# drawing = np.zeros((thresh.shape[0], thresh.shape[1], 3), np.uint8)\n",
    "\n",
    "# # draw contours and hull points\n",
    "# for i in range(len(contours)):\n",
    "#     color_contours = (0, 255, 0) # green - color for contours\n",
    "#     color = (255, 0, 0) # blue - color for convex hull\n",
    "#     # draw ith contour\n",
    "#     plt.drawContours(drawing, contours, i, color_contours, 1, 8, hierarchy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4eb7ee-cda4-4931-882e-ef3a2f2503d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Resize\n",
    "# im = Image.fromarray((cropped_gray).astype(np.uint8))\n",
    "# (width, height) = (im.width // 30, im.height // 30)\n",
    "# blurred2 = blurred.resize((im.width, im.height))\n",
    "# blurred2 = np.asarray(blurred2)\n",
    "# plt.imshow(blurred2)\n",
    "# (width, height) = (im.width, im.height)\n",
    "# rescaled_spk2 = rescaled_spk2.resize((width, height))\n",
    "\n",
    "# rescaled_spk2 = np.asarray(rescaled_spk2)\n",
    "\n",
    "skel = skeletonize(blurred>200)\n",
    "plt.imshow(skel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f4860e-d6ce-46ef-86ac-2aa4604a15e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c542ae-043c-4d18-b484-aa534374f0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42675d33-7a21-45f6-97e9-729f36c77896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a807d-9456-402b-9113-7c6ac583a166",
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f84829c-bc6a-45da-bb5c-35b6e6a182e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# blur = cv2.blur(rescaled_spk2,(10,10))\n",
    "# # blur = cv2.blur(erosion,(30,30))   # With RGB\n",
    "# plt.imshow(blur)\n",
    "\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(rescaled_spk2, cv2.MORPH_OPEN, kernel, iterations = 1)\n",
    "# plt.imshow(opening)\n",
    "\n",
    "median = cv2.medianBlur(opening, 3)\n",
    "plt.imshow(median)\n",
    "\n",
    "# kernel = np.ones((3,3),np.uint8)\n",
    "# closing = cv2.morphologyEx(opening, cv2.MORPH_ERODE, kernel, iterations = 1)\n",
    "# plt.imshow(closing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd9eaad-ea31-47b2-9d62-9eba5198b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "median2 = exposure.equalize_hist(median)\n",
    "plt.imshow(median2)\n",
    "# plt.imshow(color.rgb2gray(median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd69a12-d507-40cf-a80b-8f8ce26ed044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.draw import line\n",
    "\n",
    "# Constructing test image\n",
    "image = np.zeros((200, 200))\n",
    "idx = np.arange(25, 175)\n",
    "image[idx, idx] = 255\n",
    "image[line(45, 25, 25, 175)] = 255\n",
    "image[line(25, 135, 175, 155)] = 255\n",
    "\n",
    "# Classic straight-line Hough transform\n",
    "# Set a precision of 0.5 degree.\n",
    "tested_angles = np.linspace(-np.pi / 2, np.pi / 2, 360, endpoint=False)\n",
    "h, theta, d = hough_line(image)\n",
    "\n",
    "# Generating figure 1\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title('Input image')\n",
    "ax[0].set_axis_off()\n",
    "\n",
    "angle_step = 0.5 * np.diff(theta).mean()\n",
    "d_step = 0.5 * np.diff(d).mean()\n",
    "bounds = [np.rad2deg(theta[0] - angle_step),\n",
    "          np.rad2deg(theta[-1] + angle_step),\n",
    "          d[-1] + d_step, d[0] - d_step]\n",
    "ax[1].imshow(np.log(1 + h), extent=bounds, aspect=1 / 1.5)\n",
    "ax[1].set_title('Hough transform')\n",
    "ax[1].set_xlabel('Angles (degrees)')\n",
    "ax[1].set_ylabel('Distance (pixels)')\n",
    "ax[1].axis('image')\n",
    "\n",
    "ax[2].imshow(image)\n",
    "ax[2].set_ylim((image.shape[0], 0))\n",
    "ax[2].set_axis_off()\n",
    "ax[2].set_title('Detected lines')\n",
    "\n",
    "for _, angle, dist in zip(*hough_line_peaks(h, theta, d)):\n",
    "    (x0, y0) = dist * np.array([np.cos(angle), np.sin(angle)])\n",
    "    ax[2].axline((x0, y0), slope=np.tan(angle + np.pi/2))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aef4b3-0a23-486f-b7cf-212975127e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, theta, d = hough_line_peaks(h, theta, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cd8095-6ca5-44dc-b550-0c34ebfbb699",
   "metadata": {},
   "outputs": [],
   "source": [
    "medax= medial_axis(cropped_gray)\n",
    "# plt.imshow(medax)\n",
    "\n",
    "tested_angles = np.linspace(-np.pi, np.pi, 360, endpoint=False)\n",
    "h, theta, d = hough_line(medax, tested_angles)\n",
    "# plt.imshow(out)\n",
    "\n",
    "# np.linspace(-np.pi / 2, np.pi / 2, 360, endpoint=False)\n",
    "\n",
    "# Generating figure 1\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(medax)\n",
    "ax[0].set_title('Input image')\n",
    "ax[0].set_axis_off()\n",
    "\n",
    "ax[1].imshow(np.log(1+h))\n",
    "ax[1].set_title('Hough transform')\n",
    "ax[1].set_xlabel('Angles (degrees)')\n",
    "ax[1].set_ylabel('Distance (pixels)')\n",
    "ax[1].axis('image')\n",
    "\n",
    "ax[2].imshow(medax, cmap=\"gray\")\n",
    "ax[2].set_ylim((medax.shape[0], 0))\n",
    "ax[2].set_axis_off()\n",
    "ax[2].set_title('Detected lines')\n",
    "\n",
    "for _, angle, dist in zip(*hough_line_peaks(h, theta, d, min_angle=0, min_distance=1)):\n",
    "    (x0, y0) = dist * np.array([np.cos(angle), np.sin(angle)])\n",
    "    ax[2].axline((x0, y0), slope=np.tan(angle + np.pi/2))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# newrgb = np.where(medax[..., None], cropped_rgb, 0)\n",
    "# plt.imshow(newrgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bec34c-3767-486f-ab24-2203cecc1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea48c043-d5bf-4fc2-9d55-25263b34aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = probabilistic_hough_line(medax, line_length=10,line_gap=1)\n",
    "# plt.plot(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c15d1-a04a-4c98-b4c5-e08f5dcbee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating figure 2\n",
    "fig, axes = plt.subplots(3,1, figsize=(15, 5), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(cropped_gray, cmap='gray')\n",
    "ax[0].set_title('Input image')\n",
    "\n",
    "ax[1].imshow(medax, cmap='gray')\n",
    "ax[1].set_title('Canny edges')\n",
    "\n",
    "ax[2].imshow(edges * 0)\n",
    "for line in lines:\n",
    "    p0, p1 = line\n",
    "    ax[2].plot((p0[0], p1[0]), (p0[1], p1[1]))\n",
    "ax[2].set_xlim((0, cropped_gray.shape[1]))\n",
    "ax[2].set_ylim((cropped_gray.shape[0], 0))\n",
    "ax[2].set_title('Probabilistic Hough')\n",
    "\n",
    "for a in ax:\n",
    "    a.set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eyT4JaS5flwH",
   "metadata": {
    "id": "eyT4JaS5flwH"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# fra=frangi(cropped_gray, black_ridges=False, mode='constant')\n",
    "# plt.imshow(fra)\n",
    "\n",
    "norm_image = cv2.normalize(fra, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "norm_image = norm_image.astype(np.uint8)\n",
    "plt.imshow(norm_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e0bbff-4883-405c-a171-03dfe822053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = cv2.morphologyEx(norm_image, cv2.MORPH_TOPHAT, (3,3), iterations = 10)\n",
    "# plt.imshow(bw)\n",
    "\n",
    "\n",
    "newrgb = np.where(bw[...], cropped_gray, 0)\n",
    "plt.imshow(newrgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3753e62-2d35-492c-87ed-51d7da6d7c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 255-newrgb\n",
    "hes = hessian(image, sigmas=range(1, 10, 2), scale_range=None, scale_step=None, alpha=0.5, beta=0.5, gamma=15, black_ridges=False, mode='reflect', cval=0)\n",
    "plt.imshow(hes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c2b930-919a-4d9a-a8c0-be6841c8b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.ndimage.morphology.distance_transform_edt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e736a7b1-1919-46a3-b113-3c5c6ce0c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_filter = cv2.ximgproc.RidgeDetectionFilter_create(dx=1, dy=1, ksize = 3)\n",
    "ridges = ridge_filter.getRidgeFilteredImage(np.uint8(image))\n",
    "plt.imshow(ridges)\n",
    "\n",
    "# newrgb2 = np.where(ridges[..., None], newrgb, 0)\n",
    "# plt.imshow(newrgb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272b3932-5460-4d5e-90ff-ed0e58a51d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# medax= medial_axis(ridges)\n",
    "# plt.imshow(medax)\n",
    "\n",
    "norm_image = cv2.normalize(ridges, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "norm_image = norm_image.astype(np.uint8)\n",
    "plt.imshow(norm_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efcc705-1cab-4c06-b79c-58dbaf57bb79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0e2301-fa7c-484f-bb43-3f56d1f911b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "thin1= thin(norm_image)\n",
    "plt.imshow(thin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81848612-b4ed-4cf4-853e-2295d71c920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "# bw = cv2.morphologyEx(norm_image, cv2.MORPH_GRADIENT, (3,3), iterations = 10)\n",
    "# bw = cv2.morphologyEx(norm_image, cv2.MORPH_BLACKHAT, kernel, iterations = 10)\n",
    "# bw = cv2.morphologyEx(norm_image, cv2.MORPH_TOPHAT, (3,3), iterations = 10)\n",
    "# bw = cv2.morphologyEx(norm_image, cv2.MORPH_OPEN, (3,3), iterations = 10)\n",
    "# bw = cv2.morphologyEx(norm_image, cv2.MORPH_CLOSE, (3,3), iterations = 5)\n",
    "bw = cv2.morphologyEx(255-image, cv2.MORPH_DILATE, (3,3), iterations = 5)\n",
    "# bw = cv2.morphologyEx(newrgb, cv2.MORPH_ERODE, (3,3), iterations = 10)\n",
    "plt.imshow(bw)\n",
    "\n",
    "# # do connected components processing\n",
    "# nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(bw, None, None, None, 8, cv2.CV_32S)\n",
    "\n",
    "# #get CC_STAT_AREA component as stats[label, COLUMN] \n",
    "# areas = stats[1:,cv2.CC_STAT_AREA]\n",
    "\n",
    "# result = np.zeros((labels.shape), np.uint8)\n",
    "\n",
    "# for i in range(0, nlabels - 1):\n",
    "#     if areas[i] >= 100:   #keep\n",
    "#         result[labels == i + 1] = 255\n",
    "        \n",
    "# plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d973767c-8060-477b-9904-f9d0df9c9dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "# bw = cv2.morphologyEx(norm_image, cv2.MORPH_GRADIENT, kernel, iterations = 5)\n",
    "# bw = cv2.morphologyEx(norm_image, cv2.MORPH_BLACKHAT, kernel, iterations = 10)\n",
    "# bw = cv2.morphologyEx(result, cv2.MORPH_TOPHAT, (3,3), iterations = 10)\n",
    "# bw = cv2.morphologyEx(norm_image, cv2.MORPH_OPEN, kernel, iterations = 10)\n",
    "# plt.imshow(bw)\n",
    "\n",
    "# hyst = filters.scharr_h(bw)\n",
    "# plt.imshow(hyst)\n",
    "\n",
    "thinned = medial_axis(blurred>0.5)\n",
    "plt.imshow(thinned)\n",
    "\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "# erosion = cv2.erode(cropped_lab,kernel,iterations = 5)\n",
    "# # plt.imshow(erosion)\n",
    "\n",
    "# hyst = filters.scharr_h(fra)\n",
    "# plt.imshow(hyst)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# norm_image = cv2.normalize(hyst, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "# norm_image = norm_image.astype(np.uint8)\n",
    "# plt.imshow(norm_image)\n",
    "# thresh = np.median(hyst) + (np.std(hyst) * 2)\n",
    "\n",
    "# medax= medial_axis(result)\n",
    "# plt.imshow(medax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef2ff4-a59e-4be5-be83-cd2e406a7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amax(medax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fh84n5jEfmLI",
   "metadata": {
    "id": "fh84n5jEfmLI"
   },
   "outputs": [],
   "source": [
    "np.mean(hyst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dJymOI0fmm5",
   "metadata": {
    "id": "8dJymOI0fmm5"
   },
   "outputs": [],
   "source": [
    "# Dilation\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "# dilation = cv2.dilate(np.uint8(medax),kernel,iterations = 2)\n",
    "# # plt.imshow(dilation)\n",
    "\n",
    "result= thin(dilation)\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77cd88c-5376-47ec-8320-3fae2596be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# blur = cv2.blur(cropped_gray,(50,50))\n",
    "# blur = cv2.blur(opening,(3,3))   # With RGB\n",
    "# plt.imshow(blur)\n",
    "# np.amax(blur)\n",
    "medax= medial_axis(blurred)\n",
    "plt.imshow(medax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n4WaeY5YbkAc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "executionInfo": {
     "elapsed": 644,
     "status": "ok",
     "timestamp": 1634310080095,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "n4WaeY5YbkAc",
    "outputId": "ed9b6653-c4f5-4ec6-9817-ce5d1d301283"
   },
   "outputs": [],
   "source": [
    "# h, theta, d = hough_line(medax)\n",
    "# plt.imshow(np.uint8(medax))\n",
    "\n",
    "# norm_image = cv2.normalize(np.uint8(medax), None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "# norm_image = norm_image.astype(np.uint8)\n",
    "# plt.imshow(norm_image)\n",
    "\n",
    "# minLineLength = 10\n",
    "# maxLineGap = 5\n",
    "# lines = cv2.HoughLinesP(norm_image, 1, np.pi/180, 200, minLineLength, maxLineGap)\n",
    "# for x1, y1, x2, y2 in lines[0]:\n",
    "#     cv2.line(norm_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "# cv2.imwrite('.\\canny5.jpg', norm_image)\n",
    "\n",
    "\n",
    "lines = cv2.HoughLines(norm_image,1,np.pi/180,200)\n",
    "for rho,theta in lines[0]:\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "\n",
    "    cv2.line(norm_image,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "cv2.imwrite('houghlines3.jpg',norm_image)\n",
    "\n",
    "\n",
    "# cv2.imwrite('.\\houghlines5.jpg', cropped_rgb)\n",
    "\n",
    "# # Generating figure 1\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "# ax = axes.ravel()\n",
    "\n",
    "# ax[0].imshow(medax)\n",
    "# ax[0].set_title('Input image')\n",
    "# ax[0].set_axis_off()\n",
    "\n",
    "# ax[1].imshow(np.log(1+h))\n",
    "# ax[1].set_title('Hough transform')\n",
    "# ax[1].set_xlabel('Angles (degrees)')\n",
    "# ax[1].set_ylabel('Distance (pixels)')\n",
    "# ax[1].axis('image')\n",
    "\n",
    "# ax[2].imshow(medax, cmap=\"gray\")\n",
    "# ax[2].set_ylim((medax.shape[0], 0))\n",
    "# ax[2].set_axis_off()\n",
    "# ax[2].set_title('Detected lines')\n",
    "\n",
    "# for _, angle, dist in zip(*hough_line_peaks(h, theta, d)):\n",
    "#     (x0, y0) = dist * np.array([np.cos(angle), np.sin(angle)])\n",
    "#     ax[2].axline((x0, y0), slope=np.tan(angle + np.pi/2))\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a92da7-ea8c-42fd-8cb8-635d8f6da67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# angles\n",
    "\n",
    "sns.histplot(h, bins=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WoDDheypNUd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "error",
     "timestamp": 1634309138117,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "WoDDheypNUd4",
    "outputId": "1c4785ad-4fb3-4820-a734-506aa58f6fdd"
   },
   "outputs": [],
   "source": [
    "# Erosion\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "erosion = cv2.erode(fra,kernel,iterations =3)\n",
    "plt.imshow(erosion)\n",
    "\n",
    "erosion2 = erosion * 1000 * 255\n",
    "np.amax(fra)\n",
    "edges = cv2.Canny(np.uint8(fra*10000), 0.03, 0.1)\n",
    "plt.imshow(edges)\n",
    "\n",
    "\n",
    "\n",
    "# Opening\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "opening = cv2.morphologyEx(erosion, cv2.MORPH_OPEN, (5,5), iterations = 1)\n",
    "plt.imshow(opening)\n",
    "\n",
    "blur = cv2.blur(np.float32(opening),(10,10))\n",
    "blur = cv2.blur(opening,(3,3))   # With RGB\n",
    "plt.imshow(blur)\n",
    "\n",
    "# Dilation\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "dilation = cv2.dilate(blur,kernel,iterations = 2)\n",
    "plt.imshow(dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be50adc6-e57e-484e-8573-df2e4fb660ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "executionInfo": {
     "elapsed": 588,
     "status": "ok",
     "timestamp": 1634248465920,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "be50adc6-e57e-484e-8573-df2e4fb660ad",
    "outputId": "ea767751-a2c6-45ba-fe9e-fd3995249a99"
   },
   "outputs": [],
   "source": [
    "# dilation = dilation*255\n",
    "gray_skel = opening @ [0.2126, 0.7152, 0.0722]\n",
    "plt.imshow(gray_skel)\n",
    "np.amin(gray_skel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fbe987-a870-468f-a470-d6657ddba780",
   "metadata": {
    "id": "b1fbe987-a870-468f-a470-d6657ddba780"
   },
   "source": [
    "## Frangi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86497dce-a9af-4873-acfd-8ad17257f6a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "executionInfo": {
     "elapsed": 9028,
     "status": "ok",
     "timestamp": 1634308854329,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "86497dce-a9af-4873-acfd-8ad17257f6a0",
    "outputId": "4f247f2d-fd99-4cd9-8bc6-f2250842baf8"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fra =frangi(cropped_gray>0, black_ridges=False)\n",
    "plt.imshow(fra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ecdd7b-239b-4aee-8519-91a3fcf4e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(cropped_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc978be5-2392-4eb9-a508-b6bd3398108f",
   "metadata": {
    "id": "fc978be5-2392-4eb9-a508-b6bd3398108f"
   },
   "source": [
    "## Skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a11552-81ed-410c-afcf-fedb9da173c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "executionInfo": {
     "elapsed": 2201,
     "status": "ok",
     "timestamp": 1634307499009,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "d4a11552-81ed-410c-afcf-fedb9da173c4",
    "outputId": "dc8ba059-ae50-476f-d984-e0a3357c3586"
   },
   "outputs": [],
   "source": [
    "gray_skel = gray_skel>-0.001\n",
    "plt.imshow(gray_skel)\n",
    "\n",
    "skel = skeletonize(fra>0)\n",
    "plt.imshow(skel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30fd696-0c28-43c7-a0e6-dc72d301492b",
   "metadata": {
    "id": "b30fd696-0c28-43c7-a0e6-dc72d301492b"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ec9ee-ebe7-4cad-aff4-3a4e7c457e3a",
   "metadata": {
    "id": "429ec9ee-ebe7-4cad-aff4-3a4e7c457e3a"
   },
   "outputs": [],
   "source": [
    "data_skel = summarize(Skeleton(skel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e4dc5a-1cf9-49e6-96e2-90d9a517d4d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 875
    },
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1634058896512,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "77e4dc5a-1cf9-49e6-96e2-90d9a517d4d6",
    "outputId": "f7b35e7e-eba0-4398-a7cf-c45a45926235"
   },
   "outputs": [],
   "source": [
    "data_skel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43e5447-d314-4cf2-b418-1e1f0639a79a",
   "metadata": {
    "id": "f43e5447-d314-4cf2-b418-1e1f0639a79a"
   },
   "outputs": [],
   "source": [
    "pixel_graph, coordinates, degrees = skeleton_to_csgraph(skel)\n",
    "# plt.imshow(degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcc98e4-13e6-49db-9cba-e4941a321292",
   "metadata": {
    "id": "cdcc98e4-13e6-49db-9cba-e4941a321292"
   },
   "source": [
    "### Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea68874e-73d0-4cfb-b1ad-ed82ff6aac57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1634058931448,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "ea68874e-73d0-4cfb-b1ad-ed82ff6aac57",
    "outputId": "4b91a4d2-2587-4236-b2a4-3101d2f9a6fe"
   },
   "outputs": [],
   "source": [
    "draw.overlay_euclidean_skeleton_2d(rescaled_spk, data_skel, skeleton_color_source='branch-type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933784d-1b01-4550-88d2-d9911d064658",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1221,
     "status": "ok",
     "timestamp": 1634058940483,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "c933784d-1b01-4550-88d2-d9911d064658",
    "outputId": "6ebecad8-11eb-4058-d25c-5f6327e2dca2"
   },
   "outputs": [],
   "source": [
    "# Histograms\n",
    "data_skel.hist(column='branch-distance', by='branch-type', bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ded33f-e663-44de-9d75-7ff695423d99",
   "metadata": {
    "id": "d8ded33f-e663-44de-9d75-7ff695423d99"
   },
   "source": [
    "## Medial axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff35698-c161-4556-979e-7fc277abd6e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "executionInfo": {
     "elapsed": 3453,
     "status": "ok",
     "timestamp": 1634307760614,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "0ff35698-c161-4556-979e-7fc277abd6e3",
    "outputId": "4470ed7b-c4dd-4d11-96ad-f5452a773221"
   },
   "outputs": [],
   "source": [
    "# Compute the medial axis (skeleton) and the distance transform\n",
    "medax, distance = medial_axis(erosion, return_distance=True)\n",
    "plt.imshow(medax)\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "dilation = cv2.dilate(np.float32(medax),(5,5),iterations = 4)\n",
    "plt.imshow(dilation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02ade9-6ded-4ee3-baf6-593697959aa7",
   "metadata": {
    "id": "6f02ade9-6ded-4ee3-baf6-593697959aa7"
   },
   "outputs": [],
   "source": [
    "# plt.imshow(distance)\n",
    "# distance.shape\n",
    "# np.amin(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c90e4b-1951-42c9-a193-1e794a11400c",
   "metadata": {
    "id": "96c90e4b-1951-42c9-a193-1e794a11400c"
   },
   "outputs": [],
   "source": [
    "data_medax = summarize(Skeleton(medax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3122d230-4951-4ef6-8b87-14a6430a3a80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 115,
     "status": "ok",
     "timestamp": 1634058958625,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "3122d230-4951-4ef6-8b87-14a6430a3a80",
    "outputId": "8dfa1006-b80a-4970-cab5-f08286788b72"
   },
   "outputs": [],
   "source": [
    "data_medax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b6359a-d36f-4f6a-a75d-848774578ab9",
   "metadata": {
    "id": "f0b6359a-d36f-4f6a-a75d-848774578ab9"
   },
   "outputs": [],
   "source": [
    "pixel_graph, coordinates, degrees = skeleton_to_csgraph(medax)\n",
    "# plt.imshow(degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c717c656-4467-415d-b22e-2a3e30f2a180",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1634058969149,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "c717c656-4467-415d-b22e-2a3e30f2a180",
    "outputId": "4f961b47-64ce-4610-bee0-86443868b0d5"
   },
   "outputs": [],
   "source": [
    " draw.overlay_euclidean_skeleton_2d(rescaled_spk, data_medax, skeleton_color_source='branch-type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0fbe11-f793-4118-aed9-db460278967b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1150,
     "status": "ok",
     "timestamp": 1634059000631,
     "user": {
      "displayName": "Joan Barreto Ortiz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03887754532873831078"
     },
     "user_tz": 300
    },
    "id": "1a0fbe11-f793-4118-aed9-db460278967b",
    "outputId": "6e8a688a-f2e1-47c1-8aee-cf1837810dea"
   },
   "outputs": [],
   "source": [
    "# Histograms\n",
    "data_medax.hist(column='branch-distance', by='branch-type', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f113c3-6ba7-43c6-b1ef-e6776293017b",
   "metadata": {
    "id": "22f113c3-6ba7-43c6-b1ef-e6776293017b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0d275e-4a2f-4aa9-a7e4-36ad55b30aaf",
   "metadata": {
    "id": "1e0d275e-4a2f-4aa9-a7e4-36ad55b30aaf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33df8c98-7670-4595-ade5-69a78065f682",
   "metadata": {
    "id": "33df8c98-7670-4595-ade5-69a78065f682"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79877fe2-07d4-4858-b979-9e80b7455423",
   "metadata": {
    "id": "79877fe2-07d4-4858-b979-9e80b7455423"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "average-instrumentation",
   "metadata": {
    "id": "average-instrumentation"
   },
   "source": [
    "## Properties\n",
    "Here we look at the overall properties of each spike without any detail about branches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-enlargement",
   "metadata": {
    "id": "fantastic-enlargement"
   },
   "outputs": [],
   "source": [
    "# Get geometric and spectral properties\n",
    "spk_df = SpikesDF(img0_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-conversation",
   "metadata": {
    "id": "rational-conversation",
    "outputId": "79371f7d-5ae4-4232-85e0-187be59a7f2d"
   },
   "outputs": [],
   "source": [
    "# Visualize column names\n",
    "print(spk_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff184cb-a3df-487f-a972-bccae7f1f622",
   "metadata": {
    "id": "6ff184cb-a3df-487f-a972-bccae7f1f622"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d633d-3b03-41c6-aa34-5096abdae41f",
   "metadata": {
    "id": "6a5d633d-3b03-41c6-aa34-5096abdae41f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0d03b4-ec86-455f-ba54-2ffe66a3423a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b76cd-2636-48a8-aff3-86bc666da586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1b975-6bf2-4fea-97fd-bca2bd472651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54f54ee3-01fc-4668-b053-3d568a78ffd0",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbeec74-6189-46e8-93d4-290b3427bc28",
   "metadata": {},
   "source": [
    "## `ListImages`\n",
    "Returns a list of full image paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2745083a-2963-48c9-8f97-f0e2f725acde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def ListImages(path, imgformat=\".tif\", recursive=False):\n",
    "    Images = glob.glob(path + '/*' + imgformat, recursive=True)    \n",
    "    return Images\n",
    "\n",
    "# Example:\n",
    "# path = r'./Images/TEST'\n",
    "# Images = ListImages(path, imgformat=\".tif\", recursive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb4c25c-3c76-4932-a5ca-3275d56676bb",
   "metadata": {},
   "source": [
    "## `RemoveBackground`\n",
    "Input can be the image as an array or just the full image path.\n",
    "It takes almost 25 seconds to create list with five images (rgb, gray, lab, hsv, bw). Needs to be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f837048f-e4a8-4d0c-a0e0-7586025a3328",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def RemoveBackground(img, OtsuScaling=0.25, rgb_out=True, gray_out=True, lab_out=True, hsv_out=True, bw_out=True):\n",
    "    \n",
    "    # Read image\n",
    "    if isinstance(img, str) == True:\n",
    "        img0 = plt.imread(img)\n",
    "    else: \n",
    "        img0 = img\n",
    "    \n",
    "    # Crop images. They were all taken with the same scanner\n",
    "    img1 = img0[44:6940, 25:4970, :]\n",
    "    \n",
    "     # Convert to gray\n",
    "    gray0 = img1 @ [0.2126, 0.7152, 0.0722]\n",
    "    \n",
    "    # Set image threshold\n",
    "    T = filters.threshold_otsu(gray0)\n",
    "#     print(T)\n",
    "    T = T*OtsuScaling\n",
    "#     print(T)\n",
    "    \n",
    "    # Segment gray image\n",
    "    bw0 = gray0 > T\n",
    "    \n",
    "    # Remove small objects\n",
    "    n_pixels = gray0.shape[0] * gray0.shape[1]\n",
    "    minimum_size = n_pixels/10000\n",
    "    bw1 = morphology.remove_small_objects(bw0, min_size=np.floor(minimum_size))\n",
    "    \n",
    "    ImagesOut = []\n",
    "#     len(ImagesOut)\n",
    "    \n",
    "    if rgb_out==True:\n",
    "        # Apply mask to RGB\n",
    "        rgb = np.where(bw1[..., None], img1, 0)\n",
    "        ImagesOut.append(rgb)\n",
    "    if gray_out==True and rgb_out==True:\n",
    "        gray = color.rgb2gray(rgb)\n",
    "        ImagesOut.append(gray)\n",
    "    if lab_out==True and rgb_out==True:\n",
    "        lab = color.rgb2lab(rgb)\n",
    "        ImagesOut.append(lab)\n",
    "    if hsv_out==True and rgb_out==True:\n",
    "        hsv = color.rgb2hsv(rgb)\n",
    "        ImagesOut.append(hsv)\n",
    "    if bw_out==True:\n",
    "#         # Threshold\n",
    "#         otsu = filters.threshold_otsu(gray)\n",
    "#         bw0 = gray > 0\n",
    "#         bw = morphology.remove_small_objects(bw0, min_size=1.5e-05 * gray.shape[0] * gray.shape[1])\n",
    "        ImagesOut.append(bw1)\n",
    "    \n",
    "    return ImagesOut\n",
    "\n",
    "# Usage:\n",
    "# %%time\n",
    "# I = RemoveBackground(Images[3], OtsuScaling=0.25, rgb_out=True, gray_out=True, lab_out=True, hsv_out=True, bw_out=True)\n",
    "# rgb0 = I[0]\n",
    "# gray0 = I[1]\n",
    "# lab0 = I[2]\n",
    "# hsv0 = I[3]\n",
    "# bw0 = I[4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4820a4-bb4d-4506-8af3-7b3d45edfbd6",
   "metadata": {},
   "source": [
    "## `EnumerateSpkCV`\n",
    "Enumerate spikes, spikelets, or contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e790d91a-2f5f-4f72-869b-b7ed764b40f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Enumerate spikes\n",
    "def EnumerateSpkCV(bw, rgb, TextSize=5, TROE2020=False):\n",
    "    \n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(bw), connectivity=8)\n",
    "    img = rgb.copy()\n",
    "    \n",
    "    if TROE2020==True:\n",
    "        counter=-1\n",
    "    else:\n",
    "        counter=0\n",
    "        for c in centroids:\n",
    "    #         print(c)\n",
    "            cx = round(c[0])\n",
    "            cy = round(c[1])\n",
    "            img = cv2.circle(img, (cx, cy), 10, (255, 0, 0), -1)\n",
    "            img = cv2.putText(img, str(counter), (cx - 25, cy - 25),cv2.FONT_HERSHEY_SIMPLEX, TextSize, (255, 0, 0), 15)\n",
    "            counter = counter+1\n",
    "        plt.imshow(img)\n",
    "\n",
    "# # Example:\n",
    "# EnumerateSpkCV(bw0, rgb0, TextSize=5, TROE2020=False)\n",
    "# EnumerateSpkCV(spklts, cropped_rgb, TextSize=5, TROE2020=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea2767e-68c4-4e9f-ba45-dd12f098b60f",
   "metadata": {},
   "source": [
    "## `spk_length`\n",
    "Return the spike length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e8ea47-9227-4d05-b214-00bb637fdbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def spk_length(cropped_spk, method='skelblur', Overlay=True, PlotCH=False):\n",
    "    \n",
    "    if method=='skelblur':\n",
    "        # Severly blur the image\n",
    "        blur = cv2.blur(np.float32(cropped_spk),(100,100))\n",
    "        # Threshold the blur\n",
    "        thrb = blur > 0.1\n",
    "        skeleton = skeletonize(thrb)\n",
    "#         plt.imshow(skeleton)\n",
    "        \n",
    "    if method=='chull':\n",
    "        # Blur the image with a 50x50 kernel\n",
    "        blur = cv2.blur(np.float32(cropped_spk),(50,50))\n",
    "\n",
    "        # Get convex hull \n",
    "        chull = convex_hull_image(blur>0)\n",
    "\n",
    "        # Perform skeletonization\n",
    "        image = chull\n",
    "        skeleton = skeletonize(image)\n",
    "    #     plt.imshow(skeleton)\n",
    "    \n",
    "    # Spike length\n",
    "    SpkL = cv2.countNonZero(np.float32(skeleton))\n",
    "    \n",
    "    if PlotCH == True:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "        ax = axes.ravel()\n",
    "\n",
    "        ax[0].set_title('Original picture')\n",
    "        ax[0].imshow(cropped_spk, cmap=plt.cm.gray)\n",
    "        ax[0].set_axis_off()\n",
    "\n",
    "        ax[1].set_title('Transformed picture')\n",
    "        ax[1].imshow(chull, cmap=plt.cm.gray)\n",
    "        ax[1].set_axis_off()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Visualize overlay?\n",
    "    if Overlay == True:\n",
    "        overlay_images = cv2.addWeighted(np.float32(cropped_spk),20,np.float32(skeleton),255,0)\n",
    "        plt.imshow(overlay_images, cmap='gray')\n",
    "    \n",
    "    return SpkL\n",
    "\n",
    "# Example:\n",
    "# SL = spk_length(cropped_spk, method='skelblur', Overlay=True, PlotCH=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d15be79-4eda-4205-a336-ba4e06fef804",
   "metadata": {},
   "source": [
    "## `PixelHist`\n",
    "Object histogram analysis. This function returns the black and white version of the given image(s) and print the label of each spike as computed by 'skimage.measure.label'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3853b8c9-c824-4438-84f7-11dbb501f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def PixelHist(bw, ColorSpace, channel = 0, spikes=\"All\", nbins = 100):\n",
    "    \n",
    "    labeled_spks, num_spikes = label(bw, return_num = True)\n",
    "#     plt.imshow(labeled_spks==0)\n",
    "\n",
    "    if spikes==\"All\":\n",
    "        labeled_spks = labeled_spks\n",
    "    else:\n",
    "        for L in range(1,num_spikes+1):\n",
    "#             print(L)\n",
    "            if not L in spikes:\n",
    "#                 print(\"Deleted label \", L)\n",
    "                labeled_spks=np.where(labeled_spks==L, 0, labeled_spks)\n",
    "#     plt.imshow(labeled_spks)\n",
    "    \n",
    "    Props = regionprops(labeled_spks, intensity_image=ColorSpace[:,:,channel])\n",
    "    Areas = [rp.area for rp in Props]\n",
    "    Labels = [rp.label for rp in Props] #Delete 1 because label in image is +1 greater than ACTUAL label\n",
    "    Spikes_Data = []\n",
    "    Names = []\n",
    "    Colors = sns.color_palette(\"husl\", len(spikes))\n",
    "    Colors2 = [list(i) for i in Colors] # list of lists\n",
    "    \n",
    "    \n",
    "    for indexed in range(len(Labels)):        \n",
    "        spk_data = Props[indexed].intensity_image \n",
    "        spk_data = spk_data.ravel()\n",
    "        NonZero = spk_data[spk_data != 0]\n",
    "\n",
    "        Spikes_Data.append(NonZero)\n",
    "        Names.append(\"Spike \" + str(int(spikes[indexed])) + \"\\n\" + \"Area = \"  + str(round(np.mean(NonZero))) + \" px\" + \"\\n\" +\n",
    "                     \"Mean = \"  + str(round(np.mean(NonZero), 1)))\n",
    "        Colors.append(list(np.random.choice(range(2), size=3)))\n",
    "    \n",
    "    plt.hist(Spikes_Data, bins = nbins, color = Colors2, label = Names);\n",
    "    \n",
    "    # Plot formatting\n",
    "    plt.legend();\n",
    "    plt.xlabel('Intensity Value');\n",
    "    plt.ylabel('Number of NonZero Pixels');\n",
    "    plt.title('Distribution of None-Zero Pixel Values for Selected Given Channel and Spikes');\n",
    "\n",
    "# Example:\n",
    "# PixelHist(bw=bw0, ColorSpace=lab0, channel = 0, spikes=[1,2,26], nbins = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ba90f0-1aa9-4fe8-a14d-e7d5bcec210f",
   "metadata": {},
   "source": [
    "## `channel_percentiles`\n",
    "This returns the percentiles for a given channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09ff596-d11d-43a2-a1e4-66e06b9521e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def channel_percentiles(channel_props, Negatives = None):\n",
    "      \n",
    "    # Create empty lists to populate    \n",
    "    p25_pos_list = []\n",
    "    p50_pos_list = []\n",
    "    p75_pos_list = []\n",
    "    p25_neg_list = []\n",
    "    p50_neg_list = []\n",
    "    p75_neg_list = []\n",
    "    mean_pos_list = []\n",
    "    sd_pos_list = []\n",
    "    min_pos_list = []\n",
    "    max_pos_list = []\n",
    "    mean_neg_list = []\n",
    "    sd_neg_list = []\n",
    "    min_neg_list = []\n",
    "    max_neg_list = []\n",
    "    \n",
    "#     channel_props[1].intensity_image\n",
    "    \n",
    "\n",
    "    # channel_props = a_props\n",
    "    for spk in range(len(channel_props)):\n",
    "        # spk=0\n",
    "        my_array = channel_props[spk].intensity_image\n",
    "#         plt.imshow(my_array)\n",
    "        flat_array = my_array.ravel()\n",
    "        non_zero = flat_array[flat_array != 0]\n",
    "\n",
    "        positive_values = non_zero[non_zero > 0]\n",
    "        if positive_values.size == 0:\n",
    "            positive_values = [0]        \n",
    "        p25_pos = np.nanpercentile(positive_values, 25)\n",
    "        p25_pos_list.append(p25_pos)\n",
    "        p50_pos = np.nanpercentile(positive_values, 50)\n",
    "        p50_pos_list.append(p50_pos)\n",
    "        p75_pos = np.nanpercentile(positive_values, 75)\n",
    "        p75_pos_list.append(p75_pos)\n",
    "        mean_pos = np.mean(positive_values)\n",
    "        mean_pos_list.append(mean_pos)\n",
    "        sd_pos = np.std(positive_values)\n",
    "        sd_pos_list.append(sd_pos)\n",
    "        min_pos = min(positive_values)\n",
    "        min_pos_list.append(min_pos)\n",
    "        max_pos = max(positive_values)\n",
    "        max_pos_list.append(max_pos)\n",
    "\n",
    "        if Negatives == True:\n",
    "            negative_values = non_zero[non_zero < 0]\n",
    "            # Make sure list is not empty, otherwise add a zero\n",
    "            if negative_values.size == 0:\n",
    "                negative_values = [0]\n",
    "            p25_neg = np.nanpercentile(negative_values, 25)\n",
    "            p25_neg_list.append(p25_neg)\n",
    "            p50_neg = np.nanpercentile(negative_values, 50)\n",
    "            p50_neg_list.append(p50_neg)\n",
    "            p75_neg = np.nanpercentile(negative_values, 75)\n",
    "            p75_neg_list.append(p75_neg)\n",
    "            mean_neg = np.mean(negative_values)\n",
    "            mean_neg_list.append(mean_neg)\n",
    "            sd_neg = np.std(positive_values)\n",
    "            sd_neg_list.append(sd_neg)\n",
    "            min_neg = min(negative_values)\n",
    "            min_neg_list.append(min_neg)\n",
    "            max_neg = max(negative_values)\n",
    "            max_neg_list.append(max_neg)\n",
    "\n",
    "            Lists = [p25_pos_list, p50_pos_list, p75_pos_list, mean_pos_list, sd_pos_list, min_pos_list, max_pos_list, p25_neg_list, p50_neg_list, p75_neg_list, mean_neg_list, sd_neg_list, min_neg_list, max_neg_list]\n",
    "        else:\n",
    "            Lists = [p25_pos_list, p50_pos_list, p75_pos_list, mean_pos_list, sd_pos_list, min_pos_list, max_pos_list]\n",
    "\n",
    "        \n",
    "        # if any(pixel < 0 for pixel in non_zero) == True:\n",
    "        #     negative_values = non_zero[non_zero < 0]\n",
    "        #     p25_neg = np.percentile(negative_values, 25)\n",
    "        #     p25_neg_list.append(p25_neg)\n",
    "        #     p50_neg = np.percentile(negative_values, 50)\n",
    "        #     p50_neg_list.append(p50_neg)\n",
    "        #     p75_neg = np.percentile(negative_values, 75)\n",
    "        #     p75_neg_list.append(p75_neg)\n",
    "    return Lists\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "# Examples:\n",
    "\n",
    "# For one spike\n",
    "# labeled_contours, num_contours = label(cropped_spk, return_num = True)\n",
    "# red_props = regionprops(labeled_contours, intensity_image=cropped_rgb)\n",
    "# a_Perc = np.array(channel_percentiles(channel_props=a_props, Negatives=True)).T\n",
    "# len(a_Perc)\n",
    "\n",
    "\n",
    "# For one entire image\n",
    "# labeled_contours, num_contours = label(bw0, return_num = True)\n",
    "# red_props = regionprops(labeled_contours, intensity_image=rgb0)\n",
    "# Red_Perc = np.array(channel_percentiles(channel_props=red_props, Negatives=False)).T\n",
    "# len(Red_Perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10f713b-6187-4bd3-9f0b-faea679c7133",
   "metadata": {},
   "source": [
    "## `SpikesDF`\n",
    "Spike properties in a DataFrame. This function returns a Pandas data frame with the geometric and spectral properties of the given path to rgb image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b58ce-ccea-4f9d-a001-69356ec40b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def SpikesDF(I, ImagePath, RemoveBG=False, PrintSpkLabels=False, rm_envelope=False):\n",
    "    \n",
    "    # Check if images or path were given\n",
    "    if RemoveBG == True:\n",
    "        # Remove background (path was given)\n",
    "        I = RemoveBackground(ImagePath, OtsuScaling=0.25, rgb_out=True, gray_out=True, lab_out=True, hsv_out=True, bw_out=True)\n",
    "        rgb0 = I[0]\n",
    "        gray0 = I[1]\n",
    "        lab0 = I[2]\n",
    "        hsv0 = I[3]\n",
    "        bw0 = I[4]\n",
    "        \n",
    "        Image_Name = ImagePath.split('\\\\')[-1]\n",
    "\n",
    "    else: \n",
    "        # Images were given in a list as returned by RemoveBackground()\n",
    "        rgb0 = I[0]\n",
    "        gray0 = I[1]\n",
    "        lab0 = I[2]\n",
    "        hsv0 = I[3]\n",
    "        bw0 = I[4]\n",
    "    \n",
    "    \n",
    "    labeled_spks, num_spikes = label(bw0, return_num = True)\n",
    "    props_spikes = regionprops(labeled_spks)\n",
    "    \n",
    "    # Create column with image name\n",
    "    Image_Name = ImagePath.split('\\\\')[-1]\n",
    "    Image_Name = [Image_Name] * num_spikes\n",
    "    \n",
    "    # Geometric properties\n",
    "    Labels = [rp.label for rp in props_spikes]\n",
    "    Areas = [rp.area for rp in props_spikes]\n",
    "    MajorAxes = [rp.major_axis_length for rp in props_spikes]\n",
    "    MinorAxes = [rp.minor_axis_length for rp in props_spikes]\n",
    "    Orientations = [rp.orientation for rp in props_spikes]\n",
    "    Perimeters = [rp.perimeter for rp in props_spikes]\n",
    "    Eccentricities = [rp.eccentricity for rp in props_spikes]\n",
    "   \n",
    "    # Spectral properties\n",
    "    red_props = regionprops(labeled_spks, intensity_image=rgb0[:,:,0])\n",
    "    green_props = regionprops(labeled_spks, intensity_image=rgb0[:,:,1])\n",
    "    blue_props = regionprops(labeled_spks, intensity_image=rgb0[:,:,2])\n",
    "    L_props = regionprops(labeled_spks, intensity_image=lab0[:,:,0])\n",
    "    a_props = regionprops(labeled_spks, intensity_image=lab0[:,:,1])\n",
    "    b_props = regionprops(labeled_spks, intensity_image=lab0[:,:,2])\n",
    "    H_props = regionprops(labeled_spks, intensity_image=hsv0[:,:,0])\n",
    "    S_props = regionprops(labeled_spks, intensity_image=hsv0[:,:,1])\n",
    "    V_props = regionprops(labeled_spks, intensity_image=hsv0[:,:,2])\n",
    "    \n",
    "    red = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in red_props])\n",
    "    green = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in green_props])\n",
    "    blue = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in blue_props])\n",
    "    L = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in L_props])\n",
    "    a = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in a_props])\n",
    "    b = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in b_props])\n",
    "    H = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in H_props])\n",
    "    S = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in S_props])\n",
    "    V = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in V_props])\n",
    "    \n",
    "    Red_Perc = np.array(channel_percentiles(red_props, Negatives=False)).T\n",
    "    Green_Perc = np.array(channel_percentiles(green_props, Negatives=False)).T\n",
    "    Blue_Perc = np.array(channel_percentiles(blue_props, Negatives=False)).T\n",
    "    L_Perc = np.array(channel_percentiles(L_props)).T\n",
    "    a_Perc = np.array(channel_percentiles(a_props, Negatives=True)).T\n",
    "    b_Perc = np.array(channel_percentiles(b_props, Negatives=True)).T\n",
    "    H_Perc = np.array(channel_percentiles(H_props)).T\n",
    "    S_Perc = np.array(channel_percentiles(S_props)).T\n",
    "    V_Perc = np.array(channel_percentiles(V_props)).T\n",
    "\n",
    "    # Dataframe 1: for single obervation per spike\n",
    "    Spikes_per_image = pd.DataFrame(\n",
    "    list(zip(Image_Name, Labels, Areas, MajorAxes, MinorAxes, Orientations, Eccentricities, Perimeters, \n",
    "             red[:,0], red[:,1], red[:,2], green[:,0], green[:,1], green[:,2], blue[:,0], blue[:,1], blue[:,2], \n",
    "             L[:,0], L[:,1], L[:,2], a[:,0], a[:,1], a[:,2], b[:,0], b[:,1], b[:,2], \n",
    "             H[:,0], H[:,1], H[:,2], S[:,0], S[:,1], S[:,2], V[:,0], V[:,1], V[:,2], \n",
    "             Red_Perc[:,0], Red_Perc[:,1], Red_Perc[:,2], Red_Perc[:,3], Red_Perc[:,4], Red_Perc[:,5], Red_Perc[:,6], \n",
    "             Green_Perc[:,0], Green_Perc[:,1], Green_Perc[:,2], Green_Perc[:,3], Green_Perc[:,4], Green_Perc[:,5], Green_Perc[:,6], \n",
    "             Blue_Perc[:,0], Blue_Perc[:,1], Blue_Perc[:,2], Blue_Perc[:,3], Blue_Perc[:,4], Blue_Perc[:,5], Blue_Perc[:,6], \n",
    "             L_Perc[:,0], L_Perc[:,1], L_Perc[:,2], L_Perc[:,3], L_Perc[:,4], L_Perc[:,5], L_Perc[:,6], \n",
    "             a_Perc[:,0], a_Perc[:,1], a_Perc[:,2], a_Perc[:,3], a_Perc[:,4], a_Perc[:,5], a_Perc[:,6], \n",
    "             a_Perc[:,7], a_Perc[:,8], a_Perc[:,9], a_Perc[:,10], a_Perc[:,11], a_Perc[:,12], a_Perc[:,13], \n",
    "             b_Perc[:,0], b_Perc[:,1], b_Perc[:,2], b_Perc[:,3], b_Perc[:,4], b_Perc[:,5], b_Perc[:,6], \n",
    "             b_Perc[:,7], b_Perc[:,8], b_Perc[:,9], b_Perc[:,10], b_Perc[:,11], b_Perc[:,12], b_Perc[:,13],\n",
    "             H_Perc[:,0], H_Perc[:,1], H_Perc[:,2], H_Perc[:,3], H_Perc[:,4], H_Perc[:,5], H_Perc[:,6],\n",
    "             S_Perc[:,0], S_Perc[:,1], S_Perc[:,2], S_Perc[:,3], S_Perc[:,4], S_Perc[:,5], S_Perc[:,6],\n",
    "             V_Perc[:,0], V_Perc[:,1], V_Perc[:,2], V_Perc[:,3], V_Perc[:,4], V_Perc[:,5], V_Perc[:,6])), \n",
    "    columns = ['Image_Name', 'Spike_Label', 'Area', 'MajorAxis', 'MinorAxes', 'Orientation', 'Eccentricity', 'Perimeter', \n",
    "               'Red_mean', 'Red_min', 'Red_max', 'Green_mean', 'Green_min', 'Green_max', 'Blue_mean', 'Blue_min', 'Blue_max', \n",
    "               'L_mean', 'L_min', 'L_max', 'a_mean', 'a_min', 'a_max', 'b_mean', 'b_min', 'b_max',\n",
    "               'H_mean', 'H_min', 'H_max', 'S_mean', 'S_min', 'S_max', 'V_mean', 'V_min', 'V_max', \n",
    "               'Red_p25', 'Red_p50', 'Red_p75', 'Red_Mean', 'Red_sd', 'Red_Min', 'Red_Max', \n",
    "               'Green_p25', 'Green_p50', 'Green_p75', 'Green_Mean', 'Green_sd', 'Green_Min', 'Green_Max', \n",
    "               'Blue_p25', 'Blue_p50', 'Blue_p75', 'Blue_Mean', 'Blue_sd', 'Blue_Min', 'Blue_Max', \n",
    "               'L_p25', 'L_p50', 'L_p75', 'L_Mean', 'L_sd', 'L_Min', 'L_Max', \n",
    "               'a_p25_pos', 'a_p50_pos', 'a_p75_pos', 'a_Mean_pos', 'a_sd_pos', 'a_Min_pos', 'a_Max_pos', \n",
    "               'a_p25_neg', 'a_p50_neg', 'a_p75_neg', 'a_Mean_neg', 'a_sd_neg', 'a_Min_neg', 'a_Max_neg', \n",
    "               'b_p25_pos', 'b_p50_pos', 'b_p75_pos', 'b_Mean_pos', 'b_sd_pos', 'b_Min_pos', 'b_Max_pos', \n",
    "               'b_p25_neg', 'b_p50_neg', 'b_p75_neg', 'b_Mean_neg', 'b_sd_neg', 'b_Min_neg', 'b_Max_neg',\n",
    "               'H_p25', 'H_p50', 'H_p75', 'H_Mean', 'H_sd', 'H_Min', 'H_Max',\n",
    "               'S_p25', 'S_p50', 'S_p75', 'S_Mean', 'S_sd', 'S_Min', 'S_Max',\n",
    "               'V_p25', 'V_p50', 'V_p75', 'V_Mean', 'V_sd', 'V_Min', 'V_Max'])\n",
    "    \n",
    "    Spikes_per_image['Circularity'] = (4 * np.pi * Spikes_per_image['Area']) / (Spikes_per_image['Perimeter'] ** 2)\n",
    "    \n",
    "    # Remove envelope's data  \n",
    "    if rm_envelope==True:\n",
    "        return Spikes_per_image.iloc[1: , :]\n",
    "    else:\n",
    "        return Spikes_per_image\n",
    "\n",
    "\n",
    "# Example:\n",
    "# df = SpikesDF(I, ImagePath=img_name, RemoveBG=False, PrintSpkLabels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cd7829-2f39-45e8-a7bd-ea90186067f2",
   "metadata": {},
   "source": [
    "## `SpkltThresh`\n",
    "Threshold for contour detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb463a5f-52c9-472b-8185-492addd4e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def SpkltThresh(cropped, ResizeFactor=30, thr2=0.8, MinSize=1000):   \n",
    "    \n",
    "    # Check that it's a gray image\n",
    "    if len(cropped_rgb.shape) > 2:\n",
    "        # Convert to gray\n",
    "        cropped_gray = color.rgb2gray(cropped)\n",
    "    else:\n",
    "        cropped_gray = cropped\n",
    "        \n",
    "   \n",
    "    # Reduce image size\n",
    "    im = Image.fromarray((cropped_gray*255).astype(np.uint8))\n",
    "    (width, height) = (im.width // ResizeFactor, im.height // ResizeFactor)\n",
    "    rescaled_spk = im.resize((width, height))\n",
    "\n",
    "    # Increase to original size\n",
    "    (width, height) = (im.width, im.height)\n",
    "    rescaled_spk = rescaled_spk.resize((width, height))\n",
    "    rescaled_spk = np.asarray(rescaled_spk)\n",
    "\n",
    "    # Histogram equalization\n",
    "    rescaled_spk = exposure.equalize_hist(rescaled_spk)\n",
    "\n",
    "    # Blur with a Gaussian\n",
    "    blurred = filters.gaussian(rescaled_spk, sigma=1, preserve_range=True)\n",
    "\n",
    "    # Adaptative equalization\n",
    "    blurred = exposure.equalize_adapthist(blurred)\n",
    "\n",
    "    # Normalize\n",
    "    blurred = cv2.normalize(blurred, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    blurred = blurred.astype(np.uint8)\n",
    "    \n",
    "    if thr2 < 1 == True:\n",
    "        thr2 = thr2*255\n",
    "    else:\n",
    "        thr2 = thr2\n",
    "    \n",
    "    # Threshold at given %\n",
    "    ret, thresh = cv2.threshold(blurred, thr2, 255, 0)\n",
    "    thresh = np.uint8(thresh)\n",
    "    \n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(thresh, connectivity=8)\n",
    "    sizes = stats[1:, -1]; nb_components = nb_components - 1    \n",
    "       \n",
    "    thresh2 = np.zeros((output.shape))\n",
    "    \n",
    "    # Keep only objects with minimum size\n",
    "    for i in range(0, nb_components):\n",
    "        if sizes[i] >= MinSize:\n",
    "            thresh2[output == i + 1] = 255\n",
    "    \n",
    "#     plt.imshow(thresh2)\n",
    "    thresh2 = np.uint8(thresh2)\n",
    "    \n",
    "    return thresh2\n",
    "\n",
    "# Example:\n",
    "# thresh2 = SpkltThresh(cropped=cropped_rgb, ResizeFactor=30, thr2=0.8, MinSize=1000)\n",
    "# plt.imshow(thresh2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7df58c1-e220-4765-acae-ff315b2d4b68",
   "metadata": {},
   "source": [
    "## `LabelContours`\n",
    "Spike's contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fd7192-e9d5-41ba-8313-f2d1b0ff98da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Spike's contours\n",
    "def LabelContours(cropped_rgb, thresh2, ResizeFactor=30, MinSize = 1000, plot=True, thr2=0.8):\n",
    "    \n",
    "    # Copy iamge\n",
    "    OutImage = cropped_rgb.copy()\n",
    "    \n",
    "    if thresh2 is not None:\n",
    "        thresh2 = thresh2\n",
    "    else:\n",
    "        # Threshold for contours\n",
    "        thresh2 = SpkltThresh(cropped=OutImage, ResizeFactor=ResizeFactor, thr2=thr2, MinSize=MinSize)\n",
    "\n",
    "#     # Threshold for contours\n",
    "#     thresh2 = SpkltThresh(cropped=cropped_rgb, ResizeFactor=30, thr2=thr2, MinSize=MinSize)\n",
    "#     plt.imshow(bw_cont)\n",
    "    \n",
    "    # Enumerate objects\n",
    "    # EnumerateSpkCV(thresh2, OutImage, TextSize=5, TROE2020=False)\n",
    "    \n",
    "#     contours = measure.find_contours(blurred,(0.8*255))\n",
    "    contours, hierarchy = cv2.findContours(thresh2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     len(contours)\n",
    "    \n",
    "    # Detected spikelets\n",
    "    print(\"Detected spikeletes: \", len(contours))\n",
    "    \n",
    "    if plot==True:\n",
    "        img = OutImage.copy()\n",
    "        # Plot all found contours\n",
    "        plot_contours = cv2.drawContours(img, contours, -1, (0,255,0), 10)\n",
    "        plt.imshow(plot_contours)\n",
    "    \n",
    "    return contours\n",
    "\n",
    "# Example:\n",
    "# labels_cont = LabelContours(cropped_rgb, thresh2=thresh2, ResizeFactor=30, MinSize = 1000, thr2=0.8, plot=True)\n",
    "# len(labels_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd54177-543b-446d-a80f-cec749c2580c",
   "metadata": {},
   "source": [
    "## `ObjProps`\n",
    "Object properties. A general function to get properties of labels ROIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040f9e71-535d-4b43-9c02-330b786238df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def ObjProps(labeled, cropped_rgb, cropped_lab, cropped_hsv, ImagePath, MinSize = 1000, rm_envelope=False):\n",
    "    \n",
    "    # Label + regionprops\n",
    "    labeled_contours, num_contours = label(labeled, return_num = True)\n",
    "    props_contours = regionprops(labeled_contours)\n",
    "#     plt.imshow(labeled_contours)\n",
    "\n",
    "    # # Create column with image name\n",
    "    Image_Name = ImagePath.split('\\\\')[-1]\n",
    "    Image_Name = [Image_Name] * num_contours\n",
    "\n",
    "    # Geometric properties\n",
    "    Labels = [rp.label for rp in props_contours]\n",
    "    Areas = [rp.area for rp in props_contours]\n",
    "    MajorAxes = [rp.major_axis_length for rp in props_contours]\n",
    "    MinorAxes = [rp.minor_axis_length for rp in props_contours]\n",
    "    Orientations = [rp.orientation for rp in props_contours]\n",
    "    Perimeters = [rp.perimeter for rp in props_contours]\n",
    "    Eccentricities = [rp.eccentricity for rp in props_contours]\n",
    "\n",
    "    # Spectral properties\n",
    "    red_props = regionprops(labeled_contours, intensity_image=cropped_rgb[:,:,0])\n",
    "    green_props = regionprops(labeled_contours, intensity_image=cropped_rgb[:,:,1])\n",
    "    blue_props = regionprops(labeled_contours, intensity_image=cropped_rgb[:,:,2])\n",
    "    L_props = regionprops(labeled_contours, intensity_image=cropped_lab[:,:,0])\n",
    "    a_props = regionprops(labeled_contours, intensity_image=cropped_lab[:,:,1])\n",
    "    b_props = regionprops(labeled_contours, intensity_image=cropped_lab[:,:,2])\n",
    "    H_props = regionprops(labeled_spks, intensity_image=cropped_hsv[:,:,0])\n",
    "    S_props = regionprops(labeled_spks, intensity_image=cropped_hsv[:,:,1])\n",
    "    V_props = regionprops(labeled_spks, intensity_image=cropped_hsv[:,:,2])\n",
    "    \n",
    "    red = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in red_props])\n",
    "    green = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in green_props])\n",
    "    blue = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in blue_props])\n",
    "    L = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in L_props])\n",
    "    a = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in a_props])\n",
    "    b = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in b_props])\n",
    "    H = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in H_props])\n",
    "    S = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in S_props])\n",
    "    V = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in V_props])\n",
    "    \n",
    "    Red_Perc = np.array(channel_percentiles(red_props, Negatives=False)).T\n",
    "    Green_Perc = np.array(channel_percentiles(green_props, Negatives=False)).T\n",
    "    Blue_Perc = np.array(channel_percentiles(blue_props, Negatives=False)).T\n",
    "    L_Perc = np.array(channel_percentiles(L_props)).T\n",
    "    a_Perc = np.array(channel_percentiles(a_props, Negatives=True)).T\n",
    "    b_Perc = np.array(channel_percentiles(b_props, Negatives=True)).T\n",
    "    H_Perc = np.array(channel_percentiles(H_props)).T\n",
    "    S_Perc = np.array(channel_percentiles(S_props)).T\n",
    "    V_Perc = np.array(channel_percentiles(V_props)).T\n",
    "\n",
    "    # Dataframe 1: for single obervation per spike\n",
    "    Spikes_per_image = pd.DataFrame(\n",
    "    list(zip(Image_Name, Labels, Areas, MajorAxes, MinorAxes, Orientations, Eccentricities, Perimeters, \n",
    "             red[:,0], red[:,1], red[:,2], green[:,0], green[:,1], green[:,2], blue[:,0], blue[:,1], blue[:,2], \n",
    "             L[:,0], L[:,1], L[:,2], a[:,0], a[:,1], a[:,2], b[:,0], b[:,1], b[:,2], \n",
    "             H[:,0], H[:,1], H[:,2], S[:,0], S[:,1], S[:,2], V[:,0], V[:,1], V[:,2], \n",
    "             Red_Perc[:,0], Red_Perc[:,1], Red_Perc[:,2], Red_Perc[:,3], Red_Perc[:,4], Red_Perc[:,5], Red_Perc[:,6], \n",
    "             Green_Perc[:,0], Green_Perc[:,1], Green_Perc[:,2], Green_Perc[:,3], Green_Perc[:,4], Green_Perc[:,5], Green_Perc[:,6], \n",
    "             Blue_Perc[:,0], Blue_Perc[:,1], Blue_Perc[:,2], Blue_Perc[:,3], Blue_Perc[:,4], Blue_Perc[:,5], Blue_Perc[:,6], \n",
    "             L_Perc[:,0], L_Perc[:,1], L_Perc[:,2], L_Perc[:,3], L_Perc[:,4], L_Perc[:,5], L_Perc[:,6], \n",
    "             a_Perc[:,0], a_Perc[:,1], a_Perc[:,2], a_Perc[:,3], a_Perc[:,4], a_Perc[:,5], a_Perc[:,6], \n",
    "             a_Perc[:,7], a_Perc[:,8], a_Perc[:,9], a_Perc[:,10], a_Perc[:,11], a_Perc[:,12], a_Perc[:,13], \n",
    "             b_Perc[:,0], b_Perc[:,1], b_Perc[:,2], b_Perc[:,3], b_Perc[:,4], b_Perc[:,5], b_Perc[:,6], \n",
    "             b_Perc[:,7], b_Perc[:,8], b_Perc[:,9], b_Perc[:,10], b_Perc[:,11], b_Perc[:,12], b_Perc[:,13],\n",
    "             H_Perc[:,0], H_Perc[:,1], H_Perc[:,2], H_Perc[:,3], H_Perc[:,4], H_Perc[:,5], H_Perc[:,6],\n",
    "             S_Perc[:,0], S_Perc[:,1], S_Perc[:,2], S_Perc[:,3], S_Perc[:,4], S_Perc[:,5], S_Perc[:,6],\n",
    "             V_Perc[:,0], V_Perc[:,1], V_Perc[:,2], V_Perc[:,3], V_Perc[:,4], V_Perc[:,5], V_Perc[:,6])), \n",
    "    columns = ['Image_Name', 'Spike_Label', 'Area', 'MajorAxis', 'MinorAxes', 'Orientation', 'Eccentricity', 'Perimeter', \n",
    "               'Red_mean', 'Red_min', 'Red_max', 'Green_mean', 'Green_min', 'Green_max', 'Blue_mean', 'Blue_min', 'Blue_max', \n",
    "               'L_mean', 'L_min', 'L_max', 'a_mean', 'a_min', 'a_max', 'b_mean', 'b_min', 'b_max',\n",
    "               'H_mean', 'H_min', 'H_max', 'S_mean', 'S_min', 'S_max', 'V_mean', 'V_min', 'V_max', \n",
    "               'Red_p25', 'Red_p50', 'Red_p75', 'Red_Mean', 'Red_sd', 'Red_Min', 'Red_Max', \n",
    "               'Green_p25', 'Green_p50', 'Green_p75', 'Green_Mean', 'Green_sd', 'Green_Min', 'Green_Max', \n",
    "               'Blue_p25', 'Blue_p50', 'Blue_p75', 'Blue_Mean', 'Blue_sd', 'Blue_Min', 'Blue_Max', \n",
    "               'L_p25', 'L_p50', 'L_p75', 'L_Mean', 'L_sd', 'L_Min', 'L_Max', \n",
    "               'a_p25_pos', 'a_p50_pos', 'a_p75_pos', 'a_Mean_pos', 'a_sd_pos', 'a_Min_pos', 'a_Max_pos', \n",
    "               'a_p25_neg', 'a_p50_neg', 'a_p75_neg', 'a_Mean_neg', 'a_sd_neg', 'a_Min_neg', 'a_Max_neg', \n",
    "               'b_p25_pos', 'b_p50_pos', 'b_p75_pos', 'b_Mean_pos', 'b_sd_pos', 'b_Min_pos', 'b_Max_pos', \n",
    "               'b_p25_neg', 'b_p50_neg', 'b_p75_neg', 'b_Mean_neg', 'b_sd_neg', 'b_Min_neg', 'b_Max_neg',\n",
    "               'H_p25', 'H_p50', 'H_p75', 'H_Mean', 'H_sd', 'H_Min', 'H_Max',\n",
    "               'S_p25', 'S_p50', 'S_p75', 'S_Mean', 'S_sd', 'S_Min', 'S_Max',\n",
    "               'V_p25', 'V_p50', 'V_p75', 'V_Mean', 'V_sd', 'V_Min', 'V_Max'])\n",
    "\n",
    "    Objects_per_image['Circularity'] = (4 * np.pi * Objects_per_image['Area']) / (Objects_per_image['Perimeter'] ** 2)\n",
    "\n",
    "    \n",
    "    # Unique labels\n",
    "    labels2 = np.unique(labeled[labeled > 0])\n",
    "\n",
    "    # Empty list for contours\n",
    "    C = []\n",
    "\n",
    "    # Loop thorugh labels and add to list of contours\n",
    "    for label2 in labels2:\n",
    "            y = labeled==label2\n",
    "            y = y * 255\n",
    "            y = y.astype('uint8')\n",
    "            contours, hierarchy = cv2.findContours(y, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            # len(contours)\n",
    "            contours = np.squeeze(contours)\n",
    "            C.append(contours)\n",
    "        \n",
    "    # List for angles\n",
    "    Slopes = []\n",
    "    \n",
    "    contours = C    \n",
    "\n",
    "    for c in contours:\n",
    "\n",
    "        ellipse = cv2.fitEllipse(c)\n",
    "\n",
    "        # Fit a line \n",
    "        rows,cols = cropped_rgb.shape[:2]\n",
    "        [vx,vy,x,y] = cv2.fitLine(c, cv2.DIST_L2,0,0.01,0.01);\n",
    "        lefty = int((-x*vy/vx) + y)\n",
    "        righty = int(((cols-x)*vy/vx)+y)\n",
    "\n",
    "        rise = (0,lefty)[1] - (cols-1,righty)[1]\n",
    "        run = cols\n",
    "        Slope = rise/run\n",
    "        Slopes.append(Slope)\n",
    "    \n",
    "    # Add slopes to data frame\n",
    "    Objects_per_image['Spklt_Angle'] = Slopes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Filter by area\n",
    "    Objects_per_image2 = Objects_per_image[Objects_per_image['Area'] > MinSize]\n",
    "    \n",
    "    # Remove first row, corresponding to spikes' envelope\n",
    "    if rm_envelope==True:\n",
    "        return Objects_per_image2.iloc[1: , :]\n",
    "    else:\n",
    "        return Objects_per_image2\n",
    "\n",
    "\n",
    "# plt.imshow(spklts)\n",
    "# Example\n",
    "# Props = ObjProps(spklts, cropped_rgb, cropped_lab, ImagePath=img_name, MinSize = 5000)\n",
    "# Props = ObjProps(labeled=thresh2, cropped_rgb=cropped_rgb, cropped_lab=cropped_lab, ImagePath=img_name, MinSize = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724d650d-67fa-4bce-b3b8-422d06da1e6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `EnhanceImage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b7f9d9-d4d3-4bb6-9e00-5d6b3b5faca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def EnhanceImage(InputImage, Color = None, Contrast = None, Sharp = None):\n",
    "    \n",
    "    # Read image\n",
    "    if isinstance(InputImage, str) == True:\n",
    "        img = iio.imread(InputImage)\n",
    "    else: \n",
    "        img = InputImage\n",
    "    \n",
    "    # RGB enhancement\n",
    "    img0 = Image.fromarray(img)\n",
    "    \n",
    "    # Color seems to be good around 3.5\n",
    "    img1 = ImageEnhance.Color(img0)\n",
    "    if Color is not None:\n",
    "        img1 = img1.enhance(Color)\n",
    "    else:\n",
    "        img1 = img0\n",
    "    \n",
    "    # Contrast\n",
    "    img2 = ImageEnhance.Contrast(img1)\n",
    "    if Contrast is not None:\n",
    "        img2 = img2.enhance(Contrast)\n",
    "    else:\n",
    "        img2 = img1\n",
    "    \n",
    "    # Sharpness (Good ~20 or higher)\n",
    "    img3 = ImageEnhance.Sharpness(img2)    \n",
    "    if Sharp is not None:\n",
    "        img3 = img3.enhance(Sharp)\n",
    "    else:\n",
    "        img3 = img2\n",
    "    \n",
    "    # Final image\n",
    "    img3 = np.array(img3)\n",
    "    \n",
    "    return img3\n",
    "\n",
    "# Example\n",
    "# enh0 = EnhanceImage(InputImage=cropped_rgb, Color = 3, Contrast = None, Sharp = 10)\n",
    "# plt.imshow(enh0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6a830a-5be7-43fd-a4a4-4c4140fd4e8c",
   "metadata": {},
   "source": [
    "## `LabelSpklts`\n",
    "This fuction uses the Watershed algorithm to detect spikelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c4b6d-a4c9-4dcd-92e4-4f51eda2ae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def LabelSpklts(cropped_rgb, MinDist=50, labels_out=True, n_spklt=True, ElliPlot=False, Plot=True):\n",
    "    \n",
    "    # Rescale to 10% of original\n",
    "    rescaled_spk = rescale(cropped_rgb[...], 0.1, preserve_range=False, multichannel=True, anti_aliasing=True)\n",
    "    # plt.imshow(rescaled_spk)\n",
    "\n",
    "    # Erosion\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "    erosion = cv2.erode(rescaled_spk,kernel,iterations = 1)\n",
    "    # plt.imshow(erosion)\n",
    "\n",
    "    # Opening\n",
    "    kernel = np.ones((1,1),np.uint8)\n",
    "    opening = cv2.morphologyEx(erosion, cv2.MORPH_OPEN, kernel, iterations = 10)\n",
    "    # plt.imshow(opening)\n",
    "\n",
    "    # Resize\n",
    "    rescaled_spk2 = Image.fromarray((rescaled_spk * 255).astype(np.uint8))\n",
    "    rescaled_spk2 = rescaled_spk2.resize((cropped_rgb.shape[1],cropped_rgb.shape[0]))\n",
    "    # plt.imshow(rescaled_spk2)\n",
    "    # rescaled_spk2.size\n",
    "    opening = np.asarray(rescaled_spk2)\n",
    "    # plt.imshow(opening)\n",
    "\n",
    "    # Convert rgb to gray\n",
    "    gray_spklts = opening @ [0.2126, 0.7152, 0.0722]\n",
    "    # plt.imshow(gray_spklts)\n",
    "\n",
    "    # Binarize gray\n",
    "    bw_spklts = gray_spklts > 0\n",
    "    # plt.imshow(bw_spklts)\n",
    "\n",
    "    # Get distances\n",
    "    distance = ndi.distance_transform_edt(bw_spklts)\n",
    "    # plt.imshow(-distance)\n",
    "\n",
    "    # Get max peaks\n",
    "    coords = peak_local_max(distance, min_distance=MinDist, labels=bw_spklts)\n",
    "    # plt.imshow(coords)\n",
    "\n",
    "    mask = np.zeros(distance.shape, dtype=bool)\n",
    "    mask[tuple(coords.T)] = True\n",
    "    markers, spikelets = ndi.label(mask)\n",
    "    \n",
    "    # Watershed\n",
    "    labels = watershed(-distance, markers, mask=cropped_spk)\n",
    "#     plt.imshow(labels)\n",
    "\n",
    "    labels2 = np.unique(labels[labels > 0])\n",
    "\n",
    "    C = []\n",
    "\n",
    "    for label in labels2:\n",
    "            y = label_image == label\n",
    "            y = y * 255\n",
    "            y = y.astype('uint8')\n",
    "            contours, hierarchy = cv2.findContours(y, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            # len(contours)\n",
    "            contours = np.squeeze(contours)\n",
    "            C.append(contours)\n",
    "\n",
    "#         plt.imshow(d[2])\n",
    "    \n",
    "    contours = C\n",
    "\n",
    "    if ElliPlot==True and Plot==False:\n",
    "        \n",
    "        OutImage = cropped_rgb.copy()\n",
    "\n",
    "        # Plot all found contours\n",
    "        OutImage = cv2.drawContours(OutImage, contours, -1, (0,0,0), 10);\n",
    "        # plt.imshow(OutImage)\n",
    "\n",
    "        for c in contours:\n",
    "            # Generate random colors\n",
    "            random_channels = (np.random.choice(range(256), size=3))\n",
    "            rr = int(random_channels[0])\n",
    "            rg = int(random_channels[1])\n",
    "            rb = int(random_channels[2])\n",
    "            \n",
    "            ellipse = cv2.fitEllipse(c)\n",
    "            OutImage = cv2.ellipse(OutImage,ellipse,(rr,rg,rb),10);\n",
    "\n",
    "            # Fit a line \n",
    "            rows,cols = OutImage.shape[:2]\n",
    "            [vx,vy,x,y] = cv2.fitLine(c, cv2.DIST_L2,0,0.01,0.01);\n",
    "            lefty = int((-x*vy/vx) + y)\n",
    "            righty = int(((cols-x)*vy/vx)+y)\n",
    "            # OutImage = cv2.line(OutImage,(cols-1,righty),(0,lefty),(rr,rg,rb),3);\n",
    "            \n",
    "            # Slope from tope left, which is is the origin [0,0]\n",
    "            rise = (0,lefty)[1] - (cols-1,righty)[1]\n",
    "            run = cols\n",
    "            Slope = rise/run\n",
    "            Slopes.append(Slope)            \n",
    "        \n",
    "        # Plot\n",
    "        plt.imshow(OutImage)\n",
    "\n",
    "    # Add slopes to data frame\n",
    "    # Props['Spklt_Angle'] = Slopes\n",
    "\n",
    "    if Plot==True and ElliPlot==False:  \n",
    "        # Plot\n",
    "        plt.imshow(labels, cmap=plt.cm.nipy_spectral)\n",
    "        \n",
    "        # Print number of spikelets detected\n",
    "        print('Detected spikelets = ', spikelets)\n",
    "    \n",
    "    # Return labels\n",
    "    if labels_out==True and n_spklt==True:\n",
    "        return labels, spikelets\n",
    "\n",
    "# Example:\n",
    "# spklts, n_spklts= LabelSpklts(cropped_rgb, MinDist=50, labels_out=True, n_spklt=True, ElliPlot=True, Plot=False)\n",
    "# plt.imshow(spklts==2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6177f67-c472-4fc1-a86c-9dc0292018a1",
   "metadata": {},
   "source": [
    "## `CountorProps`\n",
    "Contour properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e1719-4fd9-4c4e-97de-ef956ed170e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def CountorProps(cropped_rgb, thresh2, ImagePath, ResizeFactor=30, MinSize = 1000, thr2=0.8, plot=True, rm_envelope=False):\n",
    "    \n",
    "#     labels_cont = SpkContours(cropped_rgb, ResizeFactor=30, MinSize = 1000, thr2=0.8, plot=True)\n",
    "    \n",
    "    # Copy image\n",
    "    OutImage = cropped_rgb.copy()\n",
    "    # Get lab\n",
    "    OutImageLab = color.rgb2lab(cropped_lab)\n",
    "    \n",
    "    if thresh2 is not None:\n",
    "        thresh2 = thresh2\n",
    "    else:\n",
    "        # Threshold for contours\n",
    "        thresh2 = SpkltThresh(cropped=OutImage, ResizeFactor=ResizeFactor, thr2=thr2, MinSize=MinSize)\n",
    "\n",
    "    #     plt.imshow(thresh2)\n",
    "    \n",
    "    # Enumerate objects\n",
    "#     EnumerateSpkCV(thresh2, OutImage, TextSize=3, TROE2020=False)\n",
    "    \n",
    "#     contours = measure.find_contours(blurred,(0.8*255))\n",
    "    contours, hierarchy = cv2.findContours(thresh2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     len(contours)\n",
    "    # np.array(contours).shape\n",
    "    # Contour properties\n",
    "    Props = ObjProps(labeled=thresh2, cropped_rgb=cropped_rgb, cropped_lab=cropped_lab, ImagePath=ImagePath, rm_envelope=False)\n",
    "    \n",
    "    # Detected spikelets\n",
    "    print(\"Fitted contours: \", len(contours))\n",
    "    \n",
    "    # Create list for slopes\n",
    "    Slopes = []\n",
    "#     len(Slopes)\n",
    "\n",
    "    if plot==True:\n",
    "\n",
    "        # Plot all found contours\n",
    "        OutImage = cv2.drawContours(OutImage, contours, -1, (255,255,255), 10);\n",
    "\n",
    "        for c in contours:\n",
    "            # Generate random colors\n",
    "            random_channels = (np.random.choice(range(256), size=3))\n",
    "            rr = int(random_channels[0])\n",
    "            rg = int(random_channels[1])\n",
    "            rb = int(random_channels[2])\n",
    "            \n",
    "            ellipse = cv2.fitEllipse(c)\n",
    "            OutImage = cv2.ellipse(OutImage,ellipse,(rr,rg,rb),10);\n",
    "\n",
    "            # Fit a line \n",
    "            rows,cols = OutImage.shape[:2]\n",
    "            [vx,vy,x,y] = cv2.fitLine(c, cv2.DIST_L2,0,0.01,0.01);\n",
    "            lefty = int((-x*vy/vx) + y)\n",
    "            righty = int(((cols-x)*vy/vx)+y)\n",
    "            OutImage = cv2.line(OutImage,(cols-1,righty),(0,lefty),(rr,rg,rb),3);\n",
    "            \n",
    "            # Slope from tope left, which is is the origin [0,0]\n",
    "            rise = (0,lefty)[1] - (cols-1,righty)[1]\n",
    "            run = cols\n",
    "            Slope = rise/run\n",
    "            Slopes.append(Slope)            \n",
    "        \n",
    "        # Plot\n",
    "        plt.imshow(OutImage)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        for c in contours:\n",
    "            \n",
    "            ellipse = cv2.fitEllipse(c)\n",
    "            \n",
    "            # Fit a line \n",
    "            rows,cols = OutImage.shape[:2]\n",
    "            [vx,vy,x,y] = cv2.fitLine(c, cv2.DIST_L2,0,0.01,0.01);\n",
    "            lefty = int((-x*vy/vx) + y)\n",
    "            righty = int(((cols-x)*vy/vx)+y)\n",
    "\n",
    "            rise = (0,lefty)[1] - (cols-1,righty)[1]\n",
    "            run = cols\n",
    "            Slope = rise/run\n",
    "            Slopes.append(Slope)\n",
    "    \n",
    "    # Add slopes to data frame\n",
    "    Props['Spklt_Angle'] = Slopes\n",
    "    \n",
    "    # Remove first row, corresponding to spikes' envelope\n",
    "    if rm_envelope==True:\n",
    "        return Props.iloc[1: , :]\n",
    "    else:\n",
    "        return Props\n",
    "\n",
    "\n",
    "\n",
    "# Example:\n",
    "# labels_cont = CountorProps(cropped_rgb, thresh2, ImagePath=img_name, ResizeFactor=30, MinSize = 1000, thr2=0.8, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9620a52-3730-45ae-a9fd-ed068092be9b",
   "metadata": {},
   "source": [
    "## `Heatmat`\n",
    "Heatmaps from a 1d matrix. This is just for fun, at least for now. The idea is to create a matrix $A_{mxm}$ from a vector (or 1d matrix) $a_{m x 1}$, to plot $A$ under changing circumnstances, such as multiplying by increasing scalar, exponentiation, etc. This results in multiple frames that can then used to make a GIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5024d-7efd-4770-bd48-fb2bc6a83d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def Heatmat(a, frames=30):\n",
    "    a = np.array(a)\n",
    "    a = a.reshape(len(a), 1)\n",
    "    aT = a.T\n",
    "    mat = np.multiply(a, aT)\n",
    "#     mata.shape\n",
    "\n",
    "    for frame in range(frames):\n",
    "        if frame < 10:\n",
    "            name = \"./GIFS/img_0\"+str(frame)+\".png\"\n",
    "        elif frame < 100:\n",
    "            name = \"./GIFS/img_00\"+str(frame)+\".png\"\n",
    "        else:\n",
    "            name = \"./GIFS/img_\"+str(frame)+\".png\"\n",
    "        \n",
    "        new_mat = np.log10( 1+(mat**(frame) ) )\n",
    "        sns.heatmap(new_mat)\n",
    "        plt.savefig(name)\n",
    "        plt.close()\n",
    "\n",
    "# Example:\n",
    "# Heatmat(a=Areas, frames=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61f76f6-4791-4127-9fd1-492028f85e7c",
   "metadata": {},
   "source": [
    "## `makeGIF`\n",
    "Create a GIF from images generated by `heatmat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed26f92-b88f-468e-b7a0-818fc2a84f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def makeGIF(filenames, duration = 0.25, out_name=None):\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        images.append(imageio.imread(filename))\n",
    "    imageio.mimsave('./GIFS/GIF.gif', images, duration=duration)\n",
    "\n",
    "\n",
    "# Example:\n",
    "# filenames = glob.glob(\"./GIFS/\" + '*.png', recursive=False)\n",
    "# makeGIF(filenames, duration = 0.25, out_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9043ab-c187-4578-808c-ef2d621c7cc1",
   "metadata": {},
   "source": [
    "## `DistAll`\n",
    "Distances among objects. This calculates the Euclidean distances (using the Pythagorean theorem) between all labeled ROIs given a binary image. If `spike_length` is given, the distances are returned as the proportion from the spike (%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d10901-28ec-46d4-aa40-32d1b789541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def DistAll(bw, HeatMap=True, spike_length=None):\n",
    "    \n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(bw), \n",
    "                                                                               connectivity=8)\n",
    "    # len(centroids[1:][:])\n",
    "    img_center = centroids[0][:]\n",
    "    c_points = centroids[1:][:]\n",
    "    c_df = pd.DataFrame(c_points, columns=[\"x\",\"y\"])\n",
    "    # c_df\n",
    "\n",
    "    # https://stackoverflow.com/questions/57107729/how-to-compute-multiple-euclidean-distances-of-all-points-in-a-dataset\n",
    "\n",
    "    # Consider points as tuples in a list\n",
    "    data = [ (float(x),float(y)) for x,y in c_df[['x', 'y']].values ]\n",
    "\n",
    "    # Create empty list for distances\n",
    "    distances = []\n",
    "\n",
    "    for point in data:\n",
    "\n",
    "        # Compute the Euclidean distance between the current point and all others\n",
    "        euc_dist = [math.sqrt((point[0]-x[0] )**2 + (point[1]-x[1])**2) for x in data]\n",
    "\n",
    "        # Append to list\n",
    "        distances.append(euc_dist)\n",
    "\n",
    "    # Convert list to array\n",
    "    D = np.array(distances)\n",
    "    \n",
    "    if spike_length != None:\n",
    "        # Express it as a fraction from spike length\n",
    "        D = D/spike_length\n",
    "    else:\n",
    "        D = D\n",
    "    \n",
    "    # Heatmap\n",
    "    if HeatMap==True:\n",
    "        sns.heatmap(D)\n",
    "    \n",
    "    return D\n",
    "\n",
    "# Example:\n",
    "# D = DistAll(bw=thresh2, HeatMap=True, spike_length=SL)\n",
    "# D = DistAll(bw=spklts, HeatMap=True, spike_length=SL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05245c3-11ed-4f96-b4a5-5018e5ef02fd",
   "metadata": {},
   "source": [
    "## `imgraph` Graph analysis (under contruction...)\n",
    "Axes: `0` for $x$, `1` for $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fcd8cb-59b0-4458-a2b1-b355a03789fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/54832694/how-to-represent-a-binary-image-as-a-graph-with-the-axis-being-height-and-width\n",
    "\n",
    "def imgraph(image, axis=0):\n",
    "    # image = blurred\n",
    "    # Theshold image if desired (only 2d images)\n",
    "    maxindex = np.argmax(image[:,:], axis=axis)\n",
    "\n",
    "    # Plot graph\n",
    "    plt.plot(image.shape[axis] - maxindex)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f85596-9be7-4923-8803-0a73d67de50b",
   "metadata": {},
   "source": [
    "## `ComparePlots`\n",
    "Compare multiple plots. Plots need to be gathered in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1794c-29b7-4aee-8d74-c9d498ff89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def ComparePlots(rows, cols, ListImages, fontsize=10):\n",
    "    plots = rows * cols\n",
    "    fig, axes = plt.subplots(rows, cols, sharex=True, sharey=True)\n",
    "    ax = axes.ravel()\n",
    "    for i in range(plots):\n",
    "        ax[i].imshow(ListImages[i], cmap='gray')\n",
    "        Title = \"Image \" + str(i)\n",
    "        ax[i].set_title(Title, fontsize=fontsize)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Example:\n",
    "# ComparePlots(3,1,[cropped_rgb, cropped_lab, cropped_hsv])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f7b153-0507-4108-99c0-05de23b13b93",
   "metadata": {},
   "source": [
    "## `SeparateSpikes`\n",
    "Split spikes into images. This function returns as many individual images as labeled in the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82175ae1-dc21-48ef-9d7b-98ee4a702ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def SeparateSpikes(ImagePath, Outfile = None):\n",
    "    \n",
    "    # Remove bakground\n",
    "    I = RemoveBackground(ImagePath, OtsuScaling=0.25, rgb_out=True, gray_out=True, lab_out=False, hsv_out=False, bw_out=True)\n",
    "    rgb0 = I[0]\n",
    "#     # Convert to gray\n",
    "#     gray0 = img0 @ [0.2126, 0.7152, 0.0722]\n",
    "# #     gray0 = img0 @ [0.2126, 0.7152, 0.0722]\n",
    "\n",
    "#     # Threshold\n",
    "#     otsu = filters.threshold_otsu(gray0)\n",
    "#     bw0 = gray0 > otsu\n",
    "#     bw1 = morphology.remove_small_objects(bw0, min_size=1.5e-05 * gray0.shape[0] * gray0.shape[1])\n",
    "    bw0 = I[1]\n",
    "#     plt.imshow(bw1)\n",
    "    # Label spikes\n",
    "    labeled_spks, num_spikes = label(bw0>0, return_num = True)\n",
    "    \n",
    "    # Loop through spikes\n",
    "    for spk in range(1,num_spikes):\n",
    "        \n",
    "        # Select current spike\n",
    "        myspk = labeled_spks == spk\n",
    "\n",
    "        # Crop spike\n",
    "        slice_x, slice_y = ndimage.find_objects(myspk)[0]\n",
    "        cropped_spk = myspk[slice_x, slice_y]\n",
    "        cropped_rgb = rgb0[slice_x, slice_y]\n",
    "        cropped_rgb = np.where(cropped_spk[..., None], cropped_rgb, 0)\n",
    "        \n",
    "        # Add 10 pixels to each border\n",
    "        padded = np.pad(cropped_rgb, pad_width=[(10, 10),(10, 10),(0, 0)], mode='constant')\n",
    "        \n",
    "        # Save image \n",
    "        im = Image.fromarray(padded)\n",
    "        \n",
    "        if Outfile == None:\n",
    "            \n",
    "            Split_Path = ImagePath.split(\"\\\\\")\n",
    "            OutName = Split_Path[-1].replace(\".tif\", \"\")\n",
    "            Split_Path = Split_Path[:-1]\n",
    "            OutDir = '\\\\'.join([str(i) for i in Split_Path])\n",
    "            OutDir = OutDir + \"\\\\IndividualSpikes\\\\\"\n",
    "            path = pathlib.Path(OutDir)\n",
    "            path.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            if spk < 10:\n",
    "                OutName = OutDir + OutName + \"_spk0\" + str(spk) + '.jpg'\n",
    "            else: \n",
    "                OutName = OutDir + OutName + \"_spk\" + str(spk) + '.jpg'\n",
    "        \n",
    "        im.save(OutName)\n",
    "        print(\"Saved image as: \" + OutName)\n",
    "\n",
    "# Example:\n",
    "# SeparateSpikes(ImagePath=img_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82577f0b-3a2b-4fcd-83be-0a755b5ee374",
   "metadata": {},
   "source": [
    "# BATCH EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcea48e9-518c-4e26-8a6a-44edd6706da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ObjProps(labeled, cropped_rgb, cropped_lab, cropped_hsv, ImagePath, MinSize = 1000, rm_envelope=False):\n",
    "    \n",
    "    # Label + regionprops\n",
    "    labeled_contours, num_contours = label(labeled, return_num = True)\n",
    "    props_contours = regionprops(labeled_contours)\n",
    "#     plt.imshow(labeled_contours)\n",
    "\n",
    "    # # Create column with image name\n",
    "    Image_Name = ImagePath.split('\\\\')[-1]\n",
    "    Image_Name = [Image_Name] * num_contours\n",
    "\n",
    "    # Geometric properties\n",
    "    Labels = [rp.label for rp in props_contours]\n",
    "    Areas = [rp.area for rp in props_contours]\n",
    "    MajorAxes = [rp.major_axis_length for rp in props_contours]\n",
    "    MinorAxes = [rp.minor_axis_length for rp in props_contours]\n",
    "    Orientations = [rp.orientation for rp in props_contours]\n",
    "    Perimeters = [rp.perimeter for rp in props_contours]\n",
    "    Eccentricities = [rp.eccentricity for rp in props_contours]\n",
    "\n",
    "    # Spectral properties\n",
    "    red_props = regionprops(labeled_contours, intensity_image=cropped_rgb[:,:,0])\n",
    "    green_props = regionprops(labeled_contours, intensity_image=cropped_rgb[:,:,1])\n",
    "    blue_props = regionprops(labeled_contours, intensity_image=cropped_rgb[:,:,2])\n",
    "    L_props = regionprops(labeled_contours, intensity_image=cropped_lab[:,:,0])\n",
    "    a_props = regionprops(labeled_contours, intensity_image=cropped_lab[:,:,1])\n",
    "    b_props = regionprops(labeled_contours, intensity_image=cropped_lab[:,:,2])\n",
    "    H_props = regionprops(labeled_contours, intensity_image=cropped_hsv[:,:,0])\n",
    "    S_props = regionprops(labeled_contours, intensity_image=cropped_hsv[:,:,1])\n",
    "    V_props = regionprops(labeled_contours, intensity_image=cropped_hsv[:,:,2])\n",
    "    \n",
    "    red = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in red_props])\n",
    "    green = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in green_props])\n",
    "    blue = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in blue_props])\n",
    "    L = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in L_props])\n",
    "    a = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in a_props])\n",
    "    b = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in b_props])\n",
    "    H = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in H_props])\n",
    "    S = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in S_props])\n",
    "    V = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in V_props])\n",
    "    \n",
    "    Red_Perc = np.array(channel_percentiles(red_props, Negatives=False)).T\n",
    "    Green_Perc = np.array(channel_percentiles(green_props, Negatives=False)).T\n",
    "    Blue_Perc = np.array(channel_percentiles(blue_props, Negatives=False)).T\n",
    "    L_Perc = np.array(channel_percentiles(L_props)).T\n",
    "    a_Perc = np.array(channel_percentiles(a_props, Negatives=True)).T\n",
    "    b_Perc = np.array(channel_percentiles(b_props, Negatives=True)).T\n",
    "    H_Perc = np.array(channel_percentiles(H_props)).T\n",
    "    S_Perc = np.array(channel_percentiles(S_props)).T\n",
    "    V_Perc = np.array(channel_percentiles(V_props)).T\n",
    "\n",
    "    # Dataframe 1: for single obervation per spike\n",
    "    Objects_per_image = pd.DataFrame(\n",
    "    list(zip(Image_Name, Labels, Areas, MajorAxes, MinorAxes, Orientations, Eccentricities, Perimeters, \n",
    "             red[:,0], red[:,1], red[:,2], green[:,0], green[:,1], green[:,2], blue[:,0], blue[:,1], blue[:,2], \n",
    "             L[:,0], L[:,1], L[:,2], a[:,0], a[:,1], a[:,2], b[:,0], b[:,1], b[:,2], \n",
    "             H[:,0], H[:,1], H[:,2], S[:,0], S[:,1], S[:,2], V[:,0], V[:,1], V[:,2], \n",
    "             Red_Perc[:,0], Red_Perc[:,1], Red_Perc[:,2], Red_Perc[:,3], Red_Perc[:,4], Red_Perc[:,5], Red_Perc[:,6], \n",
    "             Green_Perc[:,0], Green_Perc[:,1], Green_Perc[:,2], Green_Perc[:,3], Green_Perc[:,4], Green_Perc[:,5], Green_Perc[:,6], \n",
    "             Blue_Perc[:,0], Blue_Perc[:,1], Blue_Perc[:,2], Blue_Perc[:,3], Blue_Perc[:,4], Blue_Perc[:,5], Blue_Perc[:,6], \n",
    "             L_Perc[:,0], L_Perc[:,1], L_Perc[:,2], L_Perc[:,3], L_Perc[:,4], L_Perc[:,5], L_Perc[:,6], \n",
    "             a_Perc[:,0], a_Perc[:,1], a_Perc[:,2], a_Perc[:,3], a_Perc[:,4], a_Perc[:,5], a_Perc[:,6], \n",
    "             a_Perc[:,7], a_Perc[:,8], a_Perc[:,9], a_Perc[:,10], a_Perc[:,11], a_Perc[:,12], a_Perc[:,13], \n",
    "             b_Perc[:,0], b_Perc[:,1], b_Perc[:,2], b_Perc[:,3], b_Perc[:,4], b_Perc[:,5], b_Perc[:,6], \n",
    "             b_Perc[:,7], b_Perc[:,8], b_Perc[:,9], b_Perc[:,10], b_Perc[:,11], b_Perc[:,12], b_Perc[:,13],\n",
    "             H_Perc[:,0], H_Perc[:,1], H_Perc[:,2], H_Perc[:,3], H_Perc[:,4], H_Perc[:,5], H_Perc[:,6],\n",
    "             S_Perc[:,0], S_Perc[:,1], S_Perc[:,2], S_Perc[:,3], S_Perc[:,4], S_Perc[:,5], S_Perc[:,6],\n",
    "             V_Perc[:,0], V_Perc[:,1], V_Perc[:,2], V_Perc[:,3], V_Perc[:,4], V_Perc[:,5], V_Perc[:,6])), \n",
    "    columns = ['Image_Name', 'Spike_Label', 'Area', 'MajorAxis', 'MinorAxes', 'Orientation', 'Eccentricity', 'Perimeter', \n",
    "               'Red_mean', 'Red_min', 'Red_max', 'Green_mean', 'Green_min', 'Green_max', 'Blue_mean', 'Blue_min', 'Blue_max', \n",
    "               'L_mean', 'L_min', 'L_max', 'a_mean', 'a_min', 'a_max', 'b_mean', 'b_min', 'b_max',\n",
    "               'H_mean', 'H_min', 'H_max', 'S_mean', 'S_min', 'S_max', 'V_mean', 'V_min', 'V_max', \n",
    "               'Red_p25', 'Red_p50', 'Red_p75', 'Red_Mean', 'Red_sd', 'Red_Min', 'Red_Max', \n",
    "               'Green_p25', 'Green_p50', 'Green_p75', 'Green_Mean', 'Green_sd', 'Green_Min', 'Green_Max', \n",
    "               'Blue_p25', 'Blue_p50', 'Blue_p75', 'Blue_Mean', 'Blue_sd', 'Blue_Min', 'Blue_Max', \n",
    "               'L_p25', 'L_p50', 'L_p75', 'L_Mean', 'L_sd', 'L_Min', 'L_Max', \n",
    "               'a_p25_pos', 'a_p50_pos', 'a_p75_pos', 'a_Mean_pos', 'a_sd_pos', 'a_Min_pos', 'a_Max_pos', \n",
    "               'a_p25_neg', 'a_p50_neg', 'a_p75_neg', 'a_Mean_neg', 'a_sd_neg', 'a_Min_neg', 'a_Max_neg', \n",
    "               'b_p25_pos', 'b_p50_pos', 'b_p75_pos', 'b_Mean_pos', 'b_sd_pos', 'b_Min_pos', 'b_Max_pos', \n",
    "               'b_p25_neg', 'b_p50_neg', 'b_p75_neg', 'b_Mean_neg', 'b_sd_neg', 'b_Min_neg', 'b_Max_neg',\n",
    "               'H_p25', 'H_p50', 'H_p75', 'H_Mean', 'H_sd', 'H_Min', 'H_Max',\n",
    "               'S_p25', 'S_p50', 'S_p75', 'S_Mean', 'S_sd', 'S_Min', 'S_Max',\n",
    "               'V_p25', 'V_p50', 'V_p75', 'V_Mean', 'V_sd', 'V_Min', 'V_Max'])\n",
    "\n",
    "    Objects_per_image['Circularity'] = (4 * np.pi * Objects_per_image['Area']) / (Objects_per_image['Perimeter'] ** 2)\n",
    "\n",
    "    \n",
    "    # Unique labels\n",
    "    labels2 = np.unique(labeled[labeled > 0])\n",
    "\n",
    "    # Empty list for contours\n",
    "    C = []\n",
    "\n",
    "    # Loop thorugh labels and add to list of contours\n",
    "    for label2 in labels2:\n",
    "            y = labeled==label2\n",
    "            y = y * 255\n",
    "            y = y.astype('uint8')\n",
    "            contours, hierarchy = cv2.findContours(y, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            # len(contours)\n",
    "            contours = np.squeeze(contours)\n",
    "            C.append(contours)\n",
    "        \n",
    "    # List for angles\n",
    "    Slopes = []\n",
    "    \n",
    "    contours = C    \n",
    "\n",
    "    for c in contours:\n",
    "\n",
    "        ellipse = cv2.fitEllipse(c)\n",
    "\n",
    "        # Fit a line \n",
    "        rows,cols = cropped_rgb.shape[:2]\n",
    "        [vx,vy,x,y] = cv2.fitLine(c, cv2.DIST_L2,0,0.01,0.01);\n",
    "        lefty = int((-x*vy/vx) + y)\n",
    "        righty = int(((cols-x)*vy/vx)+y)\n",
    "\n",
    "        rise = (0,lefty)[1] - (cols-1,righty)[1]\n",
    "        run = cols\n",
    "        Slope = rise/run\n",
    "        Slopes.append(Slope)\n",
    "    \n",
    "    # Add slopes to data frame\n",
    "    Objects_per_image['WS_Angle'] = Slopes\n",
    "    \n",
    "\n",
    "\n",
    "def CountorProps(cropped_rgb, cropped_lab, cropped_hsv, thresh2, ImagePath, ResizeFactor=30, MinSize = 1000, thr2=0.8, plot=True, rm_envelope=False):\n",
    "    \n",
    "#     labels_cont = SpkContours(cropped_rgb, ResizeFactor=30, MinSize = 1000, thr2=0.8, plot=True)\n",
    "    \n",
    "    # Copy image\n",
    "    OutImage = cropped_rgb.copy()\n",
    "    # Get lab\n",
    "    OutImageLab = color.rgb2lab(cropped_lab)\n",
    "    \n",
    "    if thresh2 is not None:\n",
    "        thresh2 = thresh2\n",
    "    else:\n",
    "        # Threshold for contours\n",
    "        thresh2 = SpkltThresh(cropped=OutImage, ResizeFactor=ResizeFactor, thr2=thr2, MinSize=MinSize)\n",
    "\n",
    "    #     plt.imshow(thresh2)\n",
    "    \n",
    "    # Enumerate objects\n",
    "#     EnumerateSpkCV(thresh2, OutImage, TextSize=3, TROE2020=False)\n",
    "    \n",
    "#     contours = measure.find_contours(blurred,(0.8*255))\n",
    "    contours, hierarchy = cv2.findContours(thresh2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     len(contours)\n",
    "    # np.array(contours).shape\n",
    "    # Contour properties\n",
    "    Props = ObjProps(labeled=thresh2, cropped_rgb=cropped_rgb, cropped_lab=cropped_lab, cropped_hsv=cropped_hsv,ImagePath=ImagePath, rm_envelope=False)\n",
    "    \n",
    "    # Detected spikelets\n",
    "    print(\"Fitted contours: \", len(contours))\n",
    "    \n",
    "    # Create list for slopes\n",
    "    Slopes = []\n",
    "#     len(Slopes)\n",
    "\n",
    "    if plot==True:\n",
    "\n",
    "        # Plot all found contours\n",
    "        OutImage = cv2.drawContours(OutImage, contours, -1, (255,255,255), 10);\n",
    "\n",
    "        for c in contours:\n",
    "            # Generate random colors\n",
    "            random_channels = (np.random.choice(range(256), size=3))\n",
    "            rr = int(random_channels[0])\n",
    "            rg = int(random_channels[1])\n",
    "            rb = int(random_channels[2])\n",
    "            \n",
    "            ellipse = cv2.fitEllipse(c)\n",
    "            OutImage = cv2.ellipse(OutImage,ellipse,(rr,rg,rb),10);\n",
    "\n",
    "            # Fit a line \n",
    "            rows,cols = OutImage.shape[:2]\n",
    "            [vx,vy,x,y] = cv2.fitLine(c, cv2.DIST_L2,0,0.01,0.01);\n",
    "            lefty = int((-x*vy/vx) + y)\n",
    "            righty = int(((cols-x)*vy/vx)+y)\n",
    "            OutImage = cv2.line(OutImage,(cols-1,righty),(0,lefty),(rr,rg,rb),3);\n",
    "            \n",
    "            # Slope from tope left, which is is the origin [0,0]\n",
    "            rise = (0,lefty)[1] - (cols-1,righty)[1]\n",
    "            run = cols\n",
    "            Slope = rise/run\n",
    "            Slopes.append(Slope)            \n",
    "        \n",
    "        # Plot\n",
    "        plt.imshow(OutImage)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        for c in contours:\n",
    "            \n",
    "            ellipse = cv2.fitEllipse(c)\n",
    "            \n",
    "            # Fit a line \n",
    "            rows,cols = OutImage.shape[:2]\n",
    "            [vx,vy,x,y] = cv2.fitLine(c, cv2.DIST_L2,0,0.01,0.01);\n",
    "            lefty = int((-x*vy/vx) + y)\n",
    "            righty = int(((cols-x)*vy/vx)+y)\n",
    "\n",
    "            rise = (0,lefty)[1] - (cols-1,righty)[1]\n",
    "            run = cols\n",
    "            Slope = rise/run\n",
    "            Slopes.append(Slope)\n",
    "    \n",
    "    # Add slopes to data frame\n",
    "    Props['Contour_Angle'] = Slopes\n",
    "    \n",
    "    # Remove first row, corresponding to spikes' envelope\n",
    "    if rm_envelope==True:\n",
    "        return Props.iloc[1: , :]\n",
    "    else:\n",
    "        return Props\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06931969-c2f2-439f-86a9-530dba417bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SpykFunctions import *\n",
    "\n",
    "path = r'./Images/TEST'\n",
    "Images = ListImages(path, imgformat=\".tif\", recursive=False)\n",
    "\n",
    "\n",
    "Spikes_data = pd.DataFrame()\n",
    "\n",
    "\n",
    "for img_name in Images:\n",
    "    \n",
    "    Spikes = SpikesDF(i)\n",
    "    \n",
    "    \n",
    "    img_name=Images[0]\n",
    "    print(\"Processing image \", img_name)\n",
    "    \n",
    "    # Remove background and create images\n",
    "    I = RemoveBackground(img_name, OtsuScaling=0.25, rgb_out=True, gray_out=True, lab_out=True, hsv_out=True, bw_out=True)\n",
    "    rgb0 = I[0]\n",
    "    gray0 = I[1]\n",
    "    lab0 = I[2]\n",
    "    hsv0 = I[3]\n",
    "    bw0 = I[4]\n",
    "    \n",
    "    # Enumerate spikes\n",
    "#     EnumerateSpkCV(bw0, rgb0, TextSize=5, TROE2020=False)\n",
    "\n",
    "    # Collect spikes data\n",
    "    df = SpikesDF(I=I, ImagePath=img_name, RemoveBG=False, PrintSpkLabels=False)\n",
    "\n",
    "    # Label spikes\n",
    "    labeled_spks, num_spikes = label(bw0, return_num = True)\n",
    "    # plt.imshow(labeled_spks==2)\n",
    "    # Spike lengths\n",
    "    SpkLengths = []\n",
    "    \n",
    "    # Spike distances from each other\n",
    "    SpkDists = []\n",
    "\n",
    "    # TROE2021 and PGR start at 2. Ignore background (0) and envelope (1)\n",
    "    if TROE2020==False:\n",
    "        FirstSpk = 1\n",
    "    else:\n",
    "        FirstSpk = 2\n",
    "        \n",
    "    # Start at 2 so it ignores background (0) and envelope (1)\n",
    "    for Label in range(FirstSpk, num_spikes+1):\n",
    "        # print(Label)\n",
    "    \n",
    "        # Label=2\n",
    "        print(\"Processing spike \", Label)\n",
    "#         plt.imshow(labeled_spks==2)\n",
    "        \n",
    "        spk = labeled_spks==Label\n",
    "        # plt.imshow(spk)\n",
    "    \n",
    "        # Crop spike\n",
    "        slice_x, slice_y = ndimage.find_objects(spk)[0]\n",
    "        cropped_spk = spk[slice_x, slice_y]\n",
    "        cropped_rgb = rgb0[slice_x, slice_y]\n",
    "        cropped_rgb = np.where(cropped_spk[..., None], cropped_rgb, 0)\n",
    "        cropped_gray = color.rgb2gray(cropped_rgb)\n",
    "        cropped_lab = color.rgb2lab(cropped_rgb)\n",
    "        cropped_hsv = color.rgb2hsv(cropped_rgb)\n",
    "#         plt.imshow(cropped_spk)\n",
    "\n",
    "        # Spike length\n",
    "        sl = spk_length(cropped_spk, method='skelblur', Overlay=False, PlotCH=False)\n",
    "        SpkLengths.append(sl)\n",
    "\n",
    "        # Theshold for detection\n",
    "        thresh2 = SpkltThresh(cropped_rgb, ResizeFactor=30, thr2=0.8, MinSize=1000)\n",
    "\n",
    "        # Distances between contours\n",
    "        D = DistAll(bw=thresh2, HeatMap=False, spike_length=sl)\n",
    "        SpkDists.append(D)\n",
    "\n",
    "        # Contours\n",
    "        labels_cont = CountorProps(cropped_rgb, cropped_lab, cropped_hsv, thresh2, ImagePath=img_name, ResizeFactor=30, MinSize = 1000, thr2=0.8, plot=False)\n",
    "\n",
    "        # Watershed segments\n",
    "        spklts, n_spklts= LabelSpklts(cropped_rgb, MinDist=50, labels_out=True, n_spklt=True, Plot=False)\n",
    "        WSProps = ObjProps(labeled=spklts, cropped_rgb=cropped_rgb, cropped_lab=cropped_lab, cropped_hsv=cropped_hsv, ImagePath=img_name, MinSize = 5000)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# For one spike\n",
    "# labeled_contours, num_contours = label(cropped_spk, return_num = True)\n",
    "# red_props = regionprops(labeled_contours, intensity_image=cropped_rgb)\n",
    "# Red_Perc = np.array(channel_percentiles(channel_props=red_props, Negatives=False)).T\n",
    "# len(Red_Perc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b428e61-c593-436d-84c9-b353e63a4806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ef06330-31d8-410a-9169-178a1b676e31",
   "metadata": {},
   "source": [
    "# DEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aaf017-27fe-466b-a47f-575b04ca3d35",
   "metadata": {},
   "source": [
    "## Files\n",
    "List images and select an image (`img_number`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab2f05-e3b4-48c6-a94f-65fa372b422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# List images\n",
    "path = r'./Images/TEST'\n",
    "Images = ListImages(path, imgformat=\".tif\", recursive=False)\n",
    "len(Images)\n",
    "\n",
    "# Select image\n",
    "img_number = 4\n",
    "img_name = Images[img_number]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc12c20-5a5b-4385-9165-374225c1218a",
   "metadata": {},
   "source": [
    "## Generate mask and color arrays\n",
    "Remove the background and create rgb, gray, lab, hsv, and bw images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d28730-316c-47d6-9d69-01361ad0711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "I = RemoveBackground(img_name, OtsuScaling=0.25, rgb_out=True, gray_out=True, lab_out=True, hsv_out=True, bw_out=True)\n",
    "rgb0 = I[0]\n",
    "gray0 = I[1]\n",
    "lab0 = I[2]\n",
    "hsv0 = I[3]\n",
    "bw0 = I[4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12710e91-33f0-4644-8c60-7d03dd01f0cf",
   "metadata": {},
   "source": [
    "## Enumerate spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3028549e-dff4-483d-b4f6-18d34677eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Enumerate spikes\n",
    "EnumerateSpkCV(bw0, rgb0, TextSize=5, TROE2020=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5ae7c8-f43d-49b0-995d-35a1913ab372",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "PixelHist(bw=bw0, Lab=lab0, channel = 0, spikes=[1,2,26], nbins = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7e1974-0ea2-41e2-b18b-69116cf3da72",
   "metadata": {},
   "source": [
    "## Get spike properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de5c684-fa6e-490b-9e79-5dbf6dfc64e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = SpikesDF(I, ImagePath, RemoveBG=False, PrintSpkLabels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b3565f-c01c-492f-87b4-84242de2c05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df\n",
    "# notice that the envelope (Spike_Label 1) was removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001c2cdd-f6da-4a8b-8bb5-3453f2de2f86",
   "metadata": {},
   "source": [
    "## Select a spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741553fa-d46b-411f-8d06-a7728ae6c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Select a spike from the labeled image\n",
    "Selected_Spike = 26\n",
    "print(\"Selected spike number\", Selected_Spike)\n",
    "\n",
    "# Label spikes\n",
    "labeled_spks, num_spikes = label(bw0, return_num = True)\n",
    "spk = labeled_spks==Selected_Spike\n",
    "\n",
    "# Crop spike\n",
    "slice_x, slice_y = ndimage.find_objects(spk)[0]\n",
    "cropped_spk = spk[slice_x, slice_y]\n",
    "cropped_rgb = rgb0[slice_x, slice_y]\n",
    "cropped_rgb = np.where(cropped_spk[..., None], cropped_rgb, 0)\n",
    "cropped_gray = cropped_rgb @ [0.2126, 0.7152, 0.0722]\n",
    "cropped_lab = color.rgb2lab(cropped_rgb)\n",
    "cropped_hsv = color.rgb2hsv(cropped_rgb)\n",
    "\n",
    "# Visualize selected spike\n",
    "plt.imshow(cropped_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed5bb97-6298-43a4-84bd-a9910cc4278e",
   "metadata": {},
   "source": [
    "## Spike length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628bae6b-c7d7-4d20-b1a9-70051bb9534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "L = spk_length(cropped_spk, method='skelblur', Overlay=True, PlotCH=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0738f1f7-d3e0-4f91-853e-2712fc2e488b",
   "metadata": {},
   "source": [
    "## Threshold for contour detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397283da-49bc-4fae-835c-f7c97632b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "thresh2 = SpkltThresh(cropped=cropped_rgb, ResizeFactor=30, thr2=0.8, MinSize=1000)\n",
    "plt.imshow(thresh2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657d0107-430a-4b43-9de2-ffc2ff246a46",
   "metadata": {},
   "source": [
    "### Contour for spikelet detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb87b431-1a10-4aa6-bec9-16ac0132b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "labels_cont = LabelContours(cropped_rgb, ResizeFactor=30, MinSize = 1000, thr2=0.8, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84b2133-25ab-4ca6-9fe9-0ac294437720",
   "metadata": {},
   "source": [
    "### Get contour properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecfa6b3-da4e-465e-94ed-89e058c25302",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "CountProp = SpkltProps(cropped_rgb=cropped_rgb, ImagePath=img_name, ResizeFactor=30, MinSize = 1000, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef0f59f-0ae0-4f8e-b1f2-313913f10da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CountProp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fa10c4-8886-48dd-99b9-ff6edad42256",
   "metadata": {},
   "source": [
    "### Distance between detected spikelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193f0880-172e-41de-91ef-0ab72afaac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "D = DistAll(bw=thresh2, HeatMap=True, spike_length=SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d7fd7e-5de9-46d6-ba88-d8d99c6040cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnumerateSpkCV(thresh2, cropped_rgb, TextSize=3,  TROE2020=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5677053-159e-4b95-ba5a-d84b9948772d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7726c9e4-1735-4178-9da5-1d25a7ebc5df",
   "metadata": {},
   "source": [
    "## Watershed for spikelet detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492df66e-dcb9-4b5d-b1eb-afc09812d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Using watershed\n",
    "spklts, n_spklts= LabelSpklts(cropped_rgb, MinDist=50, labels_out=True, n_spklt=True, Plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fac288-86eb-4f49-9a5e-f14805d4fd73",
   "metadata": {},
   "source": [
    "### Spikelet properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff71d341-c9fc-4884-b997-b2765aeb0a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "WSProps = ObjProps(labeled=spklts, cropped_rgb=cropped_rgb, cropped_lab=cropped_lab, ImagePath=img_name, MinSize = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c938149-2af9-476c-b6a0-b6a1fc8ee990",
   "metadata": {},
   "outputs": [],
   "source": [
    "WSProps\n",
    "# Notice that the number of rows is lower. That's because the elements with that don't meet MinSize are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba0e65-5ad4-40ca-aaa2-858ff4f05ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9955f6-1082-4e7c-9cdb-01edd75a680d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1badd6c6-9ca5-476e-8ccb-a15c13bd9fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa247d53-3a0e-419e-9f63-fa72aecdaf79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41fb6af-e4f9-492a-88d7-5a71c2301c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d16945-0ea1-48e8-b4cf-906cdb14dccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lined-power",
    "84636ed5-333c-4e53-8eed-28686bef4b27",
    "56270466-2f73-42b9-9f81-d81ca62447c4",
    "c88d716c-beb7-4f95-bfeb-268cc67a0b9c",
    "76be8099-9e4a-4614-9e4f-c805cb126462",
    "b30fd696-0c28-43c7-a0e6-dc72d301492b",
    "cdcc98e4-13e6-49db-9cba-e4941a321292",
    "average-instrumentation"
   ],
   "name": "Spikes_IA.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
