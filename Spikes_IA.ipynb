{"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"name":"Spikes_IA.ipynb","provenance":[],"collapsed_sections":["lined-power","84636ed5-333c-4e53-8eed-28686bef4b27","56270466-2f73-42b9-9f81-d81ca62447c4","c88d716c-beb7-4f95-bfeb-268cc67a0b9c","76be8099-9e4a-4614-9e4f-c805cb126462","b30fd696-0c28-43c7-a0e6-dc72d301492b","cdcc98e4-13e6-49db-9cba-e4941a321292","average-instrumentation"]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"toc-autonumbering":true},"cells":[{"cell_type":"markdown","metadata":{"id":"packed-shanghai"},"source":["# Guide to Analyze Spike Properties\n","This file is meant to ilustrate the data collected in each single spike using SpykProps.\n","\n"],"id":"packed-shanghai"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hNzyEWWvYgWP","executionInfo":{"status":"ok","timestamp":1635442475345,"user_tz":300,"elapsed":29261,"user":{"displayName":"Joan Barreto Ortiz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03887754532873831078"}},"outputId":"2c8b5a5f-4218-464a-aba6-1c2ca1833301"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"hNzyEWWvYgWP","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"kDCJPXr1azrf"},"source":["import sys\n","sys.path.append('/content/drive/MyDrive/M.Sc/THESIS/ImageAnalysis/SpikeProperties/Spyk_Prop')\n","sys.path"],"id":"kDCJPXr1azrf","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IYipVKCzbpUM"},"source":["pip install skan"],"id":"IYipVKCzbpUM","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ca5c0465-9452-49f0-afdc-25d779168805"},"source":["# Dependencies"],"id":"ca5c0465-9452-49f0-afdc-25d779168805"},{"cell_type":"code","metadata":{"id":"695bd235-2d6f-4e4d-a762-45e8c3646d77"},"source":["from SpykFunctions import *"],"id":"695bd235-2d6f-4e4d-a762-45e8c3646d77","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"encouraging-personal","scrolled":true,"tags":[]},"source":["# Import dependencies\n","\n","\n","from SpykFunctions import *\n","\n","from glob import glob\n","import os\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import cv2\n","import math\n","import pathlib\n","\n","from skimage import measure, segmentation, color\n","from skimage.morphology import skeletonize, thin\n","from skimage.future import graph\n","from skimage.segmentation import watershed, active_contour\n","from skimage.feature import peak_local_max\n","from skimage.filters import meijering, sato, frangi, hessian, gaussian\n","from skimage.color import rgb2gray\n","from skimage.transform import hough_line, hough_line_peaks, probabilistic_hough_line\n","from skimage.draw import line\n","\n","from PIL import Image\n","\n","from skan import Skeleton, summarize, skeleton_to_csgraph, draw\n","\n","import seaborn as sns\n","\n","import imutils\n","\n","import imageio\n","\n","import random\n","\n","\n","\n","# import astropy.units as u\n","# from fil_finder import FilFinder2D\n","# from astropy.io import fits\n","\n","# Make sure Jupyter Notebook shows all outputs from the same cell\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\""],"id":"encouraging-personal","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"capital-venice","tags":[]},"source":["# Change the \"%matplotlib inline\" figure resolution on the notebook\n","import matplotlib as mpl\n","mpl.rcParams['figure.dpi']= 300"],"id":"capital-venice","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d75c3d30-4d58-4562-9317-253e91e116dd"},"source":["# Get files"],"id":"d75c3d30-4d58-4562-9317-253e91e116dd"},{"cell_type":"code","metadata":{"id":"needed-sunrise"},"source":["# Define image folder\n","mypath = r'./Images/TEST'\n","# mypath = r'/content/drive/MyDrive/M.Sc/THESIS/ImageAnalysis/SpikeProperties/Spyk_Prop/Images/TEST'\n","Images = glob.glob(mypath + '/**/*.tif', recursive=True)"],"id":"needed-sunrise","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cardiovascular-zealand"},"source":["len(Images)"],"id":"cardiovascular-zealand","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7d90bcc3-bc56-4338-a176-842d8b3070e7"},"source":["## Select an image"],"id":"7d90bcc3-bc56-4338-a176-842d8b3070e7"},{"cell_type":"code","metadata":{"id":"whole-special"},"source":["%%time\n","# Open and image and remove background\n","img0_name = Images[3]\n","# plt.imshow(plt.imread(img0_name))\n","img0 = RemoveBackground(img0_name, OtsuScaling=0.25)"],"id":"whole-special","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pharmaceutical-terrace"},"source":["# plt.imshow(plt.imread(img0_name))\n","plt.imshow(img0)"],"id":"pharmaceutical-terrace","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"confidential-benchmark"},"source":["# mpl.rcParams['figure.dpi']= 300\n","# plt.imshow(img0)"],"id":"confidential-benchmark","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"confident-detective"},"source":["# Convert to gray\n","gray0 = img0 @ [0.2126, 0.7152, 0.0722]\n","   \n","# Threshold\n","otsu = filters.threshold_otsu(gray0)\n","bw0 = gray0 > 0\n","bw1 = morphology.remove_small_objects(bw0, min_size=1.5e-05 * gray0.shape[0] * gray0.shape[1])\n","\n","# Get Lab values\n","img1 = np.where(bw1[..., None], img0, 0)\n","Lab = color.rgb2lab(img1)"],"id":"confident-detective","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"41ab3542-cccb-4756-ac16-ca8d30cf676a"},"source":["# plt.imshow(Lab)"],"id":"41ab3542-cccb-4756-ac16-ca8d30cf676a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1dda47fe-b4fd-45d0-abc5-9e9ba097fec2"},"source":["plt.imshow(bw1)\n","otsu"],"id":"1dda47fe-b4fd-45d0-abc5-9e9ba097fec2","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aa4e45a8-7ef3-4ede-9140-9b2334b42878"},"source":["# plt.imshow(bw1)"],"id":"aa4e45a8-7ef3-4ede-9140-9b2334b42878","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8e5d8d0c-ef56-4323-b906-785f624113f1"},"source":["## Enumerate (label) spikes"],"id":"8e5d8d0c-ef56-4323-b906-785f624113f1"},{"cell_type":"markdown","metadata":{"id":"da7e30c1-fcc0-472d-aa07-61e1c164295b"},"source":["**NOTE:** Spike number starts at 0 in TROE2020, and at 1 in TROE2021. For the latter, object 0 is the envelop."],"id":"da7e30c1-fcc0-472d-aa07-61e1c164295b"},{"cell_type":"code","metadata":{"id":"banned-coordination"},"source":["%%time\n","def EnumerateSpk(bw, TROE2020=False):\n","    \n","    # Regionprops\n","    labels, n_labels = label(bw, return_num = True)\n","    props = regionprops(labels)\n","\n","    # Visualize spike number\n","    fig, ax = plt.subplots()\n","    ax.imshow(bw, cmap=plt.cm.gray)\n","    \n","    if TROE2020 == True:\n","        spike_ind = 1\n","    else:\n","        spike_ind = 0\n","\n","    for props in props_spikes:\n","        y0, x0 = props.centroid\n","        plt.text(x0, y0, str(spike_ind), color=\"red\", fontsize=15)\n","        spike_ind += 1 \n","\n","def EnumerateSpkCV(bw, rgb, TextSize=5, TROE2020=False):\n","    \n","    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(bw), connectivity=8)\n","\n","    img = rgb.copy()\n","    counter=-1\n","    for c in centroids:\n","#         print(c)\n","        cx = round(c[0])\n","        cy = round(c[1])\n","        img = cv2.circle(img, (cx, cy), 10, (255, 0, 0), -1)\n","        img = cv2.putText(img, str(counter), (cx - 25, cy - 25),cv2.FONT_HERSHEY_SIMPLEX, TextSize, (255, 0, 0), 15)\n","        counter = counter+1\n","    plt.imshow(img)"],"id":"banned-coordination","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"564fd497-efa7-49c4-b7d3-7cfa8693ddfb"},"source":["%%time\n","EnumerateSpk(bw1,TROE2020=False)"],"id":"564fd497-efa7-49c4-b7d3-7cfa8693ddfb","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d04dcb47-e048-45ff-aaea-5ace5164bb08"},"source":["%%time\n","EnumerateSpkCV(bw1, img0, TROE2020=False)\n","# This one is faster because doesn't require regionprops"],"id":"d04dcb47-e048-45ff-aaea-5ace5164bb08","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6a376338-eea4-4588-b6d0-1b586057e399"},"source":["# plt.imshow(labeled_spks==1, cmap=plt.cm.gray)"],"id":"6a376338-eea4-4588-b6d0-1b586057e399","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"37d9ee82-c3f3-47c0-8b90-64f45972271c"},"source":["## Select a spike"],"id":"37d9ee82-c3f3-47c0-8b90-64f45972271c"},{"cell_type":"code","metadata":{"id":"ac976883-ef60-4500-b8e1-9ee2fe07d4dd"},"source":["%%time\n","\n","# Select a spike from the labeled image\n","Selected_Spike = 13\n","spk = labeled_spks==Selected_Spike+1\n","\n","# Crop spike\n","slice_x, slice_y = ndimage.find_objects(spk)[0]\n","cropped_spk = spk[slice_x, slice_y]\n","cropped_rgb = img0[slice_x, slice_y]\n","cropped_rgb = np.where(cropped_spk[..., None], cropped_rgb, 0)\n","cropped_gray = cropped_rgb @ [0.2126, 0.7152, 0.0722]\n","cropped_lab = color.rgb2lab(cropped_rgb)\n","plt.imshow(cropped_rgb)\n","# plt.imshow(cropped_gray)\n","\n","# Plot selected spike\n","# plt.imshow(cropped_spk)\n","\n","## Add 100 pixels to each border (optional)\n","# padded = np.pad(cropped_spk, ((100,100), (100,100)))\n","# plt.imshow(padded)"],"id":"ac976883-ef60-4500-b8e1-9ee2fe07d4dd","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"02f14d59-bf1d-4b86-ae62-f784e7c69466"},"source":[""],"id":"02f14d59-bf1d-4b86-ae62-f784e7c69466","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1f2e71b9-5a99-41c5-bf1f-97bf59f40c3a"},"source":[""],"id":"1f2e71b9-5a99-41c5-bf1f-97bf59f40c3a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8d11208e-b1ad-480c-a9b9-b0025a67f966"},"source":[""],"id":"8d11208e-b1ad-480c-a9b9-b0025a67f966","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6e02ceae-4610-4d43-8bd2-10a993bbf601"},"source":[""],"id":"6e02ceae-4610-4d43-8bd2-10a993bbf601","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"47663a5d-0f73-423c-b822-dab53c5030c3"},"source":[""],"id":"47663a5d-0f73-423c-b822-dab53c5030c3","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"acute-grenada"},"source":["# Plot pixel distributions\n","## CIE Lab Color Space"],"id":"acute-grenada"},{"cell_type":"code","metadata":{"id":"japanese-needle"},"source":["%%time\n","# L* channel (Luminosity)\n","PixelHist(labeled_spks, Lab, 0, 250)\n","# Single spike\n","# PixelHist(spk, Lab, 0, 250)"],"id":"japanese-needle","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"loaded-notice"},"source":["# a* channel. Green (-a) to Red (+a)\n","PixelHist(labeled_spks, Lab, 1)"],"id":"loaded-notice","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fiscal-bruce"},"source":["# b* channel. Blue (-b) to Yellow (+b)\n","PixelHist(labeled_spks, Lab, 2, nbins = 250)"],"id":"fiscal-bruce","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lined-power"},"source":["## RGB Color Space"],"id":"lined-power"},{"cell_type":"code","metadata":{"id":"loaded-georgia"},"source":["# Red channel\n","PixelHist(labeled_spks, img0, 0)"],"id":"loaded-georgia","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a3a293eb-0498-4f36-9803-69018332115b"},"source":["# Green channel\n","PixelHist(labeled_spks, img0, 1)"],"id":"a3a293eb-0498-4f36-9803-69018332115b","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"exempt-dodge"},"source":["# Blue channel\n","PixelHist(labeled_spks, img0, 2)"],"id":"exempt-dodge","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"peripheral-efficiency"},"source":[""],"id":"peripheral-efficiency","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4d98d2f4-b963-4376-a884-0553f57b696f","tags":[]},"source":["# Detecting Length"],"id":"4d98d2f4-b963-4376-a884-0553f57b696f"},{"cell_type":"markdown","metadata":{"id":"d6396dd7-037f-4686-a5a4-0e00de764a8d"},"source":["## Define function\n","The function has two possible methods, the skeleton of a blurry image (`skelblur`) or the skeleton of a convexhull (`chull`). First one is more accurate and faster."],"id":"d6396dd7-037f-4686-a5a4-0e00de764a8d"},{"cell_type":"code","metadata":{"id":"993dec09-e2f1-4bc3-9101-13456a8ae015"},"source":["def spk_length(spk, method='skelblur', Overlay=True, PlotCH=False):\n","    \n","    if method=='skelblur':\n","        # Severly blur the image\n","        blur = cv2.blur(np.float32(spk),(100,100))\n","        # Threshold the blur\n","        thrb = blur > 0.1\n","        skeleton = skeletonize(thrb)\n","#         plt.imshow(skeleton)\n","        \n","    if method=='chull':\n","        # Blur the image with a 50x50 kernel\n","        blur = cv2.blur(np.float32(spk),(50,50))\n","\n","        # Get convex hull \n","        chull = convex_hull_image(blur>0)\n","\n","        # Perform skeletonization\n","        image = chull\n","        skeleton = skeletonize(image)\n","    #     plt.imshow(skeleton)\n","    \n","    # Spike length\n","    SpkL = cv2.countNonZero(np.float32(skeleton))\n","    \n","    if PlotCH == True:\n","        fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n","        ax = axes.ravel()\n","\n","        ax[0].set_title('Original picture')\n","        ax[0].imshow(spk, cmap=plt.cm.gray)\n","        ax[0].set_axis_off()\n","\n","        ax[1].set_title('Transformed picture')\n","        ax[1].imshow(chull, cmap=plt.cm.gray)\n","        ax[1].set_axis_off()\n","\n","        plt.tight_layout()\n","        plt.show()\n","    \n","    # Visualize overlay?\n","    if Overlay == True:\n","        overlay_images = cv2.addWeighted(np.float32(spk),20,np.float32(skeleton),255,0)\n","        plt.imshow(overlay_images, cmap='gray')\n","    \n","    return SpkL\n","    \n","    "],"id":"993dec09-e2f1-4bc3-9101-13456a8ae015","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"304fe381-0bee-4a06-9345-d489c93a063e"},"source":["## Execution on selected spike"],"id":"304fe381-0bee-4a06-9345-d489c93a063e"},{"cell_type":"code","metadata":{"id":"f56c4bd1-ebc6-4491-8de9-69c93db83c0f"},"source":["%%time\n","spkl = spk_length(cropped_spk, Overlay=True)\n","print('\\n', 'Approximated spike length =',spkl, 'pixels', '\\n')"],"id":"f56c4bd1-ebc6-4491-8de9-69c93db83c0f","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6bf28bb1-8326-46df-addc-9b8c9e86bcdb"},"source":["# Skeletonize"],"id":"6bf28bb1-8326-46df-addc-9b8c9e86bcdb"},{"cell_type":"markdown","metadata":{"id":"a41d7663-a352-46be-bb75-e726cc43e78a"},"source":["## Resize"],"id":"a41d7663-a352-46be-bb75-e726cc43e78a"},{"cell_type":"code","metadata":{"id":"5f263a94-5d31-4f0e-9166-e85527b1cb68"},"source":["%%time\n","rescaled_spk = rescale(cropped_gray, 0.1, preserve_range=True, multichannel=False, anti_aliasing=True)\n","# plt.imshow(rescaled_spk)\n","# np.amax(rescaled_spk)\n","\n","# Image.resize(size, resample=None, box=None, reducing_gap=None)\n","\n","# Reduce image size\n","im = Image.fromarray((cropped_gray).astype(np.uint8))\n","(width, height) = (im.width // 30, im.height // 30)\n","rescaled_spk2 = im.resize((width, height))\n","\n","# Increase to original size\n","(width, height) = (im.width, im.height)\n","rescaled_spk2 = rescaled_spk2.resize((width, height))\n","plt.imshow(rescaled_spk2)\n","rescaled_spk2 = np.asarray(rescaled_spk2)\n","\n","# rescaled_spk2 = Image.fromarray((rescaled_spk).astype(np.uint8))\n","# rescaled_spk2 = rescaled_spk2.resize((cropped_rgb.shape[1],cropped_rgb.shape[0]))\n","# # plt.imshow(rescaled_spk2)\n","# # rescaled_spk2.size\n","# opening = np.asarray(rescaled_spk2)"],"id":"5f263a94-5d31-4f0e-9166-e85527b1cb68","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fcc22423-7f53-43a2-afc2-1010249bd81f"},"source":["## Equalization and blurring"],"id":"fcc22423-7f53-43a2-afc2-1010249bd81f"},{"cell_type":"code","metadata":{"id":"88350489-5acc-4589-a042-227dcd1d1d87"},"source":["# Histogram equalization\n","rescaled_spk3 = exposure.equalize_hist(rescaled_spk2)\n","\n","# Blur with a Gaussian\n","blurred = filters.gaussian(rescaled_spk3, sigma=1, preserve_range=True)\n","\n","# Adaptative equalization\n","blurred = exposure.equalize_adapthist(blurred)\n","\n","# Normalize\n","blurred = cv2.normalize(blurred, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n","blurred = blurred.astype(np.uint8)\n","\n","plt.imshow(blurred)"],"id":"88350489-5acc-4589-a042-227dcd1d1d87","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"829a3c2a-4e9a-4876-a8be-0d8d683f0d8c"},"source":["## Thresholding"],"id":"829a3c2a-4e9a-4876-a8be-0d8d683f0d8c"},{"cell_type":"code","metadata":{"id":"83ebc007-d673-4386-9e31-c2aa470e8be2"},"source":["# Threshold at 80%\n","ret, thresh = cv2.threshold(blurred, 0.8*255, 255, 0)\n","thresh = np.uint8(thresh)\n","\n","nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(thresh, connectivity=8)\n","sizes = stats[1:, -1]; nb_components = nb_components - 1    \n","\n","thresh2 = np.zeros((output.shape))\n","#for every component in the image, you keep it only if it's above min_size\n","for i in range(0, nb_components):\n","    if sizes[i] >= MinSize:\n","        thresh2[output == i + 1] = 255\n","\n","\n","thresh2 = np.uint8(thresh2)\n","plt.imshow(thresh2)"],"id":"83ebc007-d673-4386-9e31-c2aa470e8be2","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4170cd1b-a7d0-45e3-8921-7e4ef9c1d8dc"},"source":["## Contours"],"id":"4170cd1b-a7d0-45e3-8921-7e4ef9c1d8dc"},{"cell_type":"code","metadata":{"id":"6bb1eec1-0060-4fb7-998f-553489550a4b"},"source":["def SpkContours(cropped_rgb, ResizeFactor=30, MinSize = 1000, plot=True):\n","    \n","    # Copy iamge\n","    OutImage = cropped_rgb.copy()\n","    \n","    # Convert to gray\n","    cropped_gray = color.rgb2gray(OutImage)\n","    \n","    # Reduce image size\n","    im = Image.fromarray((cropped_gray*255).astype(np.uint8))\n","    (width, height) = (im.width // ResizeFactor, im.height // ResizeFactor)\n","    rescaled_spk = im.resize((width, height))\n","\n","    # Increase to original size\n","    (width, height) = (im.width, im.height)\n","    rescaled_spk = rescaled_spk.resize((width, height))\n","    rescaled_spk = np.asarray(rescaled_spk)\n","\n","    # Histogram equalization\n","    rescaled_spk = exposure.equalize_hist(rescaled_spk)\n","\n","    # Blur with a Gaussian\n","    blurred = filters.gaussian(rescaled_spk, sigma=1, preserve_range=True)\n","\n","    # Adaptative equalization\n","    blurred = exposure.equalize_adapthist(blurred)\n","\n","    # Normalize\n","    blurred = cv2.normalize(blurred, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n","    blurred = blurred.astype(np.uint8)\n","\n","    # Find contours at a constant value of 0.8\n","    \n","    # Threshold at 80%\n","    ret, thresh = cv2.threshold(blurred, 0.8*255, 255, 0)\n","    thresh = np.uint8(thresh)\n","    \n","    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(thresh, connectivity=8)\n","    sizes = stats[1:, -1]; nb_components = nb_components - 1    \n","       \n","    thresh2 = np.zeros((output.shape))\n","    #for every component in the image, you keep it only if it's above min_size\n","    for i in range(0, nb_components):\n","        if sizes[i] >= MinSize:\n","            thresh2[output == i + 1] = 255\n","    \n","#     plt.imshow(thresh2)\n","    thresh2 = np.uint8(thresh2)\n","    \n","    EnumerateSpk(thresh2, OutImage, TROE2020=False)\n","    \n","#     contours = measure.find_contours(blurred,(0.8*255))\n","    contours, hierarchy = cv2.findContours(thresh2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","#     len(contours)\n","    \n","    # Detected spikelets\n","    print(\"Detected spikeletes: \", len(contours))\n","    \n","    if plot==True:\n","        img = OutImage.copy()\n","        # Plot all found contours\n","        plot_contours = cv2.drawContours(img, contours, -1, (0,255,0), 10)\n","        plt.imshow(plot_contours)\n"],"id":"6bb1eec1-0060-4fb7-998f-553489550a4b","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ac8a281-3a1b-4bb0-b986-4f040628f461"},"source":["%%time\n","SpkContours(cropped_rgb, MinSize = 1000)"],"id":"0ac8a281-3a1b-4bb0-b986-4f040628f461","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"261eb2de-bd73-4555-a021-e227272876fe"},"source":["## Spikelet properties"],"id":"261eb2de-bd73-4555-a021-e227272876fe"},{"cell_type":"code","metadata":{"id":"a6bbbfe5-f311-47cd-a5c5-1cafcb9b613a"},"source":["def SpkltProps(cropped_rgb, img_name, ResizeFactor=30, MinSize = 1000, plot=True):\n","    \n","    # Copy image\n","    OutImage = cropped_rgb.copy()\n","    \n","    OutImageLab = color.rgb2lab(OutImage)\n","    \n","    # Convert to gray\n","    cropped_gray = color.rgb2gray(OutImage)\n","    \n","    # Reduce image size\n","    im = Image.fromarray((cropped_gray*255).astype(np.uint8))\n","    (width, height) = (im.width // ResizeFactor, im.height // ResizeFactor)\n","    rescaled_spk = im.resize((width, height))\n","\n","    # Increase to original size\n","    (width, height) = (im.width, im.height)\n","    rescaled_spk = rescaled_spk.resize((width, height))\n","    rescaled_spk = np.asarray(rescaled_spk)\n","\n","    # Histogram equalization\n","    rescaled_spk = exposure.equalize_hist(rescaled_spk)\n","\n","    # Blur with a Gaussian\n","    blurred = filters.gaussian(rescaled_spk, sigma=1, preserve_range=True)\n","\n","    # Adaptative equalization\n","    blurred = exposure.equalize_adapthist(blurred)\n","\n","    # Normalize\n","    blurred = cv2.normalize(blurred, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n","    blurred = blurred.astype(np.uint8)\n","\n","    # Find contours at a constant value of 0.8\n","    # Threshold at 80%\n","    ret, thresh = cv2.threshold(blurred, 0.8*255, 255, 0)\n","    thresh = np.uint8(thresh)\n","    \n","    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(thresh, connectivity=8)\n","    sizes = stats[1:, -1]; nb_components = nb_components - 1\n","# plt.imshow(output==1)\n","#     labels = output\n","       \n","    thresh2 = np.zeros((output.shape))\n","    #for every component in the image, you keep it only if it's above min_size\n","    for i in range(0, nb_components):\n","        if sizes[i] >= MinSize:\n","            thresh2[output == i + 1] = 255\n","    \n","#     plt.imshow(thresh2)\n","    thresh2 = np.uint8(thresh2)\n","    \n","    #     contours = measure.find_contours(blurred,(0.8*255))\n","    contours, hierarchy = cv2.findContours(thresh2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","#     len(contours)\n","    \n","    Props = ObjProps(thresh2, OutImage, OutImageLab, img_name='some_name')\n","\n","    \n","    # Remove contours smallers than MinSize\n","#     Filtered = [c for c in contours if cv2.contourArea(c) > MinSize]\n","    \n","    # Detected spikelets\n","    print(\"Detected spikeletes: \", len(contours))\n","    \n","    # Create list for slopes\n","    Slopes = []\n","#     len(Slopes)\n","\n","    if plot==True:\n","\n","        # Plot all found contours\n","        OutImage = cv2.drawContours(OutImage, contours, -1, (255,255,255), 10);\n","        \n","        # Palette\n","#         cmap = matplotlib.cm.get_cmap('Spectral')\n","#         color_n = 0.1\n","        \n","        for c in contours:\n","            \n","            # Generate random color from palette\n","#             random_channels = cmap(color_n)\n","            random_channels = (np.random.choice(range(256), size=3))\n","            rr = int(random_channels[0])\n","            rg = int(random_channels[1])\n","            rb = int(random_channels[2])\n","            \n","            ellipse = cv2.fitEllipse(c)\n","            OutImage = cv2.ellipse(OutImage,ellipse,(rr,rg,rb),10);\n","\n","            # Fit a line \n","            rows,cols = OutImage.shape[:2]\n","            [vx,vy,x,y] = cv2.fitLine(c, cv2.DIST_L2,0,0.01,0.01);\n","            lefty = int((-x*vy/vx) + y)\n","            righty = int(((cols-x)*vy/vx)+y)\n","            OutImage = cv2.line(OutImage,(cols-1,righty),(0,lefty),(rr,rg,rb),3);\n","            \n","            # Slope from tope left, which is is the origin [0,0]\n","            rise = (0,lefty)[1] - (cols-1,righty)[1]\n","            run = cols\n","            Slope = rise/run\n","            Slopes.append(Slope)\n","            \n","#             color_n = color_n+0.015\n","            \n","        \n","        # Plot\n","        plt.imshow(OutImage)\n","        \n","    else:\n","        \n","        for c in contours:\n","            \n","            ellipse = cv2.fitEllipse(c)\n","            \n","            # Fit a line \n","            rows,cols = OutImage.shape[:2]\n","            [vx,vy,x,y] = cv2.fitLine(c, cv2.DIST_L2,0,0.01,0.01);\n","            lefty = int((-x*vy/vx) + y)\n","            righty = int(((cols-x)*vy/vx)+y)\n","\n","            rise = (0,lefty)[1] - (cols-1,righty)[1]\n","            run = cols\n","            Slope = rise/run\n","            Slopes.append(Slope)\n","    \n","    # Add slopes to data frame\n","    Props['Spklt_Angle'] = Slopes\n","    \n","    return Props"],"id":"a6bbbfe5-f311-47cd-a5c5-1cafcb9b613a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f92bd247-9321-48f5-818b-f765abe2883c"},"source":["%%time\n","SP = SpkltProps(cropped_rgb, img_name=Images[0])\n","# SP\n"],"id":"f92bd247-9321-48f5-818b-f765abe2883c","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"46462296-f16c-4e2f-b3db-52b283e57d7b"},"source":["## Contour props"],"id":"46462296-f16c-4e2f-b3db-52b283e57d7b"},{"cell_type":"code","metadata":{"id":"15edb366-084c-47b2-a5b9-0b1f1ef3e9d1"},"source":["def ObjProps(mask, cropped_rgb, cropped_lab, img_name):\n","\n","    # Regionprops\n","    labeled_contours, num_contours = label(mask, return_num = True)\n","    props_contours = regionprops(labeled_contours)\n","\n","    # # Create column with image name\n","    Image_Name = img_name.split('\\\\')[-1]\n","    Image_Name = [Image_Name] * num_contours\n","\n","    # Geometric properties\n","    Labels = [rp.label for rp in props_contours]\n","    Areas = [rp.area for rp in props_contours]\n","    MajorAxes = [rp.major_axis_length for rp in props_contours]\n","    MinorAxes = [rp.minor_axis_length for rp in props_contours]\n","    Orientations = [rp.orientation for rp in props_contours]\n","    Perimeters = [rp.perimeter for rp in props_contours]\n","    Eccentricities = [rp.eccentricity for rp in props_contours]\n","\n","    # Spectral properties\n","    red_props = regionprops(labeled_contours, intensity_image=cropped_rgb[:,:,0])\n","    green_props = regionprops(labeled_contours, intensity_image=cropped_rgb[:,:,1])\n","    blue_props = regionprops(labeled_contours, intensity_image=cropped_rgb[:,:,2])\n","    L_props = regionprops(labeled_contours, intensity_image=cropped_lab[:,:,0])\n","    a_props = regionprops(labeled_contours, intensity_image=cropped_lab[:,:,1])\n","    b_props = regionprops(labeled_contours, intensity_image=cropped_lab[:,:,2])\n","\n","    red = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in red_props])\n","    green = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in green_props])\n","    blue = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in blue_props])\n","    L = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in L_props])\n","    a = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in a_props])\n","    b = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in b_props])\n","\n","    Red_Perc = np.array(channel_percentiles(red_props, Negatives=False)).T\n","    Green_Perc = np.array(channel_percentiles(green_props, Negatives=False)).T\n","    Blue_Perc = np.array(channel_percentiles(blue_props, Negatives=False)).T\n","    L_Perc = np.array(channel_percentiles(L_props)).T\n","    a_Perc = np.array(channel_percentiles(a_props, Negatives=True)).T\n","    b_Perc = np.array(channel_percentiles(b_props, Negatives=True)).T\n","\n","    # Dataframe 1: for single obervation per spike\n","    contours_per_image = pd.DataFrame(\n","    list(zip(Image_Name, Labels, Areas, MajorAxes, MinorAxes, Orientations, Eccentricities, Perimeters, \n","    red[:,0], red[:,1], red[:,2], green[:,0], green[:,1], green[:,2], blue[:,0], blue[:,1], blue[:,2], \n","    L[:,0], L[:,1], L[:,2], a[:,0], a[:,1], a[:,2], b[:,0], b[:,1], b[:,2], \n","    Red_Perc[:,0], Red_Perc[:,1], Red_Perc[:,2], Red_Perc[:,3], Red_Perc[:,4], Red_Perc[:,5], Red_Perc[:,6], \n","    Green_Perc[:,0], Green_Perc[:,1], Green_Perc[:,2], Green_Perc[:,3], Green_Perc[:,4], Green_Perc[:,5], Green_Perc[:,6], \n","    Blue_Perc[:,0], Blue_Perc[:,1], Blue_Perc[:,2], Blue_Perc[:,3], Blue_Perc[:,4], Blue_Perc[:,5], Blue_Perc[:,6], \n","    L_Perc[:,0], L_Perc[:,1], L_Perc[:,2], L_Perc[:,3], L_Perc[:,4], L_Perc[:,5], L_Perc[:,6], \n","    a_Perc[:,0], a_Perc[:,1], a_Perc[:,2], a_Perc[:,3], a_Perc[:,4], a_Perc[:,5], a_Perc[:,6], \n","    a_Perc[:,7], a_Perc[:,8], a_Perc[:,9], a_Perc[:,10], a_Perc[:,11], a_Perc[:,12], a_Perc[:,13], \n","    b_Perc[:,0], b_Perc[:,1], b_Perc[:,2], b_Perc[:,3], b_Perc[:,4], b_Perc[:,5], b_Perc[:,6], \n","    b_Perc[:,7], b_Perc[:,8], b_Perc[:,9], b_Perc[:,10], b_Perc[:,11], b_Perc[:,12], b_Perc[:,13])), \n","    columns = ['Image_Name', 'Spklt_Label', 'Area', 'MajorAxis', 'MinorAxes', 'Orientation', 'Eccentricity', 'Perimeter', \n","      'Red_mean', 'Red_min', 'Red_max', 'Green_mean', 'Green_min', 'Green_max', 'Blue_mean', 'Blue_min', 'Blue_max', \n","      'L_mean', 'L_min', 'L_max', 'a_mean', 'a_min', 'a_max', 'b_mean', 'b_min', 'b_max', \n","      'Red_p25', 'Red_p50', 'Red_p75', 'Red_Mean', 'Red_sd', 'Red_Min', 'Red_Max', \n","      'Green_p25', 'Green_p50', 'Green_p75', 'Green_Mean', 'Green_sd', 'Green_Min', 'Green_Max', \n","      'Blue_p25', 'Blue_p50', 'Blue_p75', 'Blue_Mean', 'Blue_sd', 'Blue_Min', 'Blue_Max', \n","      'L_p25', 'L_p50', 'L_p75', 'L_Mean', 'L_sd', 'L_Min', 'L_Max', \n","      'a_p25_pos', 'a_p50_pos', 'a_p75_pos', 'a_Mean_pos', 'a_sd_pos', 'a_Min_pos', 'a_Max_pos', \n","      'a_p25_neg', 'a_p50_neg', 'a_p75_neg', 'a_Mean_neg', 'a_sd_neg', 'a_Min_neg', 'a_Max_neg', \n","      'b_p25_pos', 'b_p50_pos', 'b_p75_pos', 'b_Mean_pos', 'b_sd_pos', 'b_Min_pos', 'b_Max_pos', \n","      'b_p25_neg', 'b_p50_neg', 'b_p75_neg', 'b_Mean_neg', 'b_sd_neg', 'b_Min_neg', 'b_Max_neg'])\n","\n","    contours_per_image['Circularity'] = (4 * np.pi * contours_per_image['Area']) / (contours_per_image['Perimeter'] ** 2)\n","\n","    return contours_per_image\n"],"id":"15edb366-084c-47b2-a5b9-0b1f1ef3e9d1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b19805e5-8132-4fd0-9d0c-f1b0a4d48677"},"source":["%%time\n","ObjP = ObjProps(mask = thresh2, cropped_rgb=cropped_rgb, cropped_lab=cropped_lab, img_name=Images[0])\n","ObjP"],"id":"b19805e5-8132-4fd0-9d0c-f1b0a4d48677","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"473105a0-135e-4e2a-83f4-c70c50e2cf73"},"source":["EnumerateSpkCV(thresh2, cropped_rgb, TextSize=3,  TROE2020=False)"],"id":"473105a0-135e-4e2a-83f4-c70c50e2cf73","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d1a50a26-3f74-4a06-8d3d-52f966c3595e"},"source":["## Angles"],"id":"d1a50a26-3f74-4a06-8d3d-52f966c3595e"},{"cell_type":"code","metadata":{"id":"10c87ab9-be8b-4a8f-8fde-fe82d05599c3"},"source":[""],"id":"10c87ab9-be8b-4a8f-8fde-fe82d05599c3","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"33c0eaaa-fb48-47b6-94ca-85f111339ca8"},"source":["L = np.array([1,2,3,4])\n","L = L.reshape(len(L), 1)\n","LT = L.T\n","matL = np.multiply(L, LT)\n","len(matL)"],"id":"33c0eaaa-fb48-47b6-94ca-85f111339ca8","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"07a7c3b2-157a-4a25-af77-f03b32364cf1"},"source":["np.cov(matL)"],"id":"07a7c3b2-157a-4a25-af77-f03b32364cf1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5e145b59-f9d1-47bf-9941-9ad4c452e203"},"source":["# S = np.array(Slopes)\n","# S = S.reshape(len(S), 1)\n","# ST = S.T\n","# matS = np.multiply(S, ST)\n","# matS.shape\n","\n","\n","\n","def Heatmat(a, frames=30):\n","    a = np.array(a)\n","    a = a.reshape(len(a), 1)\n","    aT = a.T\n","    mat = np.multiply(a, aT)\n","#     mata.shape\n","\n","    for frame in range(frames):\n","        if frame < 10:\n","            name = \"./GIFS/Angles_0\"+str(frame)+\".png\"\n","        else:\n","            name = \"./GIFS/Angles_\"+str(frame)+\".png\"\n","        \n","        new_mat = np.log10( 1+(mat**(frame) ) )\n","        sns.heatmap(new_mat)\n","        plt.savefig(name)\n","        plt.close()"],"id":"5e145b59-f9d1-47bf-9941-9ad4c452e203","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"11f9ed64-7ba4-40d1-9d76-c0669721947a"},"source":["%%time\n","S = np.array(Slopes)\n","S = S.reshape(len(S), 1)\n","Heatmat(S, frames=30)"],"id":"11f9ed64-7ba4-40d1-9d76-c0669721947a","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"195aef24-7dbe-40d0-a036-b8ee51c555df"},"source":["## GIFs"],"id":"195aef24-7dbe-40d0-a036-b8ee51c555df"},{"cell_type":"code","metadata":{"id":"500ede59-c50d-47c9-ba88-dce8666166ad"},"source":["filenames = glob.glob(\"./GIFS/\" + '*.png', recursive=False)"],"id":"500ede59-c50d-47c9-ba88-dce8666166ad","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f9d3c713-634f-4063-953c-f360d7bb31cd"},"source":["%%time\n","with imageio.get_writer('./GIFS/GIF_Angles.gif', mode='I', duration=0.25) as writer:\n","    for filename in filenames:\n","        image = imageio.imread(filename)\n","        writer.append_data(image)"],"id":"f9d3c713-634f-4063-953c-f360d7bb31cd","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d5f985e7-211b-4a65-a2e9-ffccf67d329e"},"source":["%%time\n","images = []\n","for filename in filenames:\n","    images.append(imageio.imread(filename))\n","imageio.mimsave('./GIFS/GIF_Angles2.gif', images, duration=0.25)"],"id":"d5f985e7-211b-4a65-a2e9-ffccf67d329e","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"33ca335e-366e-47c1-9414-0775e09c792a"},"source":[""],"id":"33ca335e-366e-47c1-9414-0775e09c792a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a8c87cc1-8799-4806-bebc-3e2f6b7a8edb"},"source":[""],"id":"a8c87cc1-8799-4806-bebc-3e2f6b7a8edb","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7139e540-7091-44a6-8222-17a8b1549174"},"source":["## Euclidean distances of centroids\n","**NOTE:** Curvature of the spike must be consider as it alters the real distance between spikelets."],"id":"7139e540-7091-44a6-8222-17a8b1549174"},{"cell_type":"code","metadata":{"id":"0c8cc852-7205-4bd7-a415-67ab9750d98d"},"source":["nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(thresh2), \n","                                                                           connectivity=8)\n","# len(centroids[1:][:])\n","img_center = centroids[0][:]\n","c_points = centroids[1:][:]\n","c_df = pd.DataFrame(c_points, columns=[\"x\",\"y\"])\n","# c_df"],"id":"0c8cc852-7205-4bd7-a415-67ab9750d98d","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6d345a2c-fdc0-49c7-b49a-707b9f117143"},"source":["# https://stackoverflow.com/questions/57107729/how-to-compute-multiple-euclidean-distances-of-all-points-in-a-dataset\n","\n","# Consider your points as tuples in a list\n","data = [ (float(x),float(y)) for x,y in c_df[['x', 'y']].values ]\n","\n","# Empty list to keep the distances\n","distances = []\n","\n","for point in data:\n","    \n","    # Compute the Euclidean distance between the current point and all others\n","    euc_dist = [math.sqrt((point[0]-x[0] )**2 + (point[1]-x[1])**2) for x in data]\n","    \n","    # Append\n","    distances.append(euc_dist)\n","\n","# Convert list to array\n","D = np.array(distances)\n","\n","# Express it as a fraction from spike length\n","D2 = D/spkl\n","D2.shape\n"],"id":"6d345a2c-fdc0-49c7-b49a-707b9f117143","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9e801e70-d721-463a-a517-1486ff61ce91"},"source":["# Plot distances as proportion from spike length\n","sns.heatmap(D2)"],"id":"9e801e70-d721-463a-a517-1486ff61ce91","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"001cc18c-0e38-4b7d-bebd-cf127ccdae8f"},"source":["EnumerateSpkCV(thresh2, cropped_rgb, TextSize=3,  TROE2020=False)"],"id":"001cc18c-0e38-4b7d-bebd-cf127ccdae8f","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bcdeda05-e073-4831-b328-3a7bfd621752"},"source":[""],"id":"bcdeda05-e073-4831-b328-3a7bfd621752","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9d6d1910-419c-4d4b-bd20-279adcb09501"},"source":["# Graph analysis?"],"id":"9d6d1910-419c-4d4b-bd20-279adcb09501"},{"cell_type":"code","metadata":{"id":"514def6f-b0ba-49f3-9e86-f7855a6c9944"},"source":["# https://stackoverflow.com/questions/54832694/how-to-represent-a-binary-image-as-a-graph-with-the-axis-being-height-and-width\n","image = blurred\n","\n","#Use argmax with 200 cutoff colour in one channel\n","maxindex = np.argmax(image[:,:], axis=0)\n","\n","# Plot graph\n","plt.plot(image.shape[0] - maxindex)\n","plt.show()"],"id":"514def6f-b0ba-49f3-9e86-f7855a6c9944","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b2989ebe-6241-4f1f-b7f8-177b92828900"},"source":["### Data"],"id":"b2989ebe-6241-4f1f-b7f8-177b92828900"},{"cell_type":"code","metadata":{"id":"49e25ce6-00b1-4678-822f-c2856b27c24a"},"source":["data_skel = summarize(Skeleton(skel))"],"id":"49e25ce6-00b1-4678-822f-c2856b27c24a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"34cbd6d3-6daa-4977-8045-57d90b26cb0e"},"source":["data_skel"],"id":"34cbd6d3-6daa-4977-8045-57d90b26cb0e","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"406544cd-029c-4eed-b821-7facc95802ea"},"source":["import pytrax as pt"],"id":"406544cd-029c-4eed-b821-7facc95802ea","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bd9b89d2-9a4e-4bd1-b9af-f05f33059bba"},"source":["im = ~blurred\n","im = np.pad(im, pad_width=50, mode='constant', constant_values=1)\n","plt.imshow(im)"],"id":"bd9b89d2-9a4e-4bd1-b9af-f05f33059bba","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2d29aa24-2385-4e1a-ad5a-63972412bc2f"},"source":["rw = pt.RandomWalk(image=im, seed=False)"],"id":"2d29aa24-2385-4e1a-ad5a-63972412bc2f","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"17778b92-9bf5-45c5-a3aa-d0885ccadc42"},"source":["rw.run(nt=20000, nw=1000)\n","rw.plot_walk_2d()"],"id":"17778b92-9bf5-45c5-a3aa-d0885ccadc42","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e9c64aee-ab9c-4120-a9d8-e1a7a52918f8"},"source":["rw.plot_msd()"],"id":"e9c64aee-ab9c-4120-a9d8-e1a7a52918f8","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c91f6053-638d-482f-a7a3-cb67a6b8f65e"},"source":[""],"id":"c91f6053-638d-482f-a7a3-cb67a6b8f65e","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8a5c306f-dddb-4357-b8f9-ed3590dcdbfe"},"source":["pixel_graph, coordinates, degrees = skeleton_to_csgraph(skel)\n","# plt.imshow(degrees)"],"id":"8a5c306f-dddb-4357-b8f9-ed3590dcdbfe","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"63858c92-f7d2-4df2-a4da-4eb08c29c872"},"source":["### Overlay"],"id":"63858c92-f7d2-4df2-a4da-4eb08c29c872"},{"cell_type":"code","metadata":{"id":"74546b75-4c89-4eef-8128-a4e2e4fce8a0"},"source":["draw.overlay_euclidean_skeleton_2d(rescaled_spk, data_skel, skeleton_color_source='branch-type')"],"id":"74546b75-4c89-4eef-8128-a4e2e4fce8a0","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fd34ff25-684c-41a5-b2a4-a942120fae0a"},"source":["# Histograms\n","data_skel.hist(column='branch-distance', by='branch-type', bins=100)"],"id":"fd34ff25-684c-41a5-b2a4-a942120fae0a","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"15e492c7-4f5f-47ba-9c69-fd1d9a4e58be"},"source":["## Medial axis"],"id":"15e492c7-4f5f-47ba-9c69-fd1d9a4e58be"},{"cell_type":"code","metadata":{"id":"7595e856-6e48-4406-b17e-e3643ced7c58"},"source":["# Compute the medial axis (skeleton) and the distance transform\n","medax, distance = medial_axis(erosion, return_distance=True)\n","plt.imshow(medax)\n","\n","kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n","dilation = cv2.dilate(np.float32(medax),(5,5),iterations = 4)\n","plt.imshow(dilation)\n","\n"],"id":"7595e856-6e48-4406-b17e-e3643ced7c58","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1d17c455-eff4-44f3-bc39-6fc82d477ac1"},"source":["# plt.imshow(distance)\n","# distance.shape\n","# np.amin(distance)"],"id":"1d17c455-eff4-44f3-bc39-6fc82d477ac1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ed49e21-cff4-41ca-b8a4-987052705f9c"},"source":["data_medax = summarize(Skeleton(medax))"],"id":"9ed49e21-cff4-41ca-b8a4-987052705f9c","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bce2c846-305d-463e-b26a-9e07232bd859"},"source":["data_medax"],"id":"bce2c846-305d-463e-b26a-9e07232bd859","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d2c7e80c-81ea-4971-b4b6-f27fc7da3d40"},"source":["pixel_graph, coordinates, degrees = skeleton_to_csgraph(medax)\n","# plt.imshow(degrees)"],"id":"d2c7e80c-81ea-4971-b4b6-f27fc7da3d40","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fc095a53-c3d9-403e-96d7-e78537509ea2"},"source":[" draw.overlay_euclidean_skeleton_2d(rescaled_spk, data_medax, skeleton_color_source='branch-type')"],"id":"fc095a53-c3d9-403e-96d7-e78537509ea2","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b384b330-53b6-4a5f-92ad-882a772988cd"},"source":["# Histograms\n","data_medax.hist(column='branch-distance', by='branch-type', bins=100)"],"id":"b384b330-53b6-4a5f-92ad-882a772988cd","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e368fbeb-253e-4bd4-9b13-03fe5568be15"},"source":[""],"id":"e368fbeb-253e-4bd4-9b13-03fe5568be15","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9760bfc2-0076-48d6-bc53-9dc3e18a6f08"},"source":[""],"id":"9760bfc2-0076-48d6-bc53-9dc3e18a6f08","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"97c54995-6305-4504-ac78-f87ffccee02d"},"source":["# Detecting Spikelets"],"id":"97c54995-6305-4504-ac78-f87ffccee02d"},{"cell_type":"markdown","metadata":{"id":"18e663cd-5b76-488c-8c3a-5712f061b7ee"},"source":["## Select a spike"],"id":"18e663cd-5b76-488c-8c3a-5712f061b7ee"},{"cell_type":"code","metadata":{"id":"39e6c102-a0a2-442e-a837-e001607e9604"},"source":["plt.imshow(cropped_rgb)"],"id":"39e6c102-a0a2-442e-a837-e001607e9604","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ER2K2rju2L3q","scrolled":true,"tags":[]},"source":["\n","def nSpklts(cropped_rgb, labeled_out=False):\n","    \n","    # Rescale to 10% of original\n","    rescaled_spk = rescale(cropped_rgb[...], 0.1, preserve_range=False, multichannel=True, anti_aliasing=True)\n","    # plt.imshow(rescaled_spk)\n","\n","    # Erosion\n","    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n","    erosion = cv2.erode(rescaled_spk,kernel,iterations = 1)\n","    # plt.imshow(erosion)\n","\n","    # Opening\n","    kernel = np.ones((1,1),np.uint8)\n","    opening = cv2.morphologyEx(erosion, cv2.MORPH_OPEN, kernel, iterations = 10)\n","    # plt.imshow(opening)\n","\n","    # Resize\n","    rescaled_spk2 = Image.fromarray((rescaled_spk * 255).astype(np.uint8))\n","    rescaled_spk2 = rescaled_spk2.resize((cropped_rgb.shape[1],cropped_rgb.shape[0]))\n","    # plt.imshow(rescaled_spk2)\n","    # rescaled_spk2.size\n","    opening = np.asarray(rescaled_spk2)\n","\n","    # Convert rgb to gray\n","    gray_spklts = opening @ [0.2126, 0.7152, 0.0722]\n","    # plt.imshow(gray_spklts)\n","\n","    # Binarize gray\n","    bw_spklts = gray_spklts > 0\n","    # plt.imshow(bw_spklts)\n","\n","    # Get distances\n","    distance = ndi.distance_transform_edt(bw_spklts)\n","    # plt.imshow(-distance)\n","\n","    # Get max peaks\n","    coords = peak_local_max(distance, min_distance=50, labels=bw_spklts)\n","    # plt.imshow(coords)\n","\n","    mask = np.zeros(distance.shape, dtype=bool)\n","    mask[tuple(coords.T)] = True\n","    markers, spikelets = ndi.label(mask)\n","    # markers, spikelets = label(mask, return_num = True)\n","    # markers64 = np.int64(markers)\n","\n","    if labeled_out==True:\n","        # Watershed\n","        labels = watershed(-distance, markers, mask=cropped_spk)\n","\n","        # Detected spikelets\n","        print('Detected spikelets = ', spikelets)\n","\n","        # Plot\n","        plt.imshow(labels, cmap=plt.cm.nipy_spectral)\n","\n","    else:\n","        return spikelets\n","\n"],"id":"ER2K2rju2L3q","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nc714GCy0-Qs"},"source":["%%time\n","nSpklts(cropped_rgb, labeled_out=True)"],"id":"Nc714GCy0-Qs","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9b6ba391-75c3-4fce-ad87-82735b796734"},"source":["rescaled_spk = rescale(cropped_rgb[...], 0.1, preserve_range=False, multichannel=True, anti_aliasing=True)\n","plt.imshow(rescaled_spk)\n"],"id":"9b6ba391-75c3-4fce-ad87-82735b796734","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wqSdEey6wbjT"},"source":["# cropped_rgb.shape\n","# rescaled_spk2 = rescale(rescaled_spk[...], 9, preserve_range=False, multichannel=True, anti_aliasing=True)\n","# rescaled_spk2.shape"],"id":"wqSdEey6wbjT","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"50ffcce2-3f86-4370-be9b-8ecee3441e83"},"source":["## Apply a Gaussian blur"],"id":"50ffcce2-3f86-4370-be9b-8ecee3441e83"},{"cell_type":"code","metadata":{"id":"902f3fa1-f4d4-4687-83a9-1493e6eb7fa8"},"source":["\n","\n","# kernel = np.ones((5,5),np.uint8)\n","kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n","erosion = cv2.erode(rescaled_spk,kernel,iterations = 1)\n","# plt.imshow(erosion)\n","\n","kernel = np.ones((1,1),np.uint8)\n","opening = cv2.morphologyEx(erosion, cv2.MORPH_OPEN, kernel, iterations = 10)\n","plt.imshow(opening)\n","\n","# blur = cv2.blur(np.float32(cropped_spk),(10,10))\n","# blur = cv2.blur(erosion,(30,30))   # With RGB\n","# plt.imshow(blur)\n","\n","# kernel = np.ones((7,7),np.uint8)\n","# dilation = cv2.dilate(erosion,kernel,iterations = 2)\n","# plt.imshow(dilation)\n","\n","# medfil = cv2.medianBlur(np.uint8(erosion), 5)\n","# plt.imshow(medfil)\n","\n","# kernel = np.ones((10,10),np.uint8)\n","# closing = cv2.morphologyEx(erosion, cv2.MORPH_CLOSE, kernel)\n","# plt.imshow(closing)\n","\n","\n","\n","\n","# blur = cv2.blur(erosion,(10,10))   # With RGB\n","# plt.imshow(blur)"],"id":"902f3fa1-f4d4-4687-83a9-1493e6eb7fa8","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c5a4e2e8-6375-4565-9843-6583123be18b"},"source":["## Get distances and local peaks"],"id":"c5a4e2e8-6375-4565-9843-6583123be18b"},{"cell_type":"code","metadata":{"id":"z-Q1FaQy7f1c"},"source":["# Resize\n","rescaled_spk2 = Image.fromarray((rescaled_spk * 255).astype(np.uint8))\n","rescaled_spk2 = rescaled_spk2.resize((cropped_rgb.shape[1],cropped_rgb.shape[0]))\n","# rescaled_spk2 = np.asarray(rescaled_spk2)\n","plt.imshow(rescaled_spk2)\n","rescaled_spk2.size"],"id":"z-Q1FaQy7f1c","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5bae9994-3bd8-409e-b456-054495b6b5e6"},"source":["opening = np.asarray(rescaled_spk2)\n","# Convert rgb to gray\n","gray_spklts = opening @ [0.2126, 0.7152, 0.0722]\n","# plt.imshow(gray_spklts)\n","\n","# Binarize gray\n","bw_spklts = gray_spklts > 0\n","# plt.imshow(bw_spklts)\n","\n","# Get distances\n","distance = ndi.distance_transform_edt(bw_spklts)\n","# plt.imshow(-distance)\n","\n","# Get max peaks\n","coords = peak_local_max(distance, min_distance=50, labels=bw_spklts)\n","# plt.imshow(coords)\n","\n","mask = np.zeros(distance.shape, dtype=bool)\n","mask[tuple(coords.T)] = True\n","markers, spikelets = ndi.label(mask)\n","# markers, spikelets = label(mask, return_num = True)\n","# markers64 = np.int64(markers)\n","\n","# Watershed\n","labels = watershed(-distance, markers, mask=cropped_spk)\n","\n","# Detected spikelets\n","print('Detected spikelets = ', spikelets)"],"id":"5bae9994-3bd8-409e-b456-054495b6b5e6","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c9b504c8-3e45-43a6-aba6-cd1b2c47a319"},"source":["## Visualize results"],"id":"c9b504c8-3e45-43a6-aba6-cd1b2c47a319"},{"cell_type":"code","metadata":{"id":"1df1583f-a2b7-49bc-9fa1-ff8ae4bec2ba"},"source":["fig, axes = plt.subplots(ncols=3, figsize=(9, 3), sharex=True, sharey=True)\n","ax = axes.ravel()\n","\n","ax[0].imshow(cropped_spk, cmap=plt.cm.gray)\n","ax[0].set_title('Overlapping objects')\n","ax[1].imshow(-np.float32(distance), cmap=plt.cm.gray)\n","ax[1].set_title('Distances')\n","ax[2].imshow(labels, cmap=plt.cm.nipy_spectral)\n","ax[2].set_title('Separated objects')\n","\n","for a in ax:\n","    a.set_axis_off()\n","\n","fig.tight_layout()\n","plt.show()"],"id":"1df1583f-a2b7-49bc-9fa1-ff8ae4bec2ba","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2252802a-4c6d-4fc9-bfca-a4c990ddc2d8"},"source":["plt.imshow(labels==4)"],"id":"2252802a-4c6d-4fc9-bfca-a4c990ddc2d8","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c00451a7-2c3f-478e-81b9-7b02e93219f7"},"source":["%%time\n","# Regionprops\n","labeled_spklts = np.int64(labels)\n","props_spklts = regionprops(labels)\n","\n","# labeled_spks, num_spikes = label(bw1, return_num = True)\n","# props_spikes = regionprops(labeled_spks)"],"id":"c00451a7-2c3f-478e-81b9-7b02e93219f7","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YrFIc08by-sA"},"source":["spklt = labels==6\n","rgb_spklt = np.where(spklt[..., None], cropped_rgb, 0)\n","# plt.imshow(rgb_spklt)"],"id":"YrFIc08by-sA","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DDkFJ5t4y-jh"},"source":["# Spikeletes Lab values\n","cropped_lab = color.rgb2lab(cropped_rgb)\n","plt.imshow(cropped_lab)\n","# plt.imshow(labeled_spklts, cmap='gray')\n","# labeled_spklts"],"id":"DDkFJ5t4y-jh","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpmNEsCZ7bJJ"},"source":[""],"id":"EpmNEsCZ7bJJ","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2DWkZE42y-Yv"},"source":["%%time\n","\n","# # Create column with image name\n","Image_Name = Images[0].split('\\\\')[-1]\n","Image_Name = [Image_Name] * spikelets\n","\n","# Geometric properties\n","Labels = [rp.label for rp in props_spklts]\n","Areas = [rp.area for rp in props_spklts]\n","MajorAxes = [rp.major_axis_length for rp in props_spklts]\n","MinorAxes = [rp.minor_axis_length for rp in props_spklts]\n","Orientations = [rp.orientation for rp in props_spklts]\n","Perimeters = [rp.perimeter for rp in props_spklts]\n","Eccentricities = [rp.eccentricity for rp in props_spklts]\n","\n","# Spectral properties\n","red_props = regionprops(labeled_spklts, intensity_image=cropped_rgb[:,:,0])\n","green_props = regionprops(labeled_spklts, intensity_image=cropped_rgb[:,:,1])\n","blue_props = regionprops(labeled_spklts, intensity_image=cropped_rgb[:,:,2])\n","L_props = regionprops(labeled_spklts, intensity_image=cropped_lab[:,:,0])\n","a_props = regionprops(labeled_spklts, intensity_image=cropped_lab[:,:,1])\n","b_props = regionprops(labeled_spklts, intensity_image=cropped_lab[:,:,2])\n","\n","red = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in red_props])\n","green = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in green_props])\n","blue = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in blue_props])\n","L = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in L_props])\n","a = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in a_props])\n","b = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in b_props])\n","\n","Red_Perc = np.array(channel_percentiles(red_props, Negatives=False)).T\n","Green_Perc = np.array(channel_percentiles(green_props, Negatives=False)).T\n","Blue_Perc = np.array(channel_percentiles(blue_props, Negatives=False)).T\n","L_Perc = np.array(channel_percentiles(L_props)).T\n","a_Perc = np.array(channel_percentiles(a_props, Negatives=True)).T\n","b_Perc = np.array(channel_percentiles(b_props, Negatives=True)).T\n","\n","# Dataframe 1: for single obervation per spike\n","Spikes_per_image = pd.DataFrame(\n","list(zip(Image_Name, Labels, Areas, MajorAxes, MinorAxes, Orientations, Eccentricities, Perimeters, \n","red[:,0], red[:,1], red[:,2], green[:,0], green[:,1], green[:,2], blue[:,0], blue[:,1], blue[:,2], \n","L[:,0], L[:,1], L[:,2], a[:,0], a[:,1], a[:,2], b[:,0], b[:,1], b[:,2], \n","Red_Perc[:,0], Red_Perc[:,1], Red_Perc[:,2], Red_Perc[:,3], Red_Perc[:,4], Red_Perc[:,5], Red_Perc[:,6], \n","Green_Perc[:,0], Green_Perc[:,1], Green_Perc[:,2], Green_Perc[:,3], Green_Perc[:,4], Green_Perc[:,5], Green_Perc[:,6], \n","Blue_Perc[:,0], Blue_Perc[:,1], Blue_Perc[:,2], Blue_Perc[:,3], Blue_Perc[:,4], Blue_Perc[:,5], Blue_Perc[:,6], \n","L_Perc[:,0], L_Perc[:,1], L_Perc[:,2], L_Perc[:,3], L_Perc[:,4], L_Perc[:,5], L_Perc[:,6], \n","a_Perc[:,0], a_Perc[:,1], a_Perc[:,2], a_Perc[:,3], a_Perc[:,4], a_Perc[:,5], a_Perc[:,6], \n","a_Perc[:,7], a_Perc[:,8], a_Perc[:,9], a_Perc[:,10], a_Perc[:,11], a_Perc[:,12], a_Perc[:,13], \n","b_Perc[:,0], b_Perc[:,1], b_Perc[:,2], b_Perc[:,3], b_Perc[:,4], b_Perc[:,5], b_Perc[:,6], \n","b_Perc[:,7], b_Perc[:,8], b_Perc[:,9], b_Perc[:,10], b_Perc[:,11], b_Perc[:,12], b_Perc[:,13])), \n","columns = ['Image_Name', 'Spike_Label', 'Area', 'MajorAxis', 'MinorAxes', 'Orientation', 'Eccentricity', 'Perimeter', \n","  'Red_mean', 'Red_min', 'Red_max', 'Green_mean', 'Green_min', 'Green_max', 'Blue_mean', 'Blue_min', 'Blue_max', \n","  'L_mean', 'L_min', 'L_max', 'a_mean', 'a_min', 'a_max', 'b_mean', 'b_min', 'b_max', \n","  'Red_p25', 'Red_p50', 'Red_p75', 'Red_Mean', 'Red_sd', 'Red_Min', 'Red_Max', \n","  'Green_p25', 'Green_p50', 'Green_p75', 'Green_Mean', 'Green_sd', 'Green_Min', 'Green_Max', \n","  'Blue_p25', 'Blue_p50', 'Blue_p75', 'Blue_Mean', 'Blue_sd', 'Blue_Min', 'Blue_Max', \n","  'L_p25', 'L_p50', 'L_p75', 'L_Mean', 'L_sd', 'L_Min', 'L_Max', \n","  'a_p25_pos', 'a_p50_pos', 'a_p75_pos', 'a_Mean_pos', 'a_sd_pos', 'a_Min_pos', 'a_Max_pos', \n","  'a_p25_neg', 'a_p50_neg', 'a_p75_neg', 'a_Mean_neg', 'a_sd_neg', 'a_Min_neg', 'a_Max_neg', \n","  'b_p25_pos', 'b_p50_pos', 'b_p75_pos', 'b_Mean_pos', 'b_sd_pos', 'b_Min_pos', 'b_Max_pos', \n","  'b_p25_neg', 'b_p50_neg', 'b_p75_neg', 'b_Mean_neg', 'b_sd_neg', 'b_Min_neg', 'b_Max_neg'])\n","\n","Spikes_per_image['Circularity'] = (4 * np.pi * Spikes_per_image['Area']) / (Spikes_per_image['Perimeter'] ** 2)\n"],"id":"2DWkZE42y-Yv","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kmM6qOG9Jzg-"},"source":["plt.imshow(labeled_spklts)\n","plt.imshow(labeled_spks)"],"id":"kmM6qOG9Jzg-","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MbTG0YC2kav2"},"source":["# import csv\n","# labeled_spklts.to_csv('/content/drive/MyDrive/M.Sc/THESIS/ImageAnalysis/SpikeProperties/Spyk_Prop/redprops.csv')\n","# pwd\n","pd.DataFrame(green)"],"id":"MbTG0YC2kav2","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xVp9Onu4yd-H"},"source":[""],"id":"xVp9Onu4yd-H","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c44f5820-d00c-4de4-85fc-e960dd558492"},"source":["# Ridge detection"],"id":"c44f5820-d00c-4de4-85fc-e960dd558492"},{"cell_type":"code","metadata":{"id":"eefe86c4-0b41-456c-b685-907410f8f3fc"},"source":["# Crop spike\n","slice_x, slice_y = ndimage.find_objects(spk)[0]\n","cropped_spk = spk[slice_x, slice_y]\n","cropped_rgb = img0[slice_x, slice_y]\n","cropped_rgb = np.where(cropped_spk[..., None], cropped_rgb, 0)\n","cropped_gray = cropped_rgb @ [0.2126, 0.7152, 0.0722]\n","plt.imshow(cropped_rgb)\n","# plt.imshow(cropped_gray)"],"id":"eefe86c4-0b41-456c-b685-907410f8f3fc","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6afc7b5a-00bd-4c99-a4b0-46068939bc36"},"source":["%%time\n","blur = cv2.blur(cropped_rgb,(70,70))\n","# Threshold the blur\n","# thrb = blur > 0.2\n","# skeleton = skeletonize(thrb)\n","\n","plt.imshow(blur)"],"id":"6afc7b5a-00bd-4c99-a4b0-46068939bc36","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8bf6f2eb-a02d-4dd7-b576-71563288e8ee"},"source":["blur2 = cv2.blur(cropped_spk.astype(np.uint8),(40,40))\n","# blur = cv2.blur(cropped_rgb,(50,50))   # With RGB\n","plt.imshow(blur2)"],"id":"8bf6f2eb-a02d-4dd7-b576-71563288e8ee","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ed0d8974-7dba-4e1a-b661-871ec4c53373"},"source":["from skimage.filters import meijering, sato, frangi, hessian"],"id":"ed0d8974-7dba-4e1a-b661-871ec4c53373","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0cb6797a-8d64-445c-b75d-23445748a5bc"},"source":["gray_cropped = cropped_rgb @ [0.2126, 0.7152, 0.0722]\n","plt.imshow(gray_cropped)"],"id":"0cb6797a-8d64-445c-b75d-23445748a5bc","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"448f9f3d-c91b-4c3b-a96e-fe396d2ab93a"},"source":["blur2 = cv2.blur(np.float32(gray_cropped),(30,30))\n","# blur = cv2.blur(cropped_rgb,(50,50))   # With RGB\n","plt.imshow(blur2)"],"id":"448f9f3d-c91b-4c3b-a96e-fe396d2ab93a","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"84636ed5-333c-4e53-8eed-28686bef4b27"},"source":["### Meijering\n","https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.meijering"],"id":"84636ed5-333c-4e53-8eed-28686bef4b27"},{"cell_type":"code","metadata":{"id":"ff2c667d-1477-4361-824e-bcb7a73258d5"},"source":["image = blur2\n","mei = meijering(image, sigmas=range(1, 10, 2), alpha=None, black_ridges=False, mode='reflect', cval=0)\n","plt.imshow(mei)\n"],"id":"ff2c667d-1477-4361-824e-bcb7a73258d5","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6f7c1e2-4f67-461d-829f-190c75ab850c"},"source":["image = mei > 0.2\n","skeleton = skeletonize(image)\n","plt.imshow(skeleton)"],"id":"a6f7c1e2-4f67-461d-829f-190c75ab850c","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"56270466-2f73-42b9-9f81-d81ca62447c4"},"source":["### Sato\n","https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.sato"],"id":"56270466-2f73-42b9-9f81-d81ca62447c4"},{"cell_type":"code","metadata":{"id":"15979233-02d9-45a2-8813-5823d2f8635a"},"source":["sat = sato(image, sigmas=range(1, 10, 2), black_ridges=False, mode='reflect', cval=0)\n","plt.imshow(sat)"],"id":"15979233-02d9-45a2-8813-5823d2f8635a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b98a92de-4dc7-4881-9f8b-7482ec5d43c3"},"source":["image = sat > 0.25\n","skeleton = skeletonize(image)\n","plt.imshow(skeleton)"],"id":"b98a92de-4dc7-4881-9f8b-7482ec5d43c3","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c88d716c-beb7-4f95-bfeb-268cc67a0b9c"},"source":["### Frangi\n","https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.frangi"],"id":"c88d716c-beb7-4f95-bfeb-268cc67a0b9c"},{"cell_type":"code","metadata":{"id":"c02ffa69-5083-4a60-9377-5518f48df7bd"},"source":["fra =frangi(image, sigmas=range(0, 10, 2), scale_range=None, scale_step=None, black_ridges=False, mode='constant', cval=0)\n","plt.imshow(fra)"],"id":"c02ffa69-5083-4a60-9377-5518f48df7bd","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"da9fb421-1cb9-49dc-86f1-03ffc9c18e22"},"source":["image = fra>0\n","skeleton = skeletonize(image)\n","plt.imshow(skeleton)"],"id":"da9fb421-1cb9-49dc-86f1-03ffc9c18e22","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"76be8099-9e4a-4614-9e4f-c805cb126462"},"source":["### Hessian\n","https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.hessian"],"id":"76be8099-9e4a-4614-9e4f-c805cb126462"},{"cell_type":"code","metadata":{"id":"4248cd08-92c5-45c9-96c0-c57dc4bab826"},"source":["hes = hessian(image, sigmas=range(1, 10, 2), scale_range=None, scale_step=None, alpha=0.5, beta=0.5, gamma=15, black_ridges=True, mode='reflect', cval=0)\n","plt.imshow(hes)"],"id":"4248cd08-92c5-45c9-96c0-c57dc4bab826","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1802c942-b405-44ba-a006-c797c640f76c"},"source":[""],"id":"1802c942-b405-44ba-a006-c797c640f76c","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e40bad93-64fa-4f7c-9a92-e70772945f01"},"source":["# Histogram equalization\n","rescaled_spk3 = exposure.equalize_hist(rescaled_spk2)\n","# plt.imshow(rescaled_spk3)\n","\n","# median = cv2.medianBlur(rescaled_spk2, 3)\n","# plt.imshow(median)\n","blurred = filters.gaussian(rescaled_spk3, sigma=1, preserve_range=True)\n","blurred = exposure.equalize_adapthist(blurred)\n","# blurred = cv2.medianBlur(np.float32(blurred), 1)\n","\n","blurred = cv2.normalize(blurred, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n","blurred = blurred.astype(np.uint8)\n","# plt.imshow(bw)\n","\n","\n","plt.imshow(blurred)\n","# norm_image=blurred\n","\n","# closing = cv2.morphologyEx(rescaled_spk3, cv2.MORPH_OPEN, (1,1), iterations = 10)\n","# plt.imshow(closing)\n","\n","# kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(1,1))\n","# kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n","# kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n","# bw = cv2.morphologyEx(norm_image, cv2.MORPH_GRADIENT, (3,3), iterations = 3)\n","# bw = cv2.morphologyEx(norm_image, cv2.MORPH_BLACKHAT, (1,1), iterations = 5)\n","# bw = cv2.morphologyEx(norm_image, cv2.MORPH_TOPHAT, (3,3), iterations = 10)\n","# bw = cv2.morphologyEx(norm_image, cv2.MORPH_OPEN, (3,3), iterations = 10)\n","# bw = cv2.morphologyEx(norm_image, cv2.MORPH_CLOSE, (3,3), iterations = 5)\n","# bw = cv2.morphologyEx(norm_image, cv2.MORPH_DILATE, (3,3), iterations = 1)\n","# bw = cv2.morphologyEx(norm_image, cv2.MORPH_ERODE, kernel, iterations = 1)\n","\n","# bw = cv2.morphologyEx(norm_image, cv2.MORPH_TOPHAT, (3,3), iterations = 10)\n","\n","# blurred = filters.gaussian(blurred, sigma=0.5)\n","\n","# plt.imshow(median)\n","\n","# bw = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, (3,3), iterations = 5)\n","\n","# bw = exposure.equalize_adapthist(bw)\n","# plt.imshow(rescaled_spk3)\n","# bw = cv2.normalize(bw, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n","# bw = bw.astype(np.uint8)\n","# plt.imshow(bw)\n","\n","# plt.imshow(blurred)\n","# np.min(bw)\n","# median = cv2.medianBlur(rescaled_spk2, 3)\n","# plt.imshow(median)"],"id":"e40bad93-64fa-4f7c-9a92-e70772945f01","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"39fdde33-b4fc-497d-9d3e-72cc33943deb"},"source":["# Histrogram\n","np.median(blurred)\n","histogram, bin_edges = np.histogram(blurred)\n","plt.plot(bin_edges[0:-1], histogram)"],"id":"39fdde33-b4fc-497d-9d3e-72cc33943deb","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2a858a78-efa8-4f0a-a4f2-e266f5973e25"},"source":["ridge_filter = cv2.ximgproc.RidgeDetectionFilter_create(dx=1, dy=1, ksize = 7)\n","ridges = ridge_filter.getRidgeFilteredImage(np.float32(blurred))\n","plt.imshow(ridges)\n","\n","# Morphological operations with OpenCV\n","# https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html\n","\n","# kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(5,5))\n","# gradient = cv2.morphologyEx(rescaled_spk2, cv2.MORPH_GRADIENT, kernel)\n","# plt.imshow(gradient)\n","\n","# edges = cv2.Canny(cropped_rgb, 30, 100)\n","# plt.imshow(edges)\n","\n","# kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n","# opening = cv2.morphologyEx(ridges, cv2.MORPH_BLACKHAT, kernel, iterations = 5)\n","# # plt.imshow(opening)\n","\n","# kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n","# closing = cv2.morphologyEx(ridges, cv2.MORPH_OPEN, (3,3), iterations = 3)\n","# plt.imshow(closing)\n","\n","# # kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n","# erode = cv2.morphologyEx(closing, cv2.MORPH_ERODE, kernel, iterations = 1)\n","# plt.imshow(erode)\n","\n","# kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(5,5))\n","# erosion = cv2.erode(opening,kernel,iterations = 1)\n","# # plt.imshow(erosion)"],"id":"2a858a78-efa8-4f0a-a4f2-e266f5973e25","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b30dc6fa-d930-439f-ba4d-03da2fc1d06b"},"source":["# fra=frangi(blurred, black_ridges=False, mode='constant')\n","# plt.imshow(fra)\n","\n","# kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n","# erosion = cv2.erode(fra,kernel,iterations = 5)\n","# plt.imshow(erosion)\n","\n","hyst = filters.scharr_h(blurred)\n","plt.imshow(hyst)\n","\n","# median = cv2.medianBlur(np.uint8(hyst>0), 9)\n","# # plt.imshow(median)\n","\n","# thinned = medial_axis(rescaled_spk2[:,:,0]>0)\n","# plt.imshow(thinned)\n","\n","# medax= medial_axis(thinned)\n","# plt.imshow(medax)\n","\n","\n","# median2 = cv2.medianBlur(median, 3)\n","# # plt.imshow(median2)\n","\n","# median3 = cv2.medianBlur(median2, 3)\n","# plt.imshow(median3)"],"id":"b30dc6fa-d930-439f-ba4d-03da2fc1d06b","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ff1753f2-b09e-48a5-84c9-56d0640b9da7"},"source":["# median = cv2.medianBlur(rescaled_spk2, 3)\n","# plt.imshow(median)\n","\n","# ret, thresh = cv2.threshold(median, 0, 255, cv2.THRESH_BINARY)\n","# plt.imshow(thresh)\n","\n","# contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","\n","\n","# Find contours at a constant value of 0.8\n","contours = measure.find_contours(blurred,255*0.8)\n","\n","# Display the image and plot all contours found\n","fig, ax = plt.subplots()\n","ax.imshow(blurred, cmap=plt.cm.gray)\n","\n","for contour in contours:\n","    ax.plot(contour[:, 1], contour[:, 0], linewidth=1)\n","\n","ax.axis('image')\n","ax.set_xticks([])\n","ax.set_yticks([])\n","plt.show()\n","\n","len(contours)\n","\n","# # create an empty black image\n","# drawing = np.zeros((thresh.shape[0], thresh.shape[1], 3), np.uint8)\n","\n","# # draw contours and hull points\n","# for i in range(len(contours)):\n","#     color_contours = (0, 255, 0) # green - color for contours\n","#     color = (255, 0, 0) # blue - color for convex hull\n","#     # draw ith contour\n","#     plt.drawContours(drawing, contours, i, color_contours, 1, 8, hierarchy)\n"],"id":"ff1753f2-b09e-48a5-84c9-56d0640b9da7","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8d4eb7ee-cda4-4931-882e-ef3a2f2503d2"},"source":["%%time \n","# Resize\n","# im = Image.fromarray((cropped_gray).astype(np.uint8))\n","# (width, height) = (im.width // 30, im.height // 30)\n","# blurred2 = blurred.resize((im.width, im.height))\n","# blurred2 = np.asarray(blurred2)\n","# plt.imshow(blurred2)\n","# (width, height) = (im.width, im.height)\n","# rescaled_spk2 = rescaled_spk2.resize((width, height))\n","\n","# rescaled_spk2 = np.asarray(rescaled_spk2)\n","\n","skel = skeletonize(blurred>200)\n","plt.imshow(skel)\n"],"id":"8d4eb7ee-cda4-4931-882e-ef3a2f2503d2","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"49f4860e-d6ce-46ef-86ac-2aa4604a15e0"},"source":[""],"id":"49f4860e-d6ce-46ef-86ac-2aa4604a15e0","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b7c542ae-043c-4d18-b484-aa534374f0d9"},"source":[""],"id":"b7c542ae-043c-4d18-b484-aa534374f0d9","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"42675d33-7a21-45f6-97e9-729f36c77896"},"source":[""],"id":"42675d33-7a21-45f6-97e9-729f36c77896","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b11a807d-9456-402b-9113-7c6ac583a166"},"source":["blurred2"],"id":"b11a807d-9456-402b-9113-7c6ac583a166","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1f84829c-bc6a-45da-bb5c-35b6e6a182e5"},"source":["\n","\n","# blur = cv2.blur(rescaled_spk2,(10,10))\n","# # blur = cv2.blur(erosion,(30,30))   # With RGB\n","# plt.imshow(blur)\n","\n","kernel = np.ones((3,3),np.uint8)\n","opening = cv2.morphologyEx(rescaled_spk2, cv2.MORPH_OPEN, kernel, iterations = 1)\n","# plt.imshow(opening)\n","\n","median = cv2.medianBlur(opening, 3)\n","plt.imshow(median)\n","\n","# kernel = np.ones((3,3),np.uint8)\n","# closing = cv2.morphologyEx(opening, cv2.MORPH_ERODE, kernel, iterations = 1)\n","# plt.imshow(closing)"],"id":"1f84829c-bc6a-45da-bb5c-35b6e6a182e5","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ffd9eaad-ea31-47b2-9d62-9eba5198b093"},"source":["median2 = exposure.equalize_hist(median)\n","plt.imshow(median2)\n","# plt.imshow(color.rgb2gray(median))"],"id":"ffd9eaad-ea31-47b2-9d62-9eba5198b093","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2dd69a12-d507-40cf-a80b-8f8ce26ed044"},"source":["from skimage.draw import line\n","\n","# Constructing test image\n","image = np.zeros((200, 200))\n","idx = np.arange(25, 175)\n","image[idx, idx] = 255\n","image[line(45, 25, 25, 175)] = 255\n","image[line(25, 135, 175, 155)] = 255\n","\n","# Classic straight-line Hough transform\n","# Set a precision of 0.5 degree.\n","tested_angles = np.linspace(-np.pi / 2, np.pi / 2, 360, endpoint=False)\n","h, theta, d = hough_line(image)\n","\n","# Generating figure 1\n","fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n","ax = axes.ravel()\n","\n","ax[0].imshow(image)\n","ax[0].set_title('Input image')\n","ax[0].set_axis_off()\n","\n","angle_step = 0.5 * np.diff(theta).mean()\n","d_step = 0.5 * np.diff(d).mean()\n","bounds = [np.rad2deg(theta[0] - angle_step),\n","          np.rad2deg(theta[-1] + angle_step),\n","          d[-1] + d_step, d[0] - d_step]\n","ax[1].imshow(np.log(1 + h), extent=bounds, aspect=1 / 1.5)\n","ax[1].set_title('Hough transform')\n","ax[1].set_xlabel('Angles (degrees)')\n","ax[1].set_ylabel('Distance (pixels)')\n","ax[1].axis('image')\n","\n","ax[2].imshow(image)\n","ax[2].set_ylim((image.shape[0], 0))\n","ax[2].set_axis_off()\n","ax[2].set_title('Detected lines')\n","\n","for _, angle, dist in zip(*hough_line_peaks(h, theta, d)):\n","    (x0, y0) = dist * np.array([np.cos(angle), np.sin(angle)])\n","    ax[2].axline((x0, y0), slope=np.tan(angle + np.pi/2))\n","\n","plt.tight_layout()\n","plt.show()\n","\n"],"id":"2dd69a12-d507-40cf-a80b-8f8ce26ed044","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"19aef4b3-0a23-486f-b7cf-212975127e27"},"source":["h, theta, d = hough_line_peaks(h, theta, d)"],"id":"19aef4b3-0a23-486f-b7cf-212975127e27","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"19cd8095-6ca5-44dc-b550-0c34ebfbb699"},"source":["medax= medial_axis(cropped_gray)\n","# plt.imshow(medax)\n","\n","tested_angles = np.linspace(-np.pi, np.pi, 360, endpoint=False)\n","h, theta, d = hough_line(medax, tested_angles)\n","# plt.imshow(out)\n","\n","# np.linspace(-np.pi / 2, np.pi / 2, 360, endpoint=False)\n","\n","# Generating figure 1\n","fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n","ax = axes.ravel()\n","\n","ax[0].imshow(medax)\n","ax[0].set_title('Input image')\n","ax[0].set_axis_off()\n","\n","ax[1].imshow(np.log(1+h))\n","ax[1].set_title('Hough transform')\n","ax[1].set_xlabel('Angles (degrees)')\n","ax[1].set_ylabel('Distance (pixels)')\n","ax[1].axis('image')\n","\n","ax[2].imshow(medax, cmap=\"gray\")\n","ax[2].set_ylim((medax.shape[0], 0))\n","ax[2].set_axis_off()\n","ax[2].set_title('Detected lines')\n","\n","for _, angle, dist in zip(*hough_line_peaks(h, theta, d, min_angle=0, min_distance=1)):\n","    (x0, y0) = dist * np.array([np.cos(angle), np.sin(angle)])\n","    ax[2].axline((x0, y0), slope=np.tan(angle + np.pi/2))\n","\n","plt.tight_layout()\n","plt.show()\n","# newrgb = np.where(medax[..., None], cropped_rgb, 0)\n","# plt.imshow(newrgb)"],"id":"19cd8095-6ca5-44dc-b550-0c34ebfbb699","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f5bec34c-3767-486f-ab24-2203cecc1b93"},"source":["max(theta)"],"id":"f5bec34c-3767-486f-ab24-2203cecc1b93","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ea48c043-d5bf-4fc2-9d55-25263b34aaeb"},"source":["lines = probabilistic_hough_line(medax, line_length=10,line_gap=1)\n","# plt.plot(lines)"],"id":"ea48c043-d5bf-4fc2-9d55-25263b34aaeb","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fb1c15d1-a04a-4c98-b4c5-e08f5dcbee61"},"source":["# Generating figure 2\n","fig, axes = plt.subplots(3,1, figsize=(15, 5), sharex=True, sharey=True)\n","ax = axes.ravel()\n","\n","ax[0].imshow(cropped_gray, cmap='gray')\n","ax[0].set_title('Input image')\n","\n","ax[1].imshow(medax, cmap='gray')\n","ax[1].set_title('Canny edges')\n","\n","ax[2].imshow(edges * 0)\n","for line in lines:\n","    p0, p1 = line\n","    ax[2].plot((p0[0], p1[0]), (p0[1], p1[1]))\n","ax[2].set_xlim((0, cropped_gray.shape[1]))\n","ax[2].set_ylim((cropped_gray.shape[0], 0))\n","ax[2].set_title('Probabilistic Hough')\n","\n","for a in ax:\n","    a.set_axis_off()\n","\n","plt.tight_layout()\n","plt.show()"],"id":"fb1c15d1-a04a-4c98-b4c5-e08f5dcbee61","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eyT4JaS5flwH"},"source":["%%time\n","# fra=frangi(cropped_gray, black_ridges=False, mode='constant')\n","# plt.imshow(fra)\n","\n","norm_image = cv2.normalize(fra, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n","norm_image = norm_image.astype(np.uint8)\n","plt.imshow(norm_image)\n"],"id":"eyT4JaS5flwH","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"51e0bbff-4883-405c-a171-03dfe822053d"},"source":["bw = cv2.morphologyEx(norm_image, cv2.MORPH_TOPHAT, (3,3), iterations = 10)\n","# plt.imshow(bw)\n","\n","\n","newrgb = np.where(bw[...], cropped_gray, 0)\n","plt.imshow(newrgb)"],"id":"51e0bbff-4883-405c-a171-03dfe822053d","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3753e62-2d35-492c-87ed-51d7da6d7c50"},"source":["image = 255-newrgb\n","hes = hessian(image, sigmas=range(1, 10, 2), scale_range=None, scale_step=None, alpha=0.5, beta=0.5, gamma=15, black_ridges=False, mode='reflect', cval=0)\n","plt.imshow(hes)"],"id":"c3753e62-2d35-492c-87ed-51d7da6d7c50","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"08c2b930-919a-4d9a-a8c0-be6841c8b505"},"source":["scipy.ndimage.morphology.distance_transform_edt"],"id":"08c2b930-919a-4d9a-a8c0-be6841c8b505","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e736a7b1-1919-46a3-b113-3c5c6ce0c5ec"},"source":["ridge_filter = cv2.ximgproc.RidgeDetectionFilter_create(dx=1, dy=1, ksize = 3)\n","ridges = ridge_filter.getRidgeFilteredImage(np.uint8(image))\n","plt.imshow(ridges)\n","\n","# newrgb2 = np.where(ridges[..., None], newrgb, 0)\n","# plt.imshow(newrgb2)"],"id":"e736a7b1-1919-46a3-b113-3c5c6ce0c5ec","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"272b3932-5460-4d5e-90ff-ed0e58a51d83"},"source":["# medax= medial_axis(ridges)\n","# plt.imshow(medax)\n","\n","norm_image = cv2.normalize(ridges, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n","norm_image = norm_image.astype(np.uint8)\n","plt.imshow(norm_image)"],"id":"272b3932-5460-4d5e-90ff-ed0e58a51d83","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9efcc705-1cab-4c06-b79c-58dbaf57bb79"},"source":[""],"id":"9efcc705-1cab-4c06-b79c-58dbaf57bb79","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ad0e2301-fa7c-484f-bb43-3f56d1f911b5"},"source":["thin1= thin(norm_image)\n","plt.imshow(thin1)"],"id":"ad0e2301-fa7c-484f-bb43-3f56d1f911b5","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"81848612-b4ed-4cf4-853e-2295d71c920d"},"source":["# kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n","# kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n","# kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n","# bw = cv2.morphologyEx(norm_image, cv2.MORPH_GRADIENT, (3,3), iterations = 10)\n","# bw = cv2.morphologyEx(norm_image, cv2.MORPH_BLACKHAT, kernel, iterations = 10)\n","# bw = cv2.morphologyEx(norm_image, cv2.MORPH_TOPHAT, (3,3), iterations = 10)\n","# bw = cv2.morphologyEx(norm_image, cv2.MORPH_OPEN, (3,3), iterations = 10)\n","# bw = cv2.morphologyEx(norm_image, cv2.MORPH_CLOSE, (3,3), iterations = 5)\n","bw = cv2.morphologyEx(255-image, cv2.MORPH_DILATE, (3,3), iterations = 5)\n","# bw = cv2.morphologyEx(newrgb, cv2.MORPH_ERODE, (3,3), iterations = 10)\n","plt.imshow(bw)\n","\n","# # do connected components processing\n","# nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(bw, None, None, None, 8, cv2.CV_32S)\n","\n","# #get CC_STAT_AREA component as stats[label, COLUMN] \n","# areas = stats[1:,cv2.CC_STAT_AREA]\n","\n","# result = np.zeros((labels.shape), np.uint8)\n","\n","# for i in range(0, nlabels - 1):\n","#     if areas[i] >= 100:   #keep\n","#         result[labels == i + 1] = 255\n","        \n","# plt.imshow(result)"],"id":"81848612-b4ed-4cf4-853e-2295d71c920d","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d973767c-8060-477b-9904-f9d0df9c9dcd"},"source":["# kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n","# kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n","# kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n","# bw = cv2.morphologyEx(norm_image, cv2.MORPH_GRADIENT, kernel, iterations = 5)\n","# bw = cv2.morphologyEx(norm_image, cv2.MORPH_BLACKHAT, kernel, iterations = 10)\n","# bw = cv2.morphologyEx(result, cv2.MORPH_TOPHAT, (3,3), iterations = 10)\n","# bw = cv2.morphologyEx(norm_image, cv2.MORPH_OPEN, kernel, iterations = 10)\n","# plt.imshow(bw)\n","\n","# hyst = filters.scharr_h(bw)\n","# plt.imshow(hyst)\n","\n","thinned = medial_axis(blurred>0.5)\n","plt.imshow(thinned)\n","\n","# kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n","# erosion = cv2.erode(cropped_lab,kernel,iterations = 5)\n","# # plt.imshow(erosion)\n","\n","# hyst = filters.scharr_h(fra)\n","# plt.imshow(hyst)\n","\n","\n","\n","\n","# norm_image = cv2.normalize(hyst, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n","# norm_image = norm_image.astype(np.uint8)\n","# plt.imshow(norm_image)\n","# thresh = np.median(hyst) + (np.std(hyst) * 2)\n","\n","# medax= medial_axis(result)\n","# plt.imshow(medax)"],"id":"d973767c-8060-477b-9904-f9d0df9c9dcd","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9fef2ff4-a59e-4be5-be83-cd2e406a7245"},"source":["np.amax(medax)"],"id":"9fef2ff4-a59e-4be5-be83-cd2e406a7245","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fh84n5jEfmLI"},"source":["np.mean(hyst)"],"id":"fh84n5jEfmLI","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8dJymOI0fmm5"},"source":["# Dilation\n","# kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n","# dilation = cv2.dilate(np.uint8(medax),kernel,iterations = 2)\n","# # plt.imshow(dilation)\n","\n","result= thin(dilation)\n","plt.imshow(result)"],"id":"8dJymOI0fmm5","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e77cd88c-5376-47ec-8320-3fae2596be38"},"source":["\n","# blur = cv2.blur(cropped_gray,(50,50))\n","# blur = cv2.blur(opening,(3,3))   # With RGB\n","# plt.imshow(blur)\n","# np.amax(blur)\n","medax= medial_axis(blurred)\n","plt.imshow(medax)"],"id":"e77cd88c-5376-47ec-8320-3fae2596be38","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n4WaeY5YbkAc"},"source":["# h, theta, d = hough_line(medax)\n","# plt.imshow(np.uint8(medax))\n","\n","# norm_image = cv2.normalize(np.uint8(medax), None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n","# norm_image = norm_image.astype(np.uint8)\n","# plt.imshow(norm_image)\n","\n","# minLineLength = 10\n","# maxLineGap = 5\n","# lines = cv2.HoughLinesP(norm_image, 1, np.pi/180, 200, minLineLength, maxLineGap)\n","# for x1, y1, x2, y2 in lines[0]:\n","#     cv2.line(norm_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n","# cv2.imwrite('.\\canny5.jpg', norm_image)\n","\n","\n","lines = cv2.HoughLines(norm_image,1,np.pi/180,200)\n","for rho,theta in lines[0]:\n","    a = np.cos(theta)\n","    b = np.sin(theta)\n","    x0 = a*rho\n","    y0 = b*rho\n","    x1 = int(x0 + 1000*(-b))\n","    y1 = int(y0 + 1000*(a))\n","    x2 = int(x0 - 1000*(-b))\n","    y2 = int(y0 - 1000*(a))\n","\n","    cv2.line(norm_image,(x1,y1),(x2,y2),(0,0,255),2)\n","\n","cv2.imwrite('houghlines3.jpg',norm_image)\n","\n","\n","# cv2.imwrite('.\\houghlines5.jpg', cropped_rgb)\n","\n","# # Generating figure 1\n","# fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n","# ax = axes.ravel()\n","\n","# ax[0].imshow(medax)\n","# ax[0].set_title('Input image')\n","# ax[0].set_axis_off()\n","\n","# ax[1].imshow(np.log(1+h))\n","# ax[1].set_title('Hough transform')\n","# ax[1].set_xlabel('Angles (degrees)')\n","# ax[1].set_ylabel('Distance (pixels)')\n","# ax[1].axis('image')\n","\n","# ax[2].imshow(medax, cmap=\"gray\")\n","# ax[2].set_ylim((medax.shape[0], 0))\n","# ax[2].set_axis_off()\n","# ax[2].set_title('Detected lines')\n","\n","# for _, angle, dist in zip(*hough_line_peaks(h, theta, d)):\n","#     (x0, y0) = dist * np.array([np.cos(angle), np.sin(angle)])\n","#     ax[2].axline((x0, y0), slope=np.tan(angle + np.pi/2))\n","\n","# plt.tight_layout()\n","# plt.show()"],"id":"n4WaeY5YbkAc","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"40a92da7-ea8c-42fd-8cb8-635d8f6da67d"},"source":["# angles\n","\n","sns.histplot(h, bins=100)\n"],"id":"40a92da7-ea8c-42fd-8cb8-635d8f6da67d","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WoDDheypNUd4"},"source":["# Erosion\n","kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n","erosion = cv2.erode(fra,kernel,iterations =3)\n","plt.imshow(erosion)\n","\n","erosion2 = erosion * 1000 * 255\n","np.amax(fra)\n","edges = cv2.Canny(np.uint8(fra*10000), 0.03, 0.1)\n","plt.imshow(edges)\n","\n","\n","\n","# Opening\n","kernel = np.ones((5,5),np.uint8)\n","opening = cv2.morphologyEx(erosion, cv2.MORPH_OPEN, (5,5), iterations = 1)\n","plt.imshow(opening)\n","\n","blur = cv2.blur(np.float32(opening),(10,10))\n","blur = cv2.blur(opening,(3,3))   # With RGB\n","plt.imshow(blur)\n","\n","# Dilation\n","kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n","dilation = cv2.dilate(blur,kernel,iterations = 2)\n","plt.imshow(dilation)"],"id":"WoDDheypNUd4","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"be50adc6-e57e-484e-8573-df2e4fb660ad"},"source":["# dilation = dilation*255\n","gray_skel = opening @ [0.2126, 0.7152, 0.0722]\n","plt.imshow(gray_skel)\n","np.amin(gray_skel)"],"id":"be50adc6-e57e-484e-8573-df2e4fb660ad","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b1fbe987-a870-468f-a470-d6657ddba780"},"source":["## Frangi"],"id":"b1fbe987-a870-468f-a470-d6657ddba780"},{"cell_type":"code","metadata":{"id":"86497dce-a9af-4873-acfd-8ad17257f6a0"},"source":["%%time\n","fra =frangi(cropped_gray>0, black_ridges=False)\n","plt.imshow(fra)"],"id":"86497dce-a9af-4873-acfd-8ad17257f6a0","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c6ecdd7b-239b-4aee-8519-91a3fcf4e5ab"},"source":["np.min(cropped_gray)"],"id":"c6ecdd7b-239b-4aee-8519-91a3fcf4e5ab","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fc978be5-2392-4eb9-a508-b6bd3398108f"},"source":["## Skeleton"],"id":"fc978be5-2392-4eb9-a508-b6bd3398108f"},{"cell_type":"code","metadata":{"id":"d4a11552-81ed-410c-afcf-fedb9da173c4"},"source":["gray_skel = gray_skel>-0.001\n","plt.imshow(gray_skel)\n","\n","skel = skeletonize(fra>0)\n","plt.imshow(skel)"],"id":"d4a11552-81ed-410c-afcf-fedb9da173c4","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b30fd696-0c28-43c7-a0e6-dc72d301492b"},"source":["### Data"],"id":"b30fd696-0c28-43c7-a0e6-dc72d301492b"},{"cell_type":"code","metadata":{"id":"429ec9ee-ebe7-4cad-aff4-3a4e7c457e3a"},"source":["data_skel = summarize(Skeleton(skel))"],"id":"429ec9ee-ebe7-4cad-aff4-3a4e7c457e3a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"77e4dc5a-1cf9-49e6-96e2-90d9a517d4d6"},"source":["data_skel"],"id":"77e4dc5a-1cf9-49e6-96e2-90d9a517d4d6","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f43e5447-d314-4cf2-b418-1e1f0639a79a"},"source":["pixel_graph, coordinates, degrees = skeleton_to_csgraph(skel)\n","# plt.imshow(degrees)"],"id":"f43e5447-d314-4cf2-b418-1e1f0639a79a","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cdcc98e4-13e6-49db-9cba-e4941a321292"},"source":["### Overlay"],"id":"cdcc98e4-13e6-49db-9cba-e4941a321292"},{"cell_type":"code","metadata":{"id":"ea68874e-73d0-4cfb-b1ad-ed82ff6aac57"},"source":["draw.overlay_euclidean_skeleton_2d(rescaled_spk, data_skel, skeleton_color_source='branch-type')"],"id":"ea68874e-73d0-4cfb-b1ad-ed82ff6aac57","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c933784d-1b01-4550-88d2-d9911d064658"},"source":["# Histograms\n","data_skel.hist(column='branch-distance', by='branch-type', bins=100)"],"id":"c933784d-1b01-4550-88d2-d9911d064658","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d8ded33f-e663-44de-9d75-7ff695423d99"},"source":["## Medial axis"],"id":"d8ded33f-e663-44de-9d75-7ff695423d99"},{"cell_type":"code","metadata":{"id":"0ff35698-c161-4556-979e-7fc277abd6e3"},"source":["# Compute the medial axis (skeleton) and the distance transform\n","medax, distance = medial_axis(erosion, return_distance=True)\n","plt.imshow(medax)\n","\n","kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n","dilation = cv2.dilate(np.float32(medax),(5,5),iterations = 4)\n","plt.imshow(dilation)\n","\n"],"id":"0ff35698-c161-4556-979e-7fc277abd6e3","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6f02ade9-6ded-4ee3-baf6-593697959aa7"},"source":["# plt.imshow(distance)\n","# distance.shape\n","# np.amin(distance)"],"id":"6f02ade9-6ded-4ee3-baf6-593697959aa7","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"96c90e4b-1951-42c9-a193-1e794a11400c"},"source":["data_medax = summarize(Skeleton(medax))"],"id":"96c90e4b-1951-42c9-a193-1e794a11400c","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3122d230-4951-4ef6-8b87-14a6430a3a80"},"source":["data_medax"],"id":"3122d230-4951-4ef6-8b87-14a6430a3a80","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f0b6359a-d36f-4f6a-a75d-848774578ab9"},"source":["pixel_graph, coordinates, degrees = skeleton_to_csgraph(medax)\n","# plt.imshow(degrees)"],"id":"f0b6359a-d36f-4f6a-a75d-848774578ab9","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c717c656-4467-415d-b22e-2a3e30f2a180"},"source":[" draw.overlay_euclidean_skeleton_2d(rescaled_spk, data_medax, skeleton_color_source='branch-type')"],"id":"c717c656-4467-415d-b22e-2a3e30f2a180","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1a0fbe11-f793-4118-aed9-db460278967b"},"source":["# Histograms\n","data_medax.hist(column='branch-distance', by='branch-type', bins=100)"],"id":"1a0fbe11-f793-4118-aed9-db460278967b","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"22f113c3-6ba7-43c6-b1ef-e6776293017b"},"source":[""],"id":"22f113c3-6ba7-43c6-b1ef-e6776293017b","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1e0d275e-4a2f-4aa9-a7e4-36ad55b30aaf"},"source":[""],"id":"1e0d275e-4a2f-4aa9-a7e4-36ad55b30aaf","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"33df8c98-7670-4595-ade5-69a78065f682"},"source":[""],"id":"33df8c98-7670-4595-ade5-69a78065f682","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"79877fe2-07d4-4858-b979-9e80b7455423"},"source":[""],"id":"79877fe2-07d4-4858-b979-9e80b7455423","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"average-instrumentation"},"source":["## Properties\n","Here we look at the overall properties of each spike without any detail about branches\n"],"id":"average-instrumentation"},{"cell_type":"code","metadata":{"id":"fantastic-enlargement"},"source":["# Get geometric and spectral properties\n","spk_df = SpikesDF(img0_name)"],"id":"fantastic-enlargement","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rational-conversation"},"source":["# Visualize column names\n","print(spk_df.columns)"],"id":"rational-conversation","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ff184cb-a3df-487f-a972-bccae7f1f622"},"source":[""],"id":"6ff184cb-a3df-487f-a972-bccae7f1f622","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6a5d633d-3b03-41c6-aa34-5096abdae41f"},"source":[""],"id":"6a5d633d-3b03-41c6-aa34-5096abdae41f","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6d0d03b4-ec86-455f-ba54-2ffe66a3423a"},"source":[""],"id":"6d0d03b4-ec86-455f-ba54-2ffe66a3423a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6c9b76cd-2636-48a8-aff3-86bc666da586"},"source":[""],"id":"6c9b76cd-2636-48a8-aff3-86bc666da586","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f4d1b975-6bf2-4fea-97fd-bca2bd472651"},"source":[""],"id":"f4d1b975-6bf2-4fea-97fd-bca2bd472651","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"54f54ee3-01fc-4668-b053-3d568a78ffd0"},"source":["# Functions"],"id":"54f54ee3-01fc-4668-b053-3d568a78ffd0"},{"cell_type":"markdown","metadata":{"id":"6fbeec74-6189-46e8-93d4-290b3427bc28"},"source":["## `ListImages`\n","Returns a list of full image paths."],"id":"6fbeec74-6189-46e8-93d4-290b3427bc28"},{"cell_type":"code","metadata":{"id":"2745083a-2963-48c9-8f97-f0e2f725acde"},"source":["%%time\n","def ListImages(path, imgformat=\".tif\", recursive=False):\n","    Images = glob.glob(path + '/*' + imgformat, recursive=True)    \n","    return Images\n","\n","# Example:\n","# path = r'./Images/TEST'\n","# Images = ListImages(path, imgformat=\".tif\", recursive=False)"],"id":"2745083a-2963-48c9-8f97-f0e2f725acde","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5cb4c25c-3c76-4932-a5ca-3275d56676bb"},"source":["## `RemoveBackground`\n","Input can be the image as an array or just the full image path.\n","It takes almost 25 seconds to create list with five images (rgb, gray, lab, hsv, bw). Needs to be optimized."],"id":"5cb4c25c-3c76-4932-a5ca-3275d56676bb"},{"cell_type":"code","metadata":{"id":"f837048f-e4a8-4d0c-a0e0-7586025a3328"},"source":["%%time\n","def RemoveBackground(img, OtsuScaling=0.25, rgb_out=True, gray_out=True, lab_out=True, hsv_out=True, bw_out=True):\n","    \n","    # Read image\n","    if isinstance(img, str) == True:\n","        img0 = plt.imread(img)\n","    else: \n","        img0 = img\n","    \n","    # Crop images. They were all taken with the same scanner\n","    img1 = img0[44:6940, 25:4970, :]\n","    \n","     # Convert to gray\n","    gray0 = img1 @ [0.2126, 0.7152, 0.0722]\n","    \n","    # Set image threshold\n","    T = filters.threshold_otsu(gray0)\n","#     print(T)\n","    T = T*OtsuScaling\n","#     print(T)\n","    \n","    # Segment gray image\n","    bw0 = gray0 > T\n","    \n","    # Remove small objects\n","    n_pixels = gray0.shape[0] * gray0.shape[1]\n","    minimum_size = n_pixels/10000\n","    bw1 = morphology.remove_small_objects(bw0, min_size=np.floor(minimum_size))\n","    \n","    ImagesOut = []\n","#     len(ImagesOut)\n","    \n","    if rgb_out==True:\n","        # Apply mask to RGB\n","        rgb = np.where(bw1[..., None], img1, 0)\n","        ImagesOut.append(rgb)\n","    if gray_out==True and rgb_out==True:\n","        gray = color.rgb2gray(rgb)\n","        ImagesOut.append(gray)\n","    if lab_out==True and rgb_out==True:\n","        lab = color.rgb2lab(rgb)\n","        ImagesOut.append(lab)\n","    if hsv_out==True and rgb_out==True:\n","        hsv = color.rgb2hsv(rgb)\n","        ImagesOut.append(hsv)\n","    if bw_out==True:\n","#         # Threshold\n","#         otsu = filters.threshold_otsu(gray)\n","#         bw0 = gray > 0\n","#         bw = morphology.remove_small_objects(bw0, min_size=1.5e-05 * gray.shape[0] * gray.shape[1])\n","        ImagesOut.append(bw1)\n","    \n","    return ImagesOut\n","\n","# Usage:\n","# %%time\n","# I = RemoveBackground(Images[3], OtsuScaling=0.25, rgb_out=True, gray_out=True, lab_out=True, hsv_out=True, bw_out=True)\n","# rgb0 = I[0]\n","# gray0 = I[1]\n","# lab0 = I[2]\n","# hsv0 = I[3]\n","# bw0 = I[4]\n"],"id":"f837048f-e4a8-4d0c-a0e0-7586025a3328","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6b4820a4-bb4d-4506-8af3-7b3d45edfbd6"},"source":["## `EnumerateSpkCV`\n","Enumerate spikes, spikelets, or contours."],"id":"6b4820a4-bb4d-4506-8af3-7b3d45edfbd6"},{"cell_type":"code","metadata":{"id":"e790d91a-2f5f-4f72-869b-b7ed764b40f9"},"source":["%%time\n","# Enumerate spikes\n","def EnumerateSpkCV(bw, rgb, TextSize=5, TROE2020=False):\n","    \n","    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(bw), connectivity=8)\n","    img = rgb.copy()\n","    \n","    if TROE2020==True:\n","        counter=-1\n","    else:\n","        counter=0\n","        for c in centroids:\n","    #         print(c)\n","            cx = round(c[0])\n","            cy = round(c[1])\n","            img = cv2.circle(img, (cx, cy), 10, (255, 0, 0), -1)\n","            img = cv2.putText(img, str(counter), (cx - 25, cy - 25),cv2.FONT_HERSHEY_SIMPLEX, TextSize, (255, 0, 0), 15)\n","            counter = counter+1\n","        plt.imshow(img)\n","\n","# # Example:\n","# EnumerateSpkCV(bw0, rgb0, TextSize=5, TROE2020=False)\n","# EnumerateSpkCV(spklts, cropped_rgb, TextSize=5, TROE2020=False)"],"id":"e790d91a-2f5f-4f72-869b-b7ed764b40f9","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cea2767e-68c4-4e9f-ba45-dd12f098b60f"},"source":["## `spk_length`\n","Return the spike length"],"id":"cea2767e-68c4-4e9f-ba45-dd12f098b60f"},{"cell_type":"code","metadata":{"id":"58e8ea47-9227-4d05-b214-00bb637fdbbe"},"source":["%%time\n","\n","def spk_length(cropped_spk, method='skelblur', Overlay=True, PlotCH=False):\n","    \n","    if method=='skelblur':\n","        # Severly blur the image\n","        blur = cv2.blur(np.float32(cropped_spk),(100,100))\n","        # Threshold the blur\n","        thrb = blur > 0.1\n","        skeleton = skeletonize(thrb)\n","#         plt.imshow(skeleton)\n","        \n","    if method=='chull':\n","        # Blur the image with a 50x50 kernel\n","        blur = cv2.blur(np.float32(cropped_spk),(50,50))\n","\n","        # Get convex hull \n","        chull = convex_hull_image(blur>0)\n","\n","        # Perform skeletonization\n","        image = chull\n","        skeleton = skeletonize(image)\n","    #     plt.imshow(skeleton)\n","    \n","    # Spike length\n","    SpkL = cv2.countNonZero(np.float32(skeleton))\n","    \n","    if PlotCH == True:\n","        fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n","        ax = axes.ravel()\n","\n","        ax[0].set_title('Original picture')\n","        ax[0].imshow(cropped_spk, cmap=plt.cm.gray)\n","        ax[0].set_axis_off()\n","\n","        ax[1].set_title('Transformed picture')\n","        ax[1].imshow(chull, cmap=plt.cm.gray)\n","        ax[1].set_axis_off()\n","\n","        plt.tight_layout()\n","        plt.show()\n","    \n","    # Visualize overlay?\n","    if Overlay == True:\n","        overlay_images = cv2.addWeighted(np.float32(cropped_spk),20,np.float32(skeleton),255,0)\n","        plt.imshow(overlay_images, cmap='gray')\n","    \n","    return SpkL\n","\n","# Example:\n","# SL = spk_length(cropped_spk, method='skelblur', Overlay=True, PlotCH=False)"],"id":"58e8ea47-9227-4d05-b214-00bb637fdbbe","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1d15be79-4eda-4205-a336-ba4e06fef804"},"source":["## `PixelHist`\n","Object histogram analysis. This function returns the black and white version of the given image(s) and print the label of each spike as computed by 'skimage.measure.label'\n"],"id":"1d15be79-4eda-4205-a336-ba4e06fef804"},{"cell_type":"code","metadata":{"id":"3853b8c9-c824-4438-84f7-11dbb501f273"},"source":["%%time\n","def PixelHist(bw, ColorSpace, channel = 0, spikes=\"All\", nbins = 100):\n","    \n","    labeled_spks, num_spikes = label(bw, return_num = True)\n","#     plt.imshow(labeled_spks==0)\n","\n","    if spikes==\"All\":\n","        labeled_spks = labeled_spks\n","    else:\n","        for L in range(1,num_spikes+1):\n","#             print(L)\n","            if not L in spikes:\n","#                 print(\"Deleted label \", L)\n","                labeled_spks=np.where(labeled_spks==L, 0, labeled_spks)\n","#     plt.imshow(labeled_spks)\n","    \n","    Props = regionprops(labeled_spks, intensity_image=ColorSpace[:,:,channel])\n","    Areas = [rp.area for rp in Props]\n","    Labels = [rp.label for rp in Props] #Delete 1 because label in image is +1 greater than ACTUAL label\n","    Spikes_Data = []\n","    Names = []\n","    Colors = sns.color_palette(\"husl\", len(spikes))\n","    Colors2 = [list(i) for i in Colors] # list of lists\n","    \n","    \n","    for indexed in range(len(Labels)):        \n","        spk_data = Props[indexed].intensity_image \n","        spk_data = spk_data.ravel()\n","        NonZero = spk_data[spk_data != 0]\n","\n","        Spikes_Data.append(NonZero)\n","        Names.append(\"Spike \" + str(int(spikes[indexed])) + \"\\n\" + \"Area = \"  + str(round(np.mean(NonZero))) + \" px\" + \"\\n\" +\n","                     \"Mean = \"  + str(round(np.mean(NonZero), 1)))\n","        Colors.append(list(np.random.choice(range(2), size=3)))\n","    \n","    plt.hist(Spikes_Data, bins = nbins, color = Colors2, label = Names);\n","    \n","    # Plot formatting\n","    plt.legend();\n","    plt.xlabel('Intensity Value');\n","    plt.ylabel('Number of NonZero Pixels');\n","    plt.title('Distribution of None-Zero Pixel Values for Selected Given Channel and Spikes');\n","\n","# Example:\n","# PixelHist(bw=bw0, ColorSpace=lab0, channel = 0, spikes=[1,2,26], nbins = 100)"],"id":"3853b8c9-c824-4438-84f7-11dbb501f273","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"78ba90f0-1aa9-4fe8-a14d-e7d5bcec210f"},"source":["## `channel_percentiles`\n","This returns the percentiles for a given channel."],"id":"78ba90f0-1aa9-4fe8-a14d-e7d5bcec210f"},{"cell_type":"code","metadata":{"id":"c09ff596-d11d-43a2-a1e4-66e06b9521e3"},"source":["%%time\n","def channel_percentiles(channel_props, Negatives = None):\n","      \n","    # Create empty lists to populate    \n","    p25_pos_list = []\n","    p50_pos_list = []\n","    p75_pos_list = []\n","    p25_neg_list = []\n","    p50_neg_list = []\n","    p75_neg_list = []\n","    mean_pos_list = []\n","    sd_pos_list = []\n","    min_pos_list = []\n","    max_pos_list = []\n","    mean_neg_list = []\n","    sd_neg_list = []\n","    min_neg_list = []\n","    max_neg_list = []\n","    \n","#     channel_props[1].intensity_image\n","    \n","\n","    # channel_props = a_props\n","    for spk in range(len(channel_props)):\n","        # spk=0\n","        my_array = channel_props[spk].intensity_image\n","#         plt.imshow(my_array)\n","        flat_array = my_array.ravel()\n","        non_zero = flat_array[flat_array != 0]\n","\n","        positive_values = non_zero[non_zero > 0]\n","        if positive_values.size == 0:\n","            positive_values = [0]        \n","        p25_pos = np.nanpercentile(positive_values, 25)\n","        p25_pos_list.append(p25_pos)\n","        p50_pos = np.nanpercentile(positive_values, 50)\n","        p50_pos_list.append(p50_pos)\n","        p75_pos = np.nanpercentile(positive_values, 75)\n","        p75_pos_list.append(p75_pos)\n","        mean_pos = np.mean(positive_values)\n","        mean_pos_list.append(mean_pos)\n","        sd_pos = np.std(positive_values)\n","        sd_pos_list.append(sd_pos)\n","        min_pos = min(positive_values)\n","        min_pos_list.append(min_pos)\n","        max_pos = max(positive_values)\n","        max_pos_list.append(max_pos)\n","\n","        if Negatives == True:\n","            negative_values = non_zero[non_zero < 0]\n","            # Make sure list is not empty, otherwise add a zero\n","            if negative_values.size == 0:\n","                negative_values = [0]\n","            p25_neg = np.nanpercentile(negative_values, 25)\n","            p25_neg_list.append(p25_neg)\n","            p50_neg = np.nanpercentile(negative_values, 50)\n","            p50_neg_list.append(p50_neg)\n","            p75_neg = np.nanpercentile(negative_values, 75)\n","            p75_neg_list.append(p75_neg)\n","            mean_neg = np.mean(negative_values)\n","            mean_neg_list.append(mean_neg)\n","            sd_neg = np.std(positive_values)\n","            sd_neg_list.append(sd_neg)\n","            min_neg = min(negative_values)\n","            min_neg_list.append(min_neg)\n","            max_neg = max(negative_values)\n","            max_neg_list.append(max_neg)\n","\n","            Lists = [p25_pos_list, p50_pos_list, p75_pos_list, mean_pos_list, sd_pos_list, min_pos_list, max_pos_list, p25_neg_list, p50_neg_list, p75_neg_list, mean_neg_list, sd_neg_list, min_neg_list, max_neg_list]\n","        else:\n","            Lists = [p25_pos_list, p50_pos_list, p75_pos_list, mean_pos_list, sd_pos_list, min_pos_list, max_pos_list]\n","\n","        \n","        # if any(pixel < 0 for pixel in non_zero) == True:\n","        #     negative_values = non_zero[non_zero < 0]\n","        #     p25_neg = np.percentile(negative_values, 25)\n","        #     p25_neg_list.append(p25_neg)\n","        #     p50_neg = np.percentile(negative_values, 50)\n","        #     p50_neg_list.append(p50_neg)\n","        #     p75_neg = np.percentile(negative_values, 75)\n","        #     p75_neg_list.append(p75_neg)\n","    return Lists\n","\n","\n","########################################################################################\n","# Examples:\n","\n","# For one spike\n","# labeled_contours, num_contours = label(cropped_spk, return_num = True)\n","# red_props = regionprops(labeled_contours, intensity_image=cropped_rgb)\n","# a_Perc = np.array(channel_percentiles(channel_props=a_props, Negatives=True)).T\n","# len(a_Perc)\n","\n","\n","# For one entire image\n","# labeled_contours, num_contours = label(bw0, return_num = True)\n","# red_props = regionprops(labeled_contours, intensity_image=rgb0)\n","# Red_Perc = np.array(channel_percentiles(channel_props=red_props, Negatives=False)).T\n","# len(Red_Perc)"],"id":"c09ff596-d11d-43a2-a1e4-66e06b9521e3","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e10f713b-6187-4bd3-9f0b-faea679c7133"},"source":["## `SpikesDF`\n","Spike properties in a DataFrame. This function returns a Pandas data frame with the geometric and spectral properties of the given path to rgb image"],"id":"e10f713b-6187-4bd3-9f0b-faea679c7133"},{"cell_type":"code","metadata":{"id":"f49b58ce-ccea-4f9d-a001-69356ec40b9d"},"source":["%%time\n","def SpikesDF(I, ImagePath, RemoveBG=False, PrintSpkLabels=False, rm_envelope=False):\n","    \n","    # Check if images or path were given\n","    if RemoveBG == True:\n","        # Remove background (path was given)\n","        I = RemoveBackground(ImagePath, OtsuScaling=0.25, rgb_out=True, gray_out=True, lab_out=True, hsv_out=True, bw_out=True)\n","        rgb0 = I[0]\n","        gray0 = I[1]\n","        lab0 = I[2]\n","        hsv0 = I[3]\n","        bw0 = I[4]\n","        \n","        Image_Name = ImagePath.split('\\\\')[-1]\n","\n","    else: \n","        # Images were given in a list as returned by RemoveBackground()\n","        rgb0 = I[0]\n","        gray0 = I[1]\n","        lab0 = I[2]\n","        hsv0 = I[3]\n","        bw0 = I[4]\n","    \n","    \n","    labeled_spks, num_spikes = label(bw0, return_num = True)\n","    props_spikes = regionprops(labeled_spks)\n","    \n","    # Create column with image name\n","    Image_Name = ImagePath.split('\\\\')[-1]\n","    Image_Name = [Image_Name] * num_spikes\n","    \n","    # Geometric properties\n","    Labels = [rp.label for rp in props_spikes]\n","    Areas = [rp.area for rp in props_spikes]\n","    MajorAxes = [rp.major_axis_length for rp in props_spikes]\n","    MinorAxes = [rp.minor_axis_length for rp in props_spikes]\n","    Orientations = [rp.orientation for rp in props_spikes]\n","    Perimeters = [rp.perimeter for rp in props_spikes]\n","    Eccentricities = [rp.eccentricity for rp in props_spikes]\n","   \n","    # Spectral properties\n","    red_props = regionprops(labeled_spks, intensity_image=rgb0[:,:,0])\n","    green_props = regionprops(labeled_spks, intensity_image=rgb0[:,:,1])\n","    blue_props = regionprops(labeled_spks, intensity_image=rgb0[:,:,2])\n","    L_props = regionprops(labeled_spks, intensity_image=lab0[:,:,0])\n","    a_props = regionprops(labeled_spks, intensity_image=lab0[:,:,1])\n","    b_props = regionprops(labeled_spks, intensity_image=lab0[:,:,2])\n","    H_props = regionprops(labeled_spks, intensity_image=hsv0[:,:,0])\n","    S_props = regionprops(labeled_spks, intensity_image=hsv0[:,:,1])\n","    V_props = regionprops(labeled_spks, intensity_image=hsv0[:,:,2])\n","    \n","    red = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in red_props])\n","    green = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in green_props])\n","    blue = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in blue_props])\n","    L = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in L_props])\n","    a = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in a_props])\n","    b = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in b_props])\n","    H = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in H_props])\n","    S = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in S_props])\n","    V = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in V_props])\n","    \n","    Red_Perc = np.array(channel_percentiles(red_props, Negatives=False)).T\n","    Green_Perc = np.array(channel_percentiles(green_props, Negatives=False)).T\n","    Blue_Perc = np.array(channel_percentiles(blue_props, Negatives=False)).T\n","    L_Perc = np.array(channel_percentiles(L_props)).T\n","    a_Perc = np.array(channel_percentiles(a_props, Negatives=True)).T\n","    b_Perc = np.array(channel_percentiles(b_props, Negatives=True)).T\n","    H_Perc = np.array(channel_percentiles(H_props)).T\n","    S_Perc = np.array(channel_percentiles(S_props)).T\n","    V_Perc = np.array(channel_percentiles(V_props)).T\n","\n","    # Dataframe 1: for single obervation per spike\n","    Spikes_per_image = pd.DataFrame(\n","    list(zip(Image_Name, Labels, Areas, MajorAxes, MinorAxes, Orientations, Eccentricities, Perimeters, \n","             red[:,0], red[:,1], red[:,2], green[:,0], green[:,1], green[:,2], blue[:,0], blue[:,1], blue[:,2], \n","             L[:,0], L[:,1], L[:,2], a[:,0], a[:,1], a[:,2], b[:,0], b[:,1], b[:,2], \n","             H[:,0], H[:,1], H[:,2], S[:,0], S[:,1], S[:,2], V[:,0], V[:,1], V[:,2], \n","             Red_Perc[:,0], Red_Perc[:,1], Red_Perc[:,2], Red_Perc[:,3], Red_Perc[:,4], Red_Perc[:,5], Red_Perc[:,6], \n","             Green_Perc[:,0], Green_Perc[:,1], Green_Perc[:,2], Green_Perc[:,3], Green_Perc[:,4], Green_Perc[:,5], Green_Perc[:,6], \n","             Blue_Perc[:,0], Blue_Perc[:,1], Blue_Perc[:,2], Blue_Perc[:,3], Blue_Perc[:,4], Blue_Perc[:,5], Blue_Perc[:,6], \n","             L_Perc[:,0], L_Perc[:,1], L_Perc[:,2], L_Perc[:,3], L_Perc[:,4], L_Perc[:,5], L_Perc[:,6], \n","             a_Perc[:,0], a_Perc[:,1], a_Perc[:,2], a_Perc[:,3], a_Perc[:,4], a_Perc[:,5], a_Perc[:,6], \n","             a_Perc[:,7], a_Perc[:,8], a_Perc[:,9], a_Perc[:,10], a_Perc[:,11], a_Perc[:,12], a_Perc[:,13], \n","             b_Perc[:,0], b_Perc[:,1], b_Perc[:,2], b_Perc[:,3], b_Perc[:,4], b_Perc[:,5], b_Perc[:,6], \n","             b_Perc[:,7], b_Perc[:,8], b_Perc[:,9], b_Perc[:,10], b_Perc[:,11], b_Perc[:,12], b_Perc[:,13],\n","             H_Perc[:,0], H_Perc[:,1], H_Perc[:,2], H_Perc[:,3], H_Perc[:,4], H_Perc[:,5], H_Perc[:,6],\n","             S_Perc[:,0], S_Perc[:,1], S_Perc[:,2], S_Perc[:,3], S_Perc[:,4], S_Perc[:,5], S_Perc[:,6],\n","             V_Perc[:,0], V_Perc[:,1], V_Perc[:,2], V_Perc[:,3], V_Perc[:,4], V_Perc[:,5], V_Perc[:,6])), \n","    columns = ['Image_Name', 'Spike_Label', 'Area', 'MajorAxis', 'MinorAxes', 'Orientation', 'Eccentricity', 'Perimeter', \n","               'Red_mean', 'Red_min', 'Red_max', 'Green_mean', 'Green_min', 'Green_max', 'Blue_mean', 'Blue_min', 'Blue_max', \n","               'L_mean', 'L_min', 'L_max', 'a_mean', 'a_min', 'a_max', 'b_mean', 'b_min', 'b_max',\n","               'H_mean', 'H_min', 'H_max', 'S_mean', 'S_min', 'S_max', 'V_mean', 'V_min', 'V_max', \n","               'Red_p25', 'Red_p50', 'Red_p75', 'Red_Mean', 'Red_sd', 'Red_Min', 'Red_Max', \n","               'Green_p25', 'Green_p50', 'Green_p75', 'Green_Mean', 'Green_sd', 'Green_Min', 'Green_Max', \n","               'Blue_p25', 'Blue_p50', 'Blue_p75', 'Blue_Mean', 'Blue_sd', 'Blue_Min', 'Blue_Max', \n","               'L_p25', 'L_p50', 'L_p75', 'L_Mean', 'L_sd', 'L_Min', 'L_Max', \n","               'a_p25_pos', 'a_p50_pos', 'a_p75_pos', 'a_Mean_pos', 'a_sd_pos', 'a_Min_pos', 'a_Max_pos', \n","               'a_p25_neg', 'a_p50_neg', 'a_p75_neg', 'a_Mean_neg', 'a_sd_neg', 'a_Min_neg', 'a_Max_neg', \n","               'b_p25_pos', 'b_p50_pos', 'b_p75_pos', 'b_Mean_pos', 'b_sd_pos', 'b_Min_pos', 'b_Max_pos', \n","               'b_p25_neg', 'b_p50_neg', 'b_p75_neg', 'b_Mean_neg', 'b_sd_neg', 'b_Min_neg', 'b_Max_neg',\n","               'H_p25', 'H_p50', 'H_p75', 'H_Mean', 'H_sd', 'H_Min', 'H_Max',\n","               'S_p25', 'S_p50', 'S_p75', 'S_Mean', 'S_sd', 'S_Min', 'S_Max',\n","               'V_p25', 'V_p50', 'V_p75', 'V_Mean', 'V_sd', 'V_Min', 'V_Max'])\n","    \n","    Spikes_per_image['Circularity'] = (4 * np.pi * Spikes_per_image['Area']) / (Spikes_per_image['Perimeter'] ** 2)\n","    \n","    # Remove envelope's data  \n","    if rm_envelope==True:\n","        return Spikes_per_image.iloc[1: , :]\n","    else:\n","        return Spikes_per_image\n","\n","\n","# Example:\n","# df = SpikesDF(I, ImagePath=img_name, RemoveBG=False, PrintSpkLabels=False)"],"id":"f49b58ce-ccea-4f9d-a001-69356ec40b9d","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"30cd7829-2f39-45e8-a7bd-ea90186067f2"},"source":["## `SpkltThresh`\n","Threshold for contour detection"],"id":"30cd7829-2f39-45e8-a7bd-ea90186067f2"},{"cell_type":"code","metadata":{"id":"cb463a5f-52c9-472b-8185-492addd4e288"},"source":["%%time\n","\n","def SpkltThresh(cropped, ResizeFactor=30, thr2=0.8, MinSize=1000):   \n","    \n","    # Check that it's a gray image\n","    if len(cropped_rgb.shape) > 2:\n","        # Convert to gray\n","        cropped_gray = color.rgb2gray(cropped)\n","    else:\n","        cropped_gray = cropped\n","        \n","   \n","    # Reduce image size\n","    im = Image.fromarray((cropped_gray*255).astype(np.uint8))\n","    (width, height) = (im.width // ResizeFactor, im.height // ResizeFactor)\n","    rescaled_spk = im.resize((width, height))\n","\n","    # Increase to original size\n","    (width, height) = (im.width, im.height)\n","    rescaled_spk = rescaled_spk.resize((width, height))\n","    rescaled_spk = np.asarray(rescaled_spk)\n","\n","    # Histogram equalization\n","    rescaled_spk = exposure.equalize_hist(rescaled_spk)\n","\n","    # Blur with a Gaussian\n","    blurred = filters.gaussian(rescaled_spk, sigma=1, preserve_range=True)\n","\n","    # Adaptative equalization\n","    blurred = exposure.equalize_adapthist(blurred)\n","\n","    # Normalize\n","    blurred = cv2.normalize(blurred, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n","    blurred = blurred.astype(np.uint8)\n","    \n","    if thr2 < 1 == True:\n","        thr2 = thr2*255\n","    else:\n","        thr2 = thr2\n","    \n","    # Threshold at given %\n","    ret, thresh = cv2.threshold(blurred, thr2, 255, 0)\n","    thresh = np.uint8(thresh)\n","    \n","    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(thresh, connectivity=8)\n","    sizes = stats[1:, -1]; nb_components = nb_components - 1    \n","       \n","    thresh2 = np.zeros((output.shape))\n","    \n","    # Keep only objects with minimum size\n","    for i in range(0, nb_components):\n","        if sizes[i] >= MinSize:\n","            thresh2[output == i + 1] = 255\n","    \n","#     plt.imshow(thresh2)\n","    thresh2 = np.uint8(thresh2)\n","    \n","    return thresh2\n","\n","# Example:\n","# thresh2 = SpkltThresh(cropped=cropped_rgb, ResizeFactor=30, thr2=0.8, MinSize=1000)\n","# plt.imshow(thresh2)\n"],"id":"cb463a5f-52c9-472b-8185-492addd4e288","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e7df58c1-e220-4765-acae-ff315b2d4b68"},"source":["## `LabelContours`\n","Spike's contours"],"id":"e7df58c1-e220-4765-acae-ff315b2d4b68"},{"cell_type":"code","metadata":{"id":"78fd7192-e9d5-41ba-8313-f2d1b0ff98da"},"source":["%%time\n","\n","# Spike's contours\n","def LabelContours(cropped_rgb, thresh2, ResizeFactor=30, MinSize = 1000, plot=True, thr2=0.8):\n","    \n","    # Copy iamge\n","    OutImage = cropped_rgb.copy()\n","    \n","    if thresh2 is not None:\n","        thresh2 = thresh2\n","    else:\n","        # Threshold for contours\n","        thresh2 = SpkltThresh(cropped=OutImage, ResizeFactor=ResizeFactor, thr2=thr2, MinSize=MinSize)\n","\n","#     # Threshold for contours\n","#     thresh2 = SpkltThresh(cropped=cropped_rgb, ResizeFactor=30, thr2=thr2, MinSize=MinSize)\n","#     plt.imshow(bw_cont)\n","    \n","    # Enumerate objects\n","    # EnumerateSpkCV(thresh2, OutImage, TextSize=5, TROE2020=False)\n","    \n","#     contours = measure.find_contours(blurred,(0.8*255))\n","    contours, hierarchy = cv2.findContours(thresh2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","#     len(contours)\n","    \n","    # Detected spikelets\n","    print(\"Detected spikeletes: \", len(contours))\n","    \n","    if plot==True:\n","        img = OutImage.copy()\n","        # Plot all found contours\n","        plot_contours = cv2.drawContours(img, contours, -1, (0,255,0), 10)\n","        plt.imshow(plot_contours)\n","    \n","    return contours\n","\n","# Example:\n","# labels_cont = LabelContours(cropped_rgb, thresh2=thresh2, ResizeFactor=30, MinSize = 1000, thr2=0.8, plot=True)\n","# len(labels_cont)"],"id":"78fd7192-e9d5-41ba-8313-f2d1b0ff98da","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ebd54177-543b-446d-a80f-cec749c2580c"},"source":["## `ObjProps`\n","Object properties. A general function to get properties of labels ROIs."],"id":"ebd54177-543b-446d-a80f-cec749c2580c"},{"cell_type":"code","metadata":{"id":"040f9e71-535d-4b43-9c02-330b786238df"},"source":["%%time\n","\n","def ObjProps(labeled, cropped_rgb, cropped_lab, cropped_hsv, ImagePath, MinSize = 1000, rm_envelope=False):\n","    \n","    # Label + regionprops\n","    labeled_contours, num_contours = label(labeled, return_num = True)\n","    props_contours = regionprops(labeled_contours)\n","#     plt.imshow(labeled_contours)\n","\n","    # # Create column with image name\n","    Image_Name = ImagePath.split('\\\\')[-1]\n","    Image_Name = [Image_Name] * num_contours\n","\n","    # Geometric properties\n","    Labels = [rp.label for rp in props_contours]\n","    Areas = [rp.area for rp in props_contours]\n","    MajorAxes = [rp.major_axis_length for rp in props_contours]\n","    MinorAxes = [rp.minor_axis_length for rp in props_contours]\n","    Orientations = [rp.orientation for rp in props_contours]\n","    Perimeters = [rp.perimeter for rp in props_contours]\n","    Eccentricities = [rp.eccentricity for rp in props_contours]\n","\n","    # Spectral properties\n","    red_props = regionprops(labeled_contours, intensity_image=cropped_rgb[:,:,0])\n","    green_props = regionprops(labeled_contours, intensity_image=cropped_rgb[:,:,1])\n","    blue_props = regionprops(labeled_contours, intensity_image=cropped_rgb[:,:,2])\n","    L_props = regionprops(labeled_contours, intensity_image=cropped_lab[:,:,0])\n","    a_props = regionprops(labeled_contours, intensity_image=cropped_lab[:,:,1])\n","    b_props = regionprops(labeled_contours, intensity_image=cropped_lab[:,:,2])\n","    H_props = regionprops(labeled_spks, intensity_image=cropped_hsv[:,:,0])\n","    S_props = regionprops(labeled_spks, intensity_image=cropped_hsv[:,:,1])\n","    V_props = regionprops(labeled_spks, intensity_image=cropped_hsv[:,:,2])\n","    \n","    red = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in red_props])\n","    green = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in green_props])\n","    blue = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in blue_props])\n","    L = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in L_props])\n","    a = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in a_props])\n","    b = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in b_props])\n","    H = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in H_props])\n","    S = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in S_props])\n","    V = np.array([[rp.mean_intensity,rp.min_intensity,rp.max_intensity] for rp in V_props])\n","    \n","    Red_Perc = np.array(channel_percentiles(red_props, Negatives=False)).T\n","    Green_Perc = np.array(channel_percentiles(green_props, Negatives=False)).T\n","    Blue_Perc = np.array(channel_percentiles(blue_props, Negatives=False)).T\n","    L_Perc = np.array(channel_percentiles(L_props)).T\n","    a_Perc = np.array(channel_percentiles(a_props, Negatives=True)).T\n","    b_Perc = np.array(channel_percentiles(b_props, Negatives=True)).T\n","    H_Perc = np.array(channel_percentiles(H_props)).T\n","    S_Perc = np.array(channel_percentiles(S_props)).T\n","    V_Perc = np.array(channel_percentiles(V_props)).T\n","\n","    # Dataframe 1: for single obervation per spike\n","    Spikes_per_image = pd.DataFrame(\n","    list(zip(Image_Name, Labels, Areas, MajorAxes, MinorAxes, Orientations, Eccentricities, Perimeters, \n","             red[:,0], red[:,1], red[:,2], green[:,0], green[:,1], green[:,2], blue[:,0], blue[:,1], blue[:,2], \n","             L[:,0], L[:,1], L[:,2], a[:,0], a[:,1], a[:,2], b[:,0], b[:,1], b[:,2], \n","             H[:,0], H[:,1], H[:,2], S[:,0], S[:,1], S[:,2], V[:,0], V[:,1], V[:,2], \n","             Red_Perc[:,0], Red_Perc[:,1], Red_Perc[:,2], Red_Perc[:,3], Red_Perc[:,4], Red_Perc[:,5], Red_Perc[:,6], \n","             Green_Perc[:,0], Green_Perc[:,1], Green_Perc[:,2], Green_Perc[:,3], Green_Perc[:,4], Green_Perc[:,5], Green_Perc[:,6], \n","             Blue_Perc[:,0], Blue_Perc[:,1], Blue_Perc[:,2], Blue_Perc[:,3], Blue_Perc[:,4], Blue_Perc[:,5], Blue_Perc[:,6], \n","             L_Perc[:,0], L_Perc[:,1], L_Perc[:,2], L_Perc[:,3], L_Perc[:,4], L_Perc[:,5], L_Perc[:,6], \n","             a_Perc[:,0], a_Perc[:,1], a_Perc[:,2], a_Perc[:,3], a_Perc[:,4], a_Perc[:,5], a_Perc[:,6], \n","             a_Perc[:,7], a_Perc[:,8], a_Perc[:,9], a_Perc[:,10], a_Perc[:,11], a_Perc[:,12], a_Perc[:,13], \n","             b_Perc[:,0], b_Perc[:,1], b_Perc[:,2], b_Perc[:,3], b_Perc[:,4], b_Perc[:,5], b_Perc[:,6], \n","             b_Perc[:,7], b_Perc[:,8], b_Perc[:,9], b_Perc[:,10], b_Perc[:,11], b_Perc[:,12], b_Perc[:,13],\n","             H_Perc[:,0], H_Perc[:,1], H_Perc[:,2], H_Perc[:,3], H_Perc[:,4], H_Perc[:,5], H_Perc[:,6],\n","             S_Perc[:,0], S_Perc[:,1], S_Perc[:,2], S_Perc[:,3], S_Perc[:,4], S_Perc[:,5], S_Perc[:,6],\n","             V_Perc[:,0], V_Perc[:,1], V_Perc[:,2], V_Perc[:,3], V_Perc[:,4], V_Perc[:,5], V_Perc[:,6])), \n","    columns = ['Image_Name', 'Spike_Label', 'Area', 'MajorAxis', 'MinorAxes', 'Orientation', 'Eccentricity', 'Perimeter', \n","               'Red_mean', 'Red_min', 'Red_max', 'Green_mean', 'Green_min', 'Green_max', 'Blue_mean', 'Blue_min', 'Blue_max', \n","               'L_mean', 'L_min', 'L_max', 'a_mean', 'a_min', 'a_max', 'b_mean', 'b_min', 'b_max',\n","               'H_mean', 'H_min', 'H_max', 'S_mean', 'S_min', 'S_max', 'V_mean', 'V_min', 'V_max', \n","               'Red_p25', 'Red_p50', 'Red_p75', 'Red_Mean', 'Red_sd', 'Red_Min', 'Red_Max', \n","               'Green_p25', 'Green_p50', 'Green_p75', 'Green_Mean', 'Green_sd', 'Green_Min', 'Green_Max', \n","               'Blue_p25', 'Blue_p50', 'Blue_p75', 'Blue_Mean', 'Blue_sd', 'Blue_Min', 'Blue_Max', \n","               'L_p25', 'L_p50', 'L_p75', 'L_Mean', 'L_sd', 'L_Min', 'L_Max', \n","               'a_p25_pos', 'a_p50_pos', 'a_p75_pos', 'a_Mean_pos', 'a_sd_pos', 'a_Min_pos', 'a_Max_pos', \n","               'a_p25_neg', 'a_p50_neg', 'a_p75_neg', 'a_Mean_neg', 'a_sd_neg', 'a_Min_neg', 'a_Max_neg', \n","               'b_p25_pos', 'b_p50_pos', 'b_p75_pos', 'b_Mean_pos', 'b_sd_pos', 'b_Min_pos', 'b_Max_pos', \n","               'b_p25_neg', 'b_p50_neg', 'b_p75_neg', 'b_Mean_neg', 'b_sd_neg', 'b_Min_neg', 'b_Max_neg',\n","               'H_p25', 'H_p50', 'H_p75', 'H_Mean', 'H_sd', 'H_Min', 'H_Max',\n","               'S_p25', 'S_p50', 'S_p75', 'S_Mean', 'S_sd', 'S_Min', 'S_Max',\n","               'V_p25', 'V_p50', 'V_p75', 'V_Mean', 'V_sd', 'V_Min', 'V_Max'])\n","\n","    Objects_per_image['Circularity'] = (4 * np.pi * Objects_per_image['Area']) / (Objects_per_image['Perimeter'] ** 2)\n","\n","    \n","    # Unique labels\n","    labels2 = np.unique(labeled[labeled > 0])\n","\n","    # Empty list for contours\n","    C = []\n","\n","    # Loop thorugh labels and add to list of contours\n","    for label2 in labels2:\n","            y = labeled==label2\n","            y = y * 255\n","            y = y.astype('uint8')\n","            contours, hierarchy = cv2.findContours(y, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","            # len(contours)\n","            contours = np.squeeze(contours)\n","            C.append(contours)\n","        \n","    # List for angles\n","    Slopes = []\n","    \n","    contours = C    \n","\n","    for c in contours:\n","\n","        ellipse = cv2.fitEllipse(c)\n","\n","        # Fit a line \n","        rows,cols = cropped_rgb.shape[:2]\n","        [vx,vy,x,y] = cv2.fitLine(c, cv2.DIST_L2,0,0.01,0.01);\n","        lefty = int((-x*vy/vx) + y)\n","        righty = int(((cols-x)*vy/vx)+y)\n","\n","        rise = (0,lefty)[1] - (cols-1,righty)[1]\n","        run = cols\n","        Slope = rise/run\n","        Slopes.append(Slope)\n","    \n","    # Add slopes to data frame\n","    Objects_per_image['Spklt_Angle'] = Slopes\n","    \n","    \n","    \n","    \n","    \n","    \n","    # Filter by area\n","    Objects_per_image2 = Objects_per_image[Objects_per_image['Area'] > MinSize]\n","    \n","    # Remove first row, corresponding to spikes' envelope\n","    if rm_envelope==True:\n","        return Objects_per_image2.iloc[1: , :]\n","    else:\n","        return Objects_per_image2\n","\n","\n","# plt.imshow(spklts)\n","# Example\n","# Props = ObjProps(spklts, cropped_rgb, cropped_lab, ImagePath=img_name, MinSize = 5000)\n","# Props = ObjProps(labeled=thresh2, cropped_rgb=cropped_rgb, cropped_lab=cropped_lab, ImagePath=img_name, MinSize = 1000)"],"id":"040f9e71-535d-4b43-9c02-330b786238df","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"id":"724d650d-67fa-4bce-b3b8-422d06da1e6a"},"source":["## `EnhanceImage`"],"id":"724d650d-67fa-4bce-b3b8-422d06da1e6a"},{"cell_type":"code","metadata":{"id":"e6b7f9d9-d4d3-4bb6-9e00-5d6b3b5faca9"},"source":["%%time\n","def EnhanceImage(InputImage, Color = None, Contrast = None, Sharp = None):\n","    \n","    # Read image\n","    if isinstance(InputImage, str) == True:\n","        img = iio.imread(InputImage)\n","    else: \n","        img = InputImage\n","    \n","    # RGB enhancement\n","    img0 = Image.fromarray(img)\n","    \n","    # Color seems to be good around 3.5\n","    img1 = ImageEnhance.Color(img0)\n","    if Color is not None:\n","        img1 = img1.enhance(Color)\n","    else:\n","        img1 = img0\n","    \n","    # Contrast\n","    img2 = ImageEnhance.Contrast(img1)\n","    if Contrast is not None:\n","        img2 = img2.enhance(Contrast)\n","    else:\n","        img2 = img1\n","    \n","    # Sharpness (Good ~20 or higher)\n","    img3 = ImageEnhance.Sharpness(img2)    \n","    if Sharp is not None:\n","        img3 = img3.enhance(Sharp)\n","    else:\n","        img3 = img2\n","    \n","    # Final image\n","    img3 = np.array(img3)\n","    \n","    return img3\n","\n","# Example\n","# enh0 = EnhanceImage(InputImage=cropped_rgb, Color = 3, Contrast = None, Sharp = 10)\n","# plt.imshow(enh0)"],"id":"e6b7f9d9-d4d3-4bb6-9e00-5d6b3b5faca9","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fd6a830a-5be7-43fd-a4a4-4c4140fd4e8c"},"source":["## `LabelSpklts`\n","This fuction uses the Watershed algorithm to detect spikelets"],"id":"fd6a830a-5be7-43fd-a4a4-4c4140fd4e8c"},{"cell_type":"code","metadata":{"id":"fb1c4b6d-a4c9-4dcd-92e4-4f51eda2ae70"},"source":["%%time\n","\n","def LabelSpklts(cropped_rgb, MinDist=50, labels_out=True, n_spklt=True, ElliPlot=False, Plot=True):\n","    \n","    # Rescale to 10% of original\n","    rescaled_spk = rescale(cropped_rgb[...], 0.1, preserve_range=False, multichannel=True, anti_aliasing=True)\n","    # plt.imshow(rescaled_spk)\n","\n","    # Erosion\n","    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n","    erosion = cv2.erode(rescaled_spk,kernel,iterations = 1)\n","    # plt.imshow(erosion)\n","\n","    # Opening\n","    kernel = np.ones((1,1),np.uint8)\n","    opening = cv2.morphologyEx(erosion, cv2.MORPH_OPEN, kernel, iterations = 10)\n","    # plt.imshow(opening)\n","\n","    # Resize\n","    rescaled_spk2 = Image.fromarray((rescaled_spk * 255).astype(np.uint8))\n","    rescaled_spk2 = rescaled_spk2.resize((cropped_rgb.shape[1],cropped_rgb.shape[0]))\n","    # plt.imshow(rescaled_spk2)\n","    # rescaled_spk2.size\n","    opening = np.asarray(rescaled_spk2)\n","    # plt.imshow(opening)\n","\n","    # Convert rgb to gray\n","    gray_spklts = opening @ [0.2126, 0.7152, 0.0722]\n","    # plt.imshow(gray_spklts)\n","\n","    # Binarize gray\n","    bw_spklts = gray_spklts > 0\n","    # plt.imshow(bw_spklts)\n","\n","    # Get distances\n","    distance = ndi.distance_transform_edt(bw_spklts)\n","    # plt.imshow(-distance)\n","\n","    # Get max peaks\n","    coords = peak_local_max(distance, min_distance=MinDist, labels=bw_spklts)\n","    # plt.imshow(coords)\n","\n","    mask = np.zeros(distance.shape, dtype=bool)\n","    mask[tuple(coords.T)] = True\n","    markers, spikelets = ndi.label(mask)\n","    \n","    # Watershed\n","    labels = watershed(-distance, markers, mask=cropped_spk)\n","#     plt.imshow(labels)\n","\n","    labels2 = np.unique(labels[labels > 0])\n","\n","    C = []\n","\n","    for label in labels2:\n","            y = label_image == label\n","            y = y * 255\n","            y = y.astype('uint8')\n","            contours, hierarchy = cv2.findContours(y, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","            # len(contours)\n","            contours = np.squeeze(contours)\n","            C.append(contours)\n","\n","#         plt.imshow(d[2])\n","    \n","    contours = C\n","\n","    if ElliPlot==True and Plot==False:\n","        \n","        OutImage = cropped_rgb.copy()\n","\n","        # Plot all found contours\n","        OutImage = cv2.drawContours(OutImage, contours, -1, (0,0,0), 10);\n","        # plt.imshow(OutImage)\n","\n","        for c in contours:\n","            # Generate random colors\n","            random_channels = (np.random.choice(range(256), size=3))\n","            rr = int(random_channels[0])\n","            rg = int(random_channels[1])\n","            rb = int(random_channels[2])\n","            \n","            ellipse = cv2.fitEllipse(c)\n","            OutImage = cv2.ellipse(OutImage,ellipse,(rr,rg,rb),10);\n","\n","            # Fit a line \n","            rows,cols = OutImage.shape[:2]\n","            [vx,vy,x,y] = cv2.fitLine(c, cv2.DIST_L2,0,0.01,0.01);\n","            lefty = int((-x*vy/vx) + y)\n","            righty = int(((cols-x)*vy/vx)+y)\n","            # OutImage = cv2.line(OutImage,(cols-1,righty),(0,lefty),(rr,rg,rb),3);\n","            \n","            # Slope from tope left, which is is the origin [0,0]\n","            rise = (0,lefty)[1] - (cols-1,righty)[1]\n","            run = cols\n","            Slope = rise/run\n","            Slopes.append(Slope)            \n","        \n","        # Plot\n","        plt.imshow(OutImage)\n","\n","    # Add slopes to data frame\n","    # Props['Spklt_Angle'] = Slopes\n","\n","    if Plot==True and ElliPlot==False:  \n","        # Plot\n","        plt.imshow(labels, cmap=plt.cm.nipy_spectral)\n","        \n","        # Print number of spikelets detected\n","        print('Detected spikelets = ', spikelets)\n","    \n","    # Return labels\n","    if labels_out==True and n_spklt==True:\n","        return labels, spikelets\n","\n","# Example:\n","# spklts, n_spklts= LabelSpklts(cropped_rgb, MinDist=50, labels_out=True, n_spklt=True, ElliPlot=True, Plot=False)\n","# plt.imshow(spklts==2)\n","\n"],"id":"fb1c4b6d-a4c9-4dcd-92e4-4f51eda2ae70","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d6177f67-c472-4fc1-a86c-9dc0292018a1"},"source":["## `CountorProps`\n","Contour properties"],"id":"d6177f67-c472-4fc1-a86c-9dc0292018a1"},{"cell_type":"code","metadata":{"id":"6a1e1719-4fd9-4c4e-97de-ef956ed170e5"},"source":["%%time\n","def CountorProps(cropped_rgb, thresh2, ImagePath, ResizeFactor=30, MinSize = 1000, thr2=0.8, plot=True, rm_envelope=False):\n","    \n","#     labels_cont = SpkContours(cropped_rgb, ResizeFactor=30, MinSize = 1000, thr2=0.8, plot=True)\n","    \n","    # Copy image\n","    OutImage = cropped_rgb.copy()\n","    # Get lab\n","    OutImageLab = color.rgb2lab(cropped_lab)\n","    \n","    if thresh2 is not None:\n","        thresh2 = thresh2\n","    else:\n","        # Threshold for contours\n","        thresh2 = SpkltThresh(cropped=OutImage, ResizeFactor=ResizeFactor, thr2=thr2, MinSize=MinSize)\n","\n","    #     plt.imshow(thresh2)\n","    \n","    # Enumerate objects\n","#     EnumerateSpkCV(thresh2, OutImage, TextSize=3, TROE2020=False)\n","    \n","#     contours = measure.find_contours(blurred,(0.8*255))\n","    contours, hierarchy = cv2.findContours(thresh2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","#     len(contours)\n","    # np.array(contours).shape\n","    # Contour properties\n","    Props = ObjProps(labeled=thresh2, cropped_rgb=cropped_rgb, cropped_lab=cropped_lab, ImagePath=ImagePath, rm_envelope=False)\n","    \n","    # Detected spikelets\n","    print(\"Fitted contours: \", len(contours))\n","    \n","    # Create list for slopes\n","    Slopes = []\n","#     len(Slopes)\n","\n","    if plot==True:\n","\n","        # Plot all found contours\n","        OutImage = cv2.drawContours(OutImage, contours, -1, (255,255,255), 10);\n","\n","        for c in contours:\n","            # Generate random colors\n","            random_channels = (np.random.choice(range(256), size=3))\n","            rr = int(random_channels[0])\n","            rg = int(random_channels[1])\n","            rb = int(random_channels[2])\n","            \n","            ellipse = cv2.fitEllipse(c)\n","            OutImage = cv2.ellipse(OutImage,ellipse,(rr,rg,rb),10);\n","\n","            # Fit a line \n","            rows,cols = OutImage.shape[:2]\n","            [vx,vy,x,y] = cv2.fitLine(c, cv2.DIST_L2,0,0.01,0.01);\n","            lefty = int((-x*vy/vx) + y)\n","            righty = int(((cols-x)*vy/vx)+y)\n","            OutImage = cv2.line(OutImage,(cols-1,righty),(0,lefty),(rr,rg,rb),3);\n","            \n","            # Slope from tope left, which is is the origin [0,0]\n","            rise = (0,lefty)[1] - (cols-1,righty)[1]\n","            run = cols\n","            Slope = rise/run\n","            Slopes.append(Slope)            \n","        \n","        # Plot\n","        plt.imshow(OutImage)\n","        \n","    else:\n","        \n","        for c in contours:\n","            \n","            ellipse = cv2.fitEllipse(c)\n","            \n","            # Fit a line \n","            rows,cols = OutImage.shape[:2]\n","            [vx,vy,x,y] = cv2.fitLine(c, cv2.DIST_L2,0,0.01,0.01);\n","            lefty = int((-x*vy/vx) + y)\n","            righty = int(((cols-x)*vy/vx)+y)\n","\n","            rise = (0,lefty)[1] - (cols-1,righty)[1]\n","            run = cols\n","            Slope = rise/run\n","            Slopes.append(Slope)\n","    \n","    # Add slopes to data frame\n","    Props['Spklt_Angle'] = Slopes\n","    \n","    # Remove first row, corresponding to spikes' envelope\n","    if rm_envelope==True:\n","        return Props.iloc[1: , :]\n","    else:\n","        return Props\n","\n","\n","\n","# Example:\n","# labels_cont = CountorProps(cropped_rgb, thresh2, ImagePath=img_name, ResizeFactor=30, MinSize = 1000, thr2=0.8, plot=True)"],"id":"6a1e1719-4fd9-4c4e-97de-ef956ed170e5","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d9620a52-3730-45ae-a9fd-ed068092be9b"},"source":["## `Heatmat`\n","Heatmaps from a 1d matrix. This is just for fun, at least for now. The idea is to create a matrix $A_{mxm}$ from a vector (or 1d matrix) $a_{m x 1}$, to plot $A$ under changing circumnstances, such as multiplying by increasing scalar, exponentiation, etc. This results in multiple frames that can then used to make a GIF."],"id":"d9620a52-3730-45ae-a9fd-ed068092be9b"},{"cell_type":"code","metadata":{"id":"73f5024d-7efd-4770-bd48-fb2bc6a83d42"},"source":["%%time\n","\n","def Heatmat(a, frames=30):\n","    a = np.array(a)\n","    a = a.reshape(len(a), 1)\n","    aT = a.T\n","    mat = np.multiply(a, aT)\n","#     mata.shape\n","\n","    for frame in range(frames):\n","        if frame < 10:\n","            name = \"./GIFS/img_0\"+str(frame)+\".png\"\n","        elif frame < 100:\n","            name = \"./GIFS/img_00\"+str(frame)+\".png\"\n","        else:\n","            name = \"./GIFS/img_\"+str(frame)+\".png\"\n","        \n","        new_mat = np.log10( 1+(mat**(frame) ) )\n","        sns.heatmap(new_mat)\n","        plt.savefig(name)\n","        plt.close()\n","\n","# Example:\n","# Heatmat(a=Areas, frames=30)"],"id":"73f5024d-7efd-4770-bd48-fb2bc6a83d42","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b61f76f6-4791-4127-9fd1-492028f85e7c"},"source":["## `makeGIF`\n","Create a GIF from images generated by `heatmat`"],"id":"b61f76f6-4791-4127-9fd1-492028f85e7c"},{"cell_type":"code","metadata":{"id":"3ed26f92-b88f-468e-b7a0-818fc2a84f5d"},"source":["%%time\n","\n","def makeGIF(filenames, duration = 0.25, out_name=None):\n","    images = []\n","    for filename in filenames:\n","        images.append(imageio.imread(filename))\n","    imageio.mimsave('./GIFS/GIF.gif', images, duration=duration)\n","\n","\n","# Example:\n","# filenames = glob.glob(\"./GIFS/\" + '*.png', recursive=False)\n","# makeGIF(filenames, duration = 0.25, out_name=None)"],"id":"3ed26f92-b88f-468e-b7a0-818fc2a84f5d","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3b9043ab-c187-4578-808c-ef2d621c7cc1"},"source":["## `DistAll`\n","Distances among objects. This calculates the Euclidean distances (using the Pythagorean theorem) between all labeled ROIs given a binary image. If `spike_length` is given, the distances are returned as the proportion from the spike (%)."],"id":"3b9043ab-c187-4578-808c-ef2d621c7cc1"},{"cell_type":"code","metadata":{"id":"f5d10901-28ec-46d4-aa40-32d1b789541c"},"source":["%%time\n","\n","def DistAll(bw, HeatMap=True, spike_length=None):\n","    \n","    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(bw), \n","                                                                               connectivity=8)\n","    # len(centroids[1:][:])\n","    img_center = centroids[0][:]\n","    c_points = centroids[1:][:]\n","    c_df = pd.DataFrame(c_points, columns=[\"x\",\"y\"])\n","    # c_df\n","\n","    # https://stackoverflow.com/questions/57107729/how-to-compute-multiple-euclidean-distances-of-all-points-in-a-dataset\n","\n","    # Consider points as tuples in a list\n","    data = [ (float(x),float(y)) for x,y in c_df[['x', 'y']].values ]\n","\n","    # Create empty list for distances\n","    distances = []\n","\n","    for point in data:\n","\n","        # Compute the Euclidean distance between the current point and all others\n","        euc_dist = [math.sqrt((point[0]-x[0] )**2 + (point[1]-x[1])**2) for x in data]\n","\n","        # Append to list\n","        distances.append(euc_dist)\n","\n","    # Convert list to array\n","    D = np.array(distances)\n","    \n","    if spike_length != None:\n","        # Express it as a fraction from spike length\n","        D = D/spike_length\n","    else:\n","        D = D\n","    \n","    # Heatmap\n","    if HeatMap==True:\n","        sns.heatmap(D)\n","    \n","    return D\n","\n","# Example:\n","# D = DistAll(bw=thresh2, HeatMap=True, spike_length=SL)\n","# D = DistAll(bw=spklts, HeatMap=True, spike_length=SL)"],"id":"f5d10901-28ec-46d4-aa40-32d1b789541c","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b05245c3-11ed-4f96-b4a5-5018e5ef02fd"},"source":["## `imgraph` Graph analysis (under contruction...)\n","Axes: `0` for $x$, `1` for $y$"],"id":"b05245c3-11ed-4f96-b4a5-5018e5ef02fd"},{"cell_type":"code","metadata":{"id":"d9fcd8cb-59b0-4458-a2b1-b355a03789fe"},"source":["# https://stackoverflow.com/questions/54832694/how-to-represent-a-binary-image-as-a-graph-with-the-axis-being-height-and-width\n","\n","def imgraph(image, axis=0):\n","    # image = blurred\n","    # Theshold image if desired (only 2d images)\n","    maxindex = np.argmax(image[:,:], axis=axis)\n","\n","    # Plot graph\n","    plt.plot(image.shape[axis] - maxindex)\n","    plt.show()"],"id":"d9fcd8cb-59b0-4458-a2b1-b355a03789fe","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b9f85596-9be7-4923-8803-0a73d67de50b"},"source":["## `ComparePlots`\n","Compare multiple plots. Plots need to be gathered in a list."],"id":"b9f85596-9be7-4923-8803-0a73d67de50b"},{"cell_type":"code","metadata":{"id":"54d1794c-29b7-4aee-8d74-c9d498ff89fe"},"source":["%%time\n","\n","def ComparePlots(rows, cols, ListImages, fontsize=10):\n","    plots = rows * cols\n","    fig, axes = plt.subplots(rows, cols, sharex=True, sharey=True)\n","    ax = axes.ravel()\n","    for i in range(plots):\n","        ax[i].imshow(ListImages[i], cmap='gray')\n","        Title = \"Image \" + str(i)\n","        ax[i].set_title(Title, fontsize=fontsize)\n","    fig.tight_layout()\n","    plt.show()\n","    \n","# Example:\n","# ComparePlots(3,1,[cropped_rgb, cropped_lab, cropped_hsv])"],"id":"54d1794c-29b7-4aee-8d74-c9d498ff89fe","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"12f7b153-0507-4108-99c0-05de23b13b93"},"source":["## `SeparateSpikes`\n","Split spikes into images. This function returns as many individual images as labeled in the mask."],"id":"12f7b153-0507-4108-99c0-05de23b13b93"},{"cell_type":"code","metadata":{"id":"82175ae1-dc21-48ef-9d7b-98ee4a702ae5"},"source":["%%time\n","\n","def SeparateSpikes(ImagePath, Outfile = None):\n","    \n","    # Remove bakground\n","    I = RemoveBackground(ImagePath, OtsuScaling=0.25, rgb_out=True, gray_out=True, lab_out=False, hsv_out=False, bw_out=True)\n","    rgb0 = I[0]\n","#     # Convert to gray\n","#     gray0 = img0 @ [0.2126, 0.7152, 0.0722]\n","# #     gray0 = img0 @ [0.2126, 0.7152, 0.0722]\n","\n","#     # Threshold\n","#     otsu = filters.threshold_otsu(gray0)\n","#     bw0 = gray0 > otsu\n","#     bw1 = morphology.remove_small_objects(bw0, min_size=1.5e-05 * gray0.shape[0] * gray0.shape[1])\n","    bw0 = I[1]\n","#     plt.imshow(bw1)\n","    # Label spikes\n","    labeled_spks, num_spikes = label(bw0>0, return_num = True)\n","    \n","    # Loop through spikes\n","    for spk in range(1,num_spikes):\n","        \n","        # Select current spike\n","        myspk = labeled_spks == spk\n","\n","        # Crop spike\n","        slice_x, slice_y = ndimage.find_objects(myspk)[0]\n","        cropped_spk = myspk[slice_x, slice_y]\n","        cropped_rgb = rgb0[slice_x, slice_y]\n","        cropped_rgb = np.where(cropped_spk[..., None], cropped_rgb, 0)\n","        \n","        # Add 10 pixels to each border\n","        padded = np.pad(cropped_rgb, pad_width=[(10, 10),(10, 10),(0, 0)], mode='constant')\n","        \n","        # Save image \n","        im = Image.fromarray(padded)\n","        \n","        if Outfile == None:\n","            \n","            Split_Path = ImagePath.split(\"\\\\\")\n","            OutName = Split_Path[-1].replace(\".tif\", \"\")\n","            Split_Path = Split_Path[:-1]\n","            OutDir = '\\\\'.join([str(i) for i in Split_Path])\n","            OutDir = OutDir + \"\\\\IndividualSpikes\\\\\"\n","            path = pathlib.Path(OutDir)\n","            path.mkdir(parents=True, exist_ok=True)\n","            \n","            if spk < 10:\n","                OutName = OutDir + OutName + \"_spk0\" + str(spk) + '.jpg'\n","            else: \n","                OutName = OutDir + OutName + \"_spk\" + str(spk) + '.jpg'\n","        \n","        im.save(OutName)\n","        print(\"Saved image as: \" + OutName)\n","\n","# Example:\n","# SeparateSpikes(ImagePath=img_name)"],"id":"82175ae1-dc21-48ef-9d7b-98ee4a702ae5","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"82577f0b-3a2b-4fcd-83be-0a755b5ee374"},"source":["# BATCH EXECUTION"],"id":"82577f0b-3a2b-4fcd-83be-0a755b5ee374"},{"cell_type":"code","metadata":{"id":"fcea48e9-518c-4e26-8a6a-44edd6706da6"},"source":[""],"id":"fcea48e9-518c-4e26-8a6a-44edd6706da6","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"06931969-c2f2-439f-86a9-530dba417bf4","outputId":"b79d5f3e-2c14-4d5a-8541-50638b7ca38d"},"source":["%%time\n","\n","from SpykFunctions import *\n","\n","path = r'./Images/TEST'\n","Images = ListImages(path, imgformat=\".tif\", recursive=False)\n","TROE2020=False\n","\n","Spikes_data = pd.DataFrame()\n","Contours_data = pd.DataFrame()\n","Spklts_data = pd.DataFrame()\n","Distances_data = pd.DataFrame()\n","Lengths_data = pd.DataFrame()\n","\n","for img_name in Images:\n","    # img_name=Images[0]\n","    print(\"Processing image \", img_name)\n","    \n","    # Remove background and create images\n","    I = RemoveBackground(img_name, OtsuScaling=0.25, rgb_out=True, gray_out=True, lab_out=True, hsv_out=True, bw_out=True)\n","    rgb0 = I[0]\n","    gray0 = I[1]\n","    lab0 = I[2]\n","    hsv0 = I[3]\n","    bw0 = I[4]\n","    \n","    # Enumerate spikes\n","#     EnumerateSpkCV(bw0, rgb0, TextSize=5, TROE2020=False)\n","    \n","    # Collect spikes data\n","    df = SpikesDF(I=I, ImagePath=img_name, RemoveBG=False)\n","    # Append to data set       \n","    Spikes_data = Spikes_data.append(df)\n","\n","    # Label spikes\n","    labeled_spks, num_spikes = label(bw0, return_num = True)\n","    # plt.imshow(labeled_spks==2)\n","                  \n","    # Spike lengths\n","    SpkLengths = []\n","    \n","    # Spike distances from each other\n","    SpkDists = []\n","\n","    # TROE2021 and PGR start at 2. Ignore background (0) and envelope (1)\n","    if TROE2020==False:\n","        FirstSpk = 1\n","    else:\n","        FirstSpk = 2\n","        \n","    # Start at 2 so it ignores background (0) and envelope (1)\n","    for Label in range(FirstSpk, num_spikes+1):\n","    \n","        print(\"Processing spike \", Label)\n","#         plt.imshow(labeled_spks==2)\n","        \n","        spk = labeled_spks==Label\n","        # plt.imshow(spk)\n","    \n","        # Crop spike\n","        slice_x, slice_y = ndimage.find_objects(spk)[0]\n","        cropped_spk = spk[slice_x, slice_y]\n","        cropped_rgb = rgb0[slice_x, slice_y]\n","        cropped_rgb = np.where(cropped_spk[..., None], cropped_rgb, 0)\n","        cropped_gray = color.rgb2gray(cropped_rgb)\n","        cropped_lab = color.rgb2lab(cropped_rgb)\n","        cropped_hsv = color.rgb2hsv(cropped_rgb)\n","#         plt.imshow(cropped_spk)\n","\n","        # Spike length\n","        sl = spk_length(cropped_spk, method='skelblur', Overlay=False, PlotCH=False)\n","        SpkLengths.append(sl)\n","\n","        # Theshold for detection\n","        thresh2 = SpkltThresh(cropped_rgb, ResizeFactor=30, thr2=0.8, MinSize=1000)\n","\n","        # Distances between contours\n","        D = DistAll(bw=thresh2, HeatMap=False, spike_length=sl)\n","        SpkDists.append(D)\n","\n","        # Contours\n","        labels_cont = CountorProps(cropped_rgb, cropped_lab, cropped_hsv, thresh2, ImagePath=img_name, ResizeFactor=30, MinSize = 1000, thr2=0.8, plot=False)\n","\n","        # Watershed segments\n","        spklts, n_spklts= LabelSpklts(cropped_rgb, MinDist=50, labels_out=True, n_spklt=True, Plot=False)\n","        WSProps = ObjProps(labeled=spklts, cropped_rgb=cropped_rgb, cropped_lab=cropped_lab, cropped_hsv=cropped_hsv, ImagePath=img_name, MinSize = 5000)\n","        \n","    Contours_data = Contours_data.append(labels_cont)\n","    Spklts_data = Spklts_data.append(WSProps)\n","    Distances_data = Distances_data.append(SpkDists)\n","    Lengths_data = Lengths_data.append(SpkLengths)\n","\n","\n","# For one spike\n","# labeled_contours, num_contours = label(cropped_spk, return_num = True)\n","# red_props = regionprops(labeled_contours, intensity_image=cropped_rgb)\n","# Red_Perc = np.array(channel_percentiles(channel_props=red_props, Negatives=False)).T\n","# len(Red_Perc)\n","    "],"id":"06931969-c2f2-439f-86a9-530dba417bf4","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Processing image  ./Images/TEST\\S2p13T4R3.tif\n","Processing spike  1\n"]},{"ename":"error","evalue":"OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\shapedescr.cpp:360: error: (-201:Incorrect size of input array) There should be at least 5 points to fit the ellipse in function 'cv::fitEllipseNoDirect'\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n","\u001b[1;32mJ:\\My Drive\\M.Sc\\THESIS\\ImageAnalysis\\SpikeProperties\\Spyk_Prop\\SpykFunctions.py\u001b[0m in \u001b[0;36mObjProps\u001b[1;34m(labeled, cropped_rgb, cropped_lab, cropped_hsv, ImagePath, MinSize, rm_envelope)\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m         \u001b[0mellipse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitEllipse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m         \u001b[1;31m# Fit a line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31merror\u001b[0m: OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\shapedescr.cpp:360: error: (-201:Incorrect size of input array) There should be at least 5 points to fit the ellipse in function 'cv::fitEllipseNoDirect'\n"]}]},{"cell_type":"code","metadata":{"id":"1b428e61-c593-436d-84c9-b353e63a4806"},"source":[""],"id":"1b428e61-c593-436d-84c9-b353e63a4806","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5ef06330-31d8-410a-9169-178a1b676e31"},"source":["# DEMO"],"id":"5ef06330-31d8-410a-9169-178a1b676e31"},{"cell_type":"markdown","metadata":{"id":"17aaf017-27fe-466b-a47f-575b04ca3d35"},"source":["## Files\n","List images and select an image (`img_number`)"],"id":"17aaf017-27fe-466b-a47f-575b04ca3d35"},{"cell_type":"code","metadata":{"id":"c5ab2f05-e3b4-48c6-a94f-65fa372b422c"},"source":["%%time\n","\n","# List images\n","path = r'./Images/TEST'\n","Images = ListImages(path, imgformat=\".tif\", recursive=False)\n","len(Images)\n","\n","# Select image\n","img_number = 4\n","img_name = Images[img_number]"],"id":"c5ab2f05-e3b4-48c6-a94f-65fa372b422c","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3dc12c20-5a5b-4385-9165-374225c1218a"},"source":["## Generate mask and color arrays\n","Remove the background and create rgb, gray, lab, hsv, and bw images."],"id":"3dc12c20-5a5b-4385-9165-374225c1218a"},{"cell_type":"code","metadata":{"id":"25d28730-316c-47d6-9d69-01361ad0711c"},"source":["%%time\n","I = RemoveBackground(img_name, OtsuScaling=0.25, rgb_out=True, gray_out=True, lab_out=True, hsv_out=True, bw_out=True)\n","rgb0 = I[0]\n","gray0 = I[1]\n","lab0 = I[2]\n","hsv0 = I[3]\n","bw0 = I[4]\n"],"id":"25d28730-316c-47d6-9d69-01361ad0711c","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"12710e91-33f0-4644-8c60-7d03dd01f0cf"},"source":["## Enumerate spikes"],"id":"12710e91-33f0-4644-8c60-7d03dd01f0cf"},{"cell_type":"code","metadata":{"id":"3028549e-dff4-483d-b4f6-18d34677eb14"},"source":["%%time\n","# Enumerate spikes\n","EnumerateSpkCV(bw0, rgb0, TextSize=5, TROE2020=False)"],"id":"3028549e-dff4-483d-b4f6-18d34677eb14","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5d5ae7c8-f43d-49b0-995d-35a1913ab372"},"source":["%%time\n","PixelHist(bw=bw0, Lab=lab0, channel = 0, spikes=[1,2,26], nbins = 100)"],"id":"5d5ae7c8-f43d-49b0-995d-35a1913ab372","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9f7e1974-0ea2-41e2-b18b-69116cf3da72"},"source":["## Get spike properties"],"id":"9f7e1974-0ea2-41e2-b18b-69116cf3da72"},{"cell_type":"code","metadata":{"id":"2de5c684-fa6e-490b-9e79-5dbf6dfc64e6"},"source":["%%time\n","df = SpikesDF(I, ImagePath, RemoveBG=False, PrintSpkLabels=False)"],"id":"2de5c684-fa6e-490b-9e79-5dbf6dfc64e6","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2b3565f-c01c-492f-87b4-84242de2c05a"},"source":["%%time\n","df\n","# notice that the envelope (Spike_Label 1) was removed."],"id":"a2b3565f-c01c-492f-87b4-84242de2c05a","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"001c2cdd-f6da-4a8b-8bb5-3453f2de2f86"},"source":["## Select a spike"],"id":"001c2cdd-f6da-4a8b-8bb5-3453f2de2f86"},{"cell_type":"code","metadata":{"id":"741553fa-d46b-411f-8d06-a7728ae6c457"},"source":["%%time\n","# Select a spike from the labeled image\n","Selected_Spike = 26\n","print(\"Selected spike number\", Selected_Spike)\n","\n","# Label spikes\n","labeled_spks, num_spikes = label(bw0, return_num = True)\n","spk = labeled_spks==Selected_Spike\n","\n","# Crop spike\n","slice_x, slice_y = ndimage.find_objects(spk)[0]\n","cropped_spk = spk[slice_x, slice_y]\n","cropped_rgb = rgb0[slice_x, slice_y]\n","cropped_rgb = np.where(cropped_spk[..., None], cropped_rgb, 0)\n","cropped_gray = cropped_rgb @ [0.2126, 0.7152, 0.0722]\n","cropped_lab = color.rgb2lab(cropped_rgb)\n","cropped_hsv = color.rgb2hsv(cropped_rgb)\n","\n","# Visualize selected spike\n","plt.imshow(cropped_rgb)"],"id":"741553fa-d46b-411f-8d06-a7728ae6c457","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8ed5bb97-6298-43a4-84bd-a9910cc4278e"},"source":["## Spike length"],"id":"8ed5bb97-6298-43a4-84bd-a9910cc4278e"},{"cell_type":"code","metadata":{"id":"628bae6b-c7d7-4d20-b1a9-70051bb9534a"},"source":["%%time\n","L = spk_length(cropped_spk, method='skelblur', Overlay=True, PlotCH=False)"],"id":"628bae6b-c7d7-4d20-b1a9-70051bb9534a","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0738f1f7-d3e0-4f91-853e-2712fc2e488b"},"source":["## Threshold for contour detection"],"id":"0738f1f7-d3e0-4f91-853e-2712fc2e488b"},{"cell_type":"code","metadata":{"id":"397283da-49bc-4fae-835c-f7c97632b2ef"},"source":["%%time\n","thresh2 = SpkltThresh(cropped=cropped_rgb, ResizeFactor=30, thr2=0.8, MinSize=1000)\n","plt.imshow(thresh2)"],"id":"397283da-49bc-4fae-835c-f7c97632b2ef","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"657d0107-430a-4b43-9de2-ffc2ff246a46"},"source":["### Contour for spikelet detection"],"id":"657d0107-430a-4b43-9de2-ffc2ff246a46"},{"cell_type":"code","metadata":{"id":"bb87b431-1a10-4aa6-bec9-16ac0132b2ef"},"source":["%%time\n","labels_cont = LabelContours(cropped_rgb, ResizeFactor=30, MinSize = 1000, thr2=0.8, plot=True)"],"id":"bb87b431-1a10-4aa6-bec9-16ac0132b2ef","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e84b2133-25ab-4ca6-9fe9-0ac294437720"},"source":["### Get contour properties"],"id":"e84b2133-25ab-4ca6-9fe9-0ac294437720"},{"cell_type":"code","metadata":{"id":"3ecfa6b3-da4e-465e-94ed-89e058c25302"},"source":["%time\n","CountProp = SpkltProps(cropped_rgb=cropped_rgb, ImagePath=img_name, ResizeFactor=30, MinSize = 1000, plot=True)"],"id":"3ecfa6b3-da4e-465e-94ed-89e058c25302","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cef0f59f-0ae0-4f8e-b1f2-313913f10da5"},"source":["CountProp"],"id":"cef0f59f-0ae0-4f8e-b1f2-313913f10da5","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"58fa10c4-8886-48dd-99b9-ff6edad42256"},"source":["### Distance between detected spikelets"],"id":"58fa10c4-8886-48dd-99b9-ff6edad42256"},{"cell_type":"code","metadata":{"id":"193f0880-172e-41de-91ef-0ab72afaac07"},"source":["# Example:\n","D = DistAll(bw=thresh2, HeatMap=True, spike_length=SL)"],"id":"193f0880-172e-41de-91ef-0ab72afaac07","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c1d7fd7e-5de9-46d6-ba88-d8d99c6040cd"},"source":["EnumerateSpkCV(thresh2, cropped_rgb, TextSize=3,  TROE2020=False)"],"id":"c1d7fd7e-5de9-46d6-ba88-d8d99c6040cd","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a5677053-159e-4b95-ba5a-d84b9948772d"},"source":[""],"id":"a5677053-159e-4b95-ba5a-d84b9948772d","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7726c9e4-1735-4178-9da5-1d25a7ebc5df"},"source":["## Watershed for spikelet detection"],"id":"7726c9e4-1735-4178-9da5-1d25a7ebc5df"},{"cell_type":"code","metadata":{"id":"492df66e-dcb9-4b5d-b1eb-afc09812d129"},"source":["%%time\n","# Using watershed\n","spklts, n_spklts= LabelSpklts(cropped_rgb, MinDist=50, labels_out=True, n_spklt=True, Plot=True)"],"id":"492df66e-dcb9-4b5d-b1eb-afc09812d129","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a4fac288-86eb-4f49-9a5e-f14805d4fd73"},"source":["### Spikelet properties"],"id":"a4fac288-86eb-4f49-9a5e-f14805d4fd73"},{"cell_type":"code","metadata":{"id":"ff71d341-c9fc-4884-b997-b2765aeb0a1a"},"source":["%%time\n","WSProps = ObjProps(labeled=spklts, cropped_rgb=cropped_rgb, cropped_lab=cropped_lab, ImagePath=img_name, MinSize = 10000)"],"id":"ff71d341-c9fc-4884-b997-b2765aeb0a1a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5c938149-2af9-476c-b6a0-b6a1fc8ee990"},"source":["WSProps\n","# Notice that the number of rows is lower. That's because the elements with that don't meet MinSize are removed."],"id":"5c938149-2af9-476c-b6a0-b6a1fc8ee990","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cdba0e65-5ad4-40ca-aaa2-858ff4f05ebc"},"source":[""],"id":"cdba0e65-5ad4-40ca-aaa2-858ff4f05ebc","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4b9955f6-1082-4e7c-9cdb-01edd75a680d"},"source":[""],"id":"4b9955f6-1082-4e7c-9cdb-01edd75a680d","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1badd6c6-9ca5-476e-8ccb-a15c13bd9fb0"},"source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"id":"1badd6c6-9ca5-476e-8ccb-a15c13bd9fb0","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aa247d53-3a0e-419e-9f63-fa72aecdaf79"},"source":[""],"id":"aa247d53-3a0e-419e-9f63-fa72aecdaf79","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f41fb6af-e4f9-492a-88d7-5a71c2301c77"},"source":[""],"id":"f41fb6af-e4f9-492a-88d7-5a71c2301c77","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"98d16945-0ea1-48e8-b4cf-906cdb14dccd"},"source":[""],"id":"98d16945-0ea1-48e8-b4cf-906cdb14dccd","execution_count":null,"outputs":[]}]}